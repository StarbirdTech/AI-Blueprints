{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fdb4bbf",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-size: 50px;\"> Run Workflow </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149608e8",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "- Configure the Environment\n",
    "- Define Constants and Paths\n",
    "- Load Configuratons and Secrets\n",
    "- Extract Markdown Files with Placeholders\n",
    "- Parse Markdown Files\n",
    "- Chunk Markdown Content\n",
    "- Initialize Model\n",
    "- Invoke Model on Each Chunk\n",
    "- Save Results\n",
    "- Log Execution Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115eb488",
   "metadata": {},
   "source": [
    "## Step 0: Configure the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6591e9f3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "# Configure logger\n",
    "logger: logging.Logger = logging.getLogger(\"run_workflow_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent duplicate logs from parent loggers\n",
    "\n",
    "# Set formatter\n",
    "formatter: logging.Formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Configure and attach stream handler\n",
    "stream_handler: logging.StreamHandler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97410cf1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()  \n",
    "\n",
    "logger.info(\"Notebook execution started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73afb67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Required Libraries\n",
    "%pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f576c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import sys\n",
    "import difflib\n",
    "import json\n",
    "import re\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to system path\n",
    "sys.path.append(str(Path(\"..\").resolve() / \"src\"))\n",
    "\n",
    "# Internal Modules\n",
    "from github_extractor import GitHubMarkdownProcessor\n",
    "from utils import load_config_and_secrets, initialize_llm\n",
    "from parser import parse_md_for_grammar_correction, restore_placeholders\n",
    "from chunker import chunk_markdown\n",
    "from prompt_templates import get_markdown_correction_prompt\n",
    "from markdown_correction_service import MarkdownCorrectionService\n",
    "\n",
    "# Other modules\n",
    "import mlflow\n",
    "from mlflow.models import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ce4f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d56403",
   "metadata": {},
   "source": [
    "### Define Constants and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21ae9c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG_PATH = Path(\"../configs/configs.yaml\")\n",
    "SECRETS_PATH = Path(\"../configs/secrets.yaml\")\n",
    "LOCAL_MODEL_PATH = Path(\"/home/jovyan/datafabric/llama3.1-8b-instruct/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de48c5",
   "metadata": {},
   "source": [
    "### Load Configurations and Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca78569",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Load secrets \n",
    "github_token = os.getenv(\"AIS_GITHUB_ACCESS_TOKEN\")\n",
    "if github_token:\n",
    "    secrets = {\"AIS_GITHUB_ACCESS_TOKEN\": github_token}\n",
    "    logger.info(\"Loaded GITHUB_ACCESS_TOKEN from environment variable.\")\n",
    "else:\n",
    "    secrets_path = SECRETS_PATH\n",
    "    if os.path.exists(secrets_path):\n",
    "        with open(secrets_path, \"r\") as f:\n",
    "            secrets = yaml.safe_load(f)\n",
    "        logger.info(f\"Loaded secrets from {secrets_path}.\")\n",
    "    else:\n",
    "        # If no token is found anywhere, initialize with an empty dict or handle as an error\n",
    "        secrets = {}\n",
    "        logger.warning(\"No GITHUB_ACCESS_TOKEN found in environment or secrets.yaml.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9594ff16",
   "metadata": {},
   "source": [
    "## Step 1: Extracting and Parsing Markdown Files From GitHub Repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1634fe",
   "metadata": {},
   "source": [
    "### Extract Markdown Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012bfaf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define repo URL and GitHub access token\n",
    "repo_url = \"https://github.com/hp-david/test\"\n",
    "access_token = secrets.get(\"AIS_GITHUB_ACCESS_TOKEN\")\n",
    "\n",
    "# Create processor instance\n",
    "processor = GitHubMarkdownProcessor(repo_url=repo_url, access_token=access_token)\n",
    "\n",
    "# Run preprocessing workflow\n",
    "markdowns = processor.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc969753",
   "metadata": {},
   "source": [
    "### Parse Markdown Files with Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6c5a8c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "parsed_markdowns = {}\n",
    "placeholder_maps = {}\n",
    "\n",
    "for filename, content in markdowns.items():\n",
    "    # Parse the content and get placeholder map\n",
    "    placeholder_map, processed_content = parse_md_for_grammar_correction(content)\n",
    "    \n",
    "    # Store the processed content (maintains dictionary structure for chunker)\n",
    "    parsed_markdowns[filename] = processed_content\n",
    "    \n",
    "    # Store the placeholder map for restoration\n",
    "    placeholder_maps[filename] = placeholder_map\n",
    "\n",
    "logger.info(f\"Parsed {len(parsed_markdowns)} files successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342a312",
   "metadata": {},
   "source": [
    "### Chunk Markdown Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c7a75",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "all_chunks = {}  \n",
    "\n",
    "# Chunk each file's content and store the results in a dictionary\n",
    "for file_name, content in parsed_markdowns.items():\n",
    "    chunks = chunk_markdown(content)\n",
    "    all_chunks[file_name] = chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527b5a1c",
   "metadata": {},
   "source": [
    "### Display Chunks (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a37ce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for file_name, chunks in all_chunks.items():\n",
    "    logger.info(f\"\\n===== {file_name} =====\\n\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        logger.info(f\"\\n--- Chunk {i+1} ---\\n\")\n",
    "        logger.info(chunk)\n",
    "        logger.info(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cfa1f8",
   "metadata": {},
   "source": [
    "## Step 2: Correct Markdown Files with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5b195",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get markdown correction prompt from prompt_templates module\n",
    "correction_prompt = get_markdown_correction_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65823c9d",
   "metadata": {},
   "source": [
    "### Initialize Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6470bbf6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set the model source from the configs\n",
    "if \"model_source\" in config:\n",
    "    model_source = config[\"model_source\"]\n",
    "\n",
    "# Initialize llm \n",
    "llm = initialize_llm(model_source, secrets, str(LOCAL_MODEL_PATH))\n",
    "\n",
    "# Create the LLM chain with the correction prompt\n",
    "llm_chain = correction_prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b3fb3",
   "metadata": {},
   "source": [
    "### Invoke Model on Each Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6cc26",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "count = 0\n",
    "\n",
    "# Process each chunk through the language model and store the results\n",
    "for file_name, chunks in all_chunks.items():  \n",
    "    for chunk in chunks:\n",
    "        # Send the chunks to the llm for correction\n",
    "        response = llm_chain.invoke({\"markdown\": chunk})\n",
    "\n",
    "        # Store the file name, original text, and corrected text\n",
    "        results.append({\n",
    "            \"file\": file_name,\n",
    "            \"original\": chunk,\n",
    "            \"corrected\": response\n",
    "        })\n",
    "\n",
    "        # Log progress (optional)\n",
    "        '''\n",
    "        logger.info(f\"chunk {count} done\")\n",
    "        '''\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4fa12",
   "metadata": {},
   "source": [
    "### Display Corrected Chunks (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4223c3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for result in results:\n",
    "    original_text = result[\"original\"]\n",
    "    corrected_text = result[\"corrected\"]\n",
    "    \n",
    "    original_tokens = len(llm.client.tokenize(original_text.encode(\"utf-8\")))\n",
    "    corrected_tokens = len(llm.client.tokenize(corrected_text.encode(\"utf-8\")))\n",
    "\n",
    "    logger.info(f\"\\n===== {result['file']} =====\\n\")\n",
    "    logger.info(f\"--- Original ({original_tokens} tokens) ---\\n\")\n",
    "    logger.info(original_text)\n",
    "    logger.info(f\"\\n--- Corrected ({corrected_tokens} tokens) ---\\n\")\n",
    "    logger.info(corrected_text)\n",
    "    logger.info(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3616c50",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503d8fa",
   "metadata": {},
   "source": [
    "#### Save Raw Corrrected Markdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f2da8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Helper: Safe chunk joiner\n",
    "def safe_join_chunks(chunks: List[str]) -> str:\n",
    "    \"\"\"Rejoins a list of text chunks into a single string, preserving formatting and sentence boundaries.\n",
    "\n",
    "    Ensures that chunks split mid-sentence get a space inserted appropriately.\n",
    "\n",
    "    Args:\n",
    "        chunks (List[str]): A list of processed text segments.\n",
    "\n",
    "    Returns:\n",
    "        str: The reassembled markdown text.\n",
    "    \"\"\"\n",
    "    joined = \"\"\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i == 0:\n",
    "            joined += chunk\n",
    "        else:\n",
    "            prev = chunks[i - 1].rstrip()\n",
    "            curr = chunk\n",
    "\n",
    "            # Heuristic: Detect if a sentence was split across two chunks.\n",
    "            if prev.endswith('.') and re.match(r'^[A-Z\\\"]', curr.lstrip()):\n",
    "                # If it's a sentence break, add a single space to separate them.\n",
    "                joined += ' ' + curr.lstrip()\n",
    "            else:\n",
    "                # Otherwise, join the chunk directly.\n",
    "                joined += curr  \n",
    "    return joined\n",
    "\n",
    "\n",
    "# Group corrected chunks by file\n",
    "corrected_chunks_by_file = defaultdict(list)\n",
    "\n",
    "for result in results:\n",
    "    corrected_chunks_by_file[result[\"file\"]].append(result[\"corrected\"])\n",
    "\n",
    "# Rebuild each file from its corrected chunks with smart joining\n",
    "rebuilt_corrected_files = {\n",
    "    file_name: safe_join_chunks(chunks)\n",
    "    for file_name, chunks in corrected_chunks_by_file.items()\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"corrected\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Restore placeholders and write final output\n",
    "for file_name, corrected_content in rebuilt_corrected_files.items():\n",
    "    placeholder_map = placeholder_maps.get(file_name, {})\n",
    "    restored_content = restore_placeholders(corrected_content, placeholder_map)\n",
    "\n",
    "    file_path = Path(file_name)\n",
    "\n",
    "    # Create subdirectories as needed under 'corrected/'\n",
    "    output_path = output_dir / f\"{file_path.stem}_{timestamp}{file_path.suffix}\"\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(restored_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebcf303",
   "metadata": {},
   "source": [
    "#### Save Corrected Markdowns with Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d272f2d0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "diff_output_dir = Path(\"corrected-diffs\")\n",
    "diff_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for file_name, corrected_content in rebuilt_corrected_files.items():\n",
    "    placeholder_map = placeholder_maps.get(file_name, {})\n",
    "    restored_content = restore_placeholders(corrected_content, placeholder_map)\n",
    "\n",
    "    # Get original content from markdowns dict\n",
    "    original_content = markdowns.get(file_name)\n",
    "    if original_content is None:\n",
    "        logger.info(f\"Warning: No original content for file {file_name}\")\n",
    "        continue\n",
    "\n",
    "    # Create unified diff view (HTML side-by-side)\n",
    "    differ = difflib.HtmlDiff(tabsize=4, wrapcolumn=80)\n",
    "    diff_html = differ.make_file(\n",
    "        original_content.splitlines(),\n",
    "        restored_content.splitlines(),\n",
    "        fromdesc=f\"Original: {file_name}\",\n",
    "        todesc=f\"Corrected: {file_name}\",\n",
    "        context=True,\n",
    "        numlines=3\n",
    "    )\n",
    "\n",
    "    file_path = Path(file_name)\n",
    "\n",
    "    # Write diff HTML file\n",
    "    diff_path = diff_output_dir / f\"{file_path.stem}_{timestamp}{file_path.suffix}.html\"\n",
    "    diff_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(diff_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(diff_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7589c5ca",
   "metadata": {},
   "source": [
    "#### Save Chunks Into a JSON for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932307d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results_path = Path(\"results.json\")\n",
    "with results_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef870f3",
   "metadata": {},
   "source": [
    "### Log Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66633023",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"⏱️ Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"✅ Notebook execution completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
