{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50bb196b-2724-4fa5-acc1-ff716ee78f1c",
   "metadata": {},
   "source": [
    "<h1 style=\\\"text-align: center; font-size: 50px;\\\"> Register Model </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666a4c50-225e-4ca3-a601-023e61d82126",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "- Start Execution\n",
    "- Define User Constants\n",
    "- Install and Import Libraries\n",
    "- Configure Settings\n",
    "- Verify Assets\n",
    "- Load and Validate Data\n",
    "- Define MLflow Class\n",
    "- Log the Model to MLflow\n",
    "- Fetch the Latest Model Version from MLflow\n",
    "- Load the Model and Run Inference\n",
    "- Display Evaluation Results\n",
    "- Save Evaluation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc11e6-060f-4dea-ad55-722884ee25f7",
   "metadata": {},
   "source": [
    "# Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "777cf31f-7745-484c-899e-0dfdfdec5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Configure logger\n",
    "logger: logging.Logger = logging.getLogger(\"register_model_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent duplicate logs from parent loggers\n",
    "\n",
    "# Set formatter\n",
    "formatter: logging.Formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Configure and attach stream handler\n",
    "stream_handler: logging.StreamHandler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0a022b-7676-4ebd-833a-914ec3e10b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 11:56:21 - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  \n",
    "logger.info(\"Notebook execution started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf05f24-14ec-4bd0-b528-fea6e2440410",
   "metadata": {},
   "source": [
    "# Define User Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a9b06d-f6a6-40a4-b649-6b4b9d719cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File configuration\n",
    "INPUT_FILE_NAME: str = \"2025 ISEF Project Abstracts.csv\"\n",
    "INPUT_DIR: Path = Path(\"../data/inputs\")\n",
    "OUTPUT_DIR: Path = Path(\"../data/outputs\")\n",
    "\n",
    "# Ensure directories exist\n",
    "INPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INPUT_PATH: Path = INPUT_DIR / INPUT_FILE_NAME\n",
    "TIMESTAMP: str = datetime.now().strftime('%Y-%m-%d %H-%M-%S')\n",
    "OUTPUT_FILE_NAME: str = f\"Evaluated - {INPUT_FILE_NAME} - {TIMESTAMP}\"\n",
    "OUTPUT_PATH: Path = OUTPUT_DIR / OUTPUT_FILE_NAME\n",
    "\n",
    "# Evaluation configuration\n",
    "KEY_COLUMN: str = \"title\"\n",
    "EVAL_COLUMN: str = \"abstract\"\n",
    "CRITERIA: dict[str, int] = json.loads(\n",
    "        json.dumps({\n",
    "            \"Originality\": 3,\n",
    "            \"ScientificRigor\": 4,\n",
    "            \"Clarity\": 2,\n",
    "            \"Relevance\": 1,\n",
    "            \"Feasibility\": 3,\n",
    "            \"Brevity\": 2,\n",
    "        }),\n",
    ")\n",
    "\n",
    "# Percentage of rows to evaluate\n",
    "PERCENTAGE_ROWS_TO_BE_EVALUATED: float = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a47ed24-7449-4fc5-9d98-4b041b32f917",
   "metadata": {},
   "source": [
    "# Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ff38d7-e677-47ee-a808-f043d272d793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CPU times: user 36.8 ms, sys: 11.6 ms, total: 48.4 ms\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97925fde-bb0f-4378-a2d2-af43d51f497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import multiprocessing\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models import ModelSignature\n",
    "from mlflow.types import Schema, ColSpec, DataType, ParamSpec, ParamSchema, TensorSpec\n",
    "from mlflow.tracking import MlflowClient\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from src.utils import load_config, configure_proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e948e09-eaff-4edf-b1bb-8a10a6bab1e8",
   "metadata": {},
   "source": [
    "# Configure Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a8844e-7a29-428b-8648-c77e98c5da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df8f8f1e-674e-4365-bad5-4a6a561004a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration loaded successfully\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"EvaluationExperiment\"\n",
    "RUN_NAME = \"EvaluationRun\"\n",
    "MODEL_NAME = \"EvaluationModel\"\n",
    "\n",
    "LLAMA_MODEL_PATH = \"/home/jovyan/datafabric/meta-llama3.1-8b-Q8/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\"\n",
    "\n",
    "# Load configuration\n",
    "CONFIG_PATH = \"../configs/config.yaml\"\n",
    "config = load_config(CONFIG_PATH)\n",
    "\n",
    "# Configure proxy if specified\n",
    "configure_proxy(config)\n",
    "\n",
    "print(\"✅ Configuration loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fed128-4068-4bf4-9e6b-3f1d35301cde",
   "metadata": {},
   "source": [
    "# Verify Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f477e2d-0fe3-483c-8428-8e9a127e5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_asset_status(asset_path: str, asset_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Logs the status of a given asset based on its existence.\n",
    "\n",
    "    Parameters:\n",
    "        asset_path (str): File or directory path to check.\n",
    "        asset_name (str): Name of the asset for logging context.\n",
    "    \"\"\"\n",
    "    if Path(asset_path).exists():\n",
    "        logger.info(f\"{asset_name} is properly configured.\")\n",
    "    else:\n",
    "        logger.info(f\"{asset_name} is not properly configured. Please ensure the required asset is correctly configured in your AI Studio project according to the README file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f99e3331-07e7-408e-8a91-f92a5ac7852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 11:56:25 - INFO - Input Data is properly configured.\n",
      "2025-08-05 11:56:25 - INFO - LLaMA Local model is properly configured.\n"
     ]
    }
   ],
   "source": [
    "log_asset_status(\n",
    "    asset_path=INPUT_PATH,\n",
    "    asset_name=\"Input Data\",\n",
    ")\n",
    "\n",
    "log_asset_status(\n",
    "    asset_path=LLAMA_MODEL_PATH,\n",
    "    asset_name=\"LLaMA Local model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af238084-ce32-4070-8017-00c2db27a2a0",
   "metadata": {},
   "source": [
    "# Load and Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2984cac1-dbfb-40ff-913e-d8f7b3c23f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>year</th>\n",
       "      <th>schools</th>\n",
       "      <th>abstract</th>\n",
       "      <th>country</th>\n",
       "      <th>State</th>\n",
       "      <th>Province</th>\n",
       "      <th>awards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dynamic Response of a Human Neck Replica to Ax...</td>\n",
       "      <td>Energy: Physical</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>set()</td>\n",
       "      <td>Purpose: A human neck replica was made to simu...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Effect of Nutrient Solution Concentration ...</td>\n",
       "      <td>Physics and Astronomy</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>set()</td>\n",
       "      <td>Studies comparing the mineral nutrition of hyd...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>UT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do Air Root Pruning Pots Accelerate Success in...</td>\n",
       "      <td>Physics and Astronomy</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>set()</td>\n",
       "      <td>The purpose of my project was to determine whi...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>LA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Insect-repelling Plants &amp; New Organic Pesticide</td>\n",
       "      <td>Environmental Engineering</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>set()</td>\n",
       "      <td>Organochlorine pesticides in agriculture are n...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Do Different Factors Affect the Accuracy o...</td>\n",
       "      <td>Earth and Environmental Sciences</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>set()</td>\n",
       "      <td>The purpose of this experiment is to determine...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dye Sensitized Solar Cells: New Structures and...</td>\n",
       "      <td>Engineering Mechanics</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>set()</td>\n",
       "      <td>Although fossil fuels have the capacity to pow...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Fourth Award of $500']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Novel Method for Determination of Camera Pos...</td>\n",
       "      <td>Embedded Systems</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>set()</td>\n",
       "      <td>The method proposed here solves for the pose o...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>MO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Observational Detection of Solar g-mode Oscill...</td>\n",
       "      <td>Microbiology</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>set()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>HI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Third Award of $1,000']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Synthesis of Periodic Mesoporous Organosilicas...</td>\n",
       "      <td>Plant Sciences</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>set()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Second Award of $2,000']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Novel Mathematical Simulation to Study the D...</td>\n",
       "      <td>Materials Science</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>set()</td>\n",
       "      <td>Human Immunodeficiency Virus (HIV), the virus ...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Dynamic Response of a Human Neck Replica to Ax...   \n",
       "1  The Effect of Nutrient Solution Concentration ...   \n",
       "2  Do Air Root Pruning Pots Accelerate Success in...   \n",
       "3    Insect-repelling Plants & New Organic Pesticide   \n",
       "4  How Do Different Factors Affect the Accuracy o...   \n",
       "5  Dye Sensitized Solar Cells: New Structures and...   \n",
       "6  A Novel Method for Determination of Camera Pos...   \n",
       "7  Observational Detection of Solar g-mode Oscill...   \n",
       "8  Synthesis of Periodic Mesoporous Organosilicas...   \n",
       "9  A Novel Mathematical Simulation to Study the D...   \n",
       "\n",
       "                           category    year schools  \\\n",
       "0                  Energy: Physical  2014.0   set()   \n",
       "1             Physics and Astronomy  2014.0   set()   \n",
       "2             Physics and Astronomy  2014.0   set()   \n",
       "3         Environmental Engineering  2014.0   set()   \n",
       "4  Earth and Environmental Sciences  2014.0   set()   \n",
       "5             Engineering Mechanics  2014.0   set()   \n",
       "6                  Embedded Systems  2014.0   set()   \n",
       "7                      Microbiology  2014.0   set()   \n",
       "8                    Plant Sciences  2014.0   set()   \n",
       "9                 Materials Science  2014.0   set()   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Purpose: A human neck replica was made to simu...   \n",
       "1  Studies comparing the mineral nutrition of hyd...   \n",
       "2  The purpose of my project was to determine whi...   \n",
       "3  Organochlorine pesticides in agriculture are n...   \n",
       "4  The purpose of this experiment is to determine...   \n",
       "5  Although fossil fuels have the capacity to pow...   \n",
       "6  The method proposed here solves for the pose o...   \n",
       "7                                                NaN   \n",
       "8                                                NaN   \n",
       "9  Human Immunodeficiency Virus (HIV), the virus ...   \n",
       "\n",
       "                    country State Province                      awards  \n",
       "0  United States of America    MN      NaN                     ['nan']  \n",
       "1  United States of America    UT      NaN                     ['nan']  \n",
       "2  United States of America    LA      NaN                     ['nan']  \n",
       "3  United States of America    TX      NaN                     ['nan']  \n",
       "4  United States of America    MN      NaN                     ['nan']  \n",
       "5  United States of America    TX      NaN    ['Fourth Award of $500']  \n",
       "6  United States of America    MO      NaN                     ['nan']  \n",
       "7  United States of America    HI      NaN   ['Third Award of $1,000']  \n",
       "8  United States of America    TX      NaN  ['Second Award of $2,000']  \n",
       "9  United States of America    TX      NaN                     ['nan']  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_PATH)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "044c75ac-2ac6-44c0-8073-fd34086cc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate required columns\n",
    "missing_columns: list[str] = [\n",
    "    col for col in [KEY_COLUMN, EVAL_COLUMN] if col not in df.columns\n",
    "]\n",
    "if missing_columns:\n",
    "    raise KeyError(f\"Missing required column(s): {', '.join(missing_columns)}\")\n",
    "\n",
    "# Ensure key column is of string type\n",
    "df[KEY_COLUMN] = df[KEY_COLUMN].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "543d7e7a-03f8-4853-844b-5b9c4be4a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of rows to evaluate (at least 1)\n",
    "num_rows_to_evaluate: int = max(int(len(df) * PERCENTAGE_ROWS_TO_BE_EVALUATED / 100), 1)\n",
    "\n",
    "# Select the top rows for evaluation\n",
    "df = df[:num_rows_to_evaluate]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ca432-af24-4365-84eb-0fc1adf0beb2",
   "metadata": {},
   "source": [
    "# Define MLflow Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0b2bf55-4f22-4040-9aaf-cc4303374867",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluatorModel(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"\n",
    "    A PythonModel using a local LLaMA model to evaluate texts by multiple criteria.\n",
    "    \"\"\"\n",
    "    def load_context(self, context):\n",
    "        \"\"\"Load LLaMA model from artifacts with optimized configuration.\"\"\"\n",
    "        model_path = context.artifacts[\"llama_model_path\"]\n",
    "        self.llm = Llama(\n",
    "            model_path=model_path,\n",
    "            n_gpu_layers=-1,\n",
    "            n_batch=128,\n",
    "            n_ctx=8192,\n",
    "            max_tokens=512,\n",
    "            f16_kv=True,\n",
    "            use_mmap=False,\n",
    "            low_vram=True,\n",
    "            rope_scaling=None,\n",
    "            temperature=0.0,\n",
    "            repeat_penalty=1.0,\n",
    "            streaming=False,\n",
    "            stop=None,\n",
    "            seed=42,\n",
    "            num_threads=multiprocessing.cpu_count(),\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "    def predict(self, context, model_input: pd.DataFrame, params: dict) -> pd.DataFrame:\n",
    "        \"\"\"Evaluate texts using LLaMA model and return scores with total.\"\"\"\n",
    "        # Extract parameters\n",
    "        key_col = params.get(\"key_column\", KEY_COLUMN)\n",
    "        eval_col = params.get(\"eval_column\", EVAL_COLUMN)\n",
    "        criteria = params.get(\"criteria\", CRITERIA)\n",
    "        if isinstance(criteria, str):\n",
    "            criteria = json.loads(criteria)\n",
    "\n",
    "        # Validate input\n",
    "        for col in (key_col, eval_col):\n",
    "            if col not in model_input.columns:\n",
    "                raise KeyError(f\"Input DataFrame missing column '{col}'\")\n",
    "\n",
    "        df = model_input.copy()\n",
    "        df[key_col] = df[key_col].astype(str)\n",
    "\n",
    "        # Helper functions\n",
    "        def scale_score(raw: int, target: int) -> int:\n",
    "            \"\"\"Scale raw score (1-10) to target range.\"\"\"\n",
    "            scaled = round((raw / 10) * target)\n",
    "            return min(max(scaled, 0), target)\n",
    "\n",
    "        def extract_score(text: str) -> int:\n",
    "            \"\"\"Extract numeric score from LLM response text.\"\"\"\n",
    "            match = re.search(r\"\\b(10|[1-9])\\b\", text)\n",
    "            return int(match.group(1)) if match else -1\n",
    "\n",
    "        def eval_criterion(text: str, crit: str) -> int:\n",
    "            \"\"\"Evaluate text against criterion using LLM.\"\"\"\n",
    "            prompt = (\n",
    "                f\"Evaluate abstract by '{crit}', return integer 1-10 only.\\n\"\n",
    "                f\"Abstract:\\n{text.strip()}\\nScore:\"\n",
    "            )\n",
    "            resp = self.llm(prompt)[\"choices\"][0][\"text\"]\n",
    "            return extract_score(resp)\n",
    "\n",
    "\n",
    "        results = []\n",
    "        for _, row in df.iterrows():\n",
    "            scores = {crit: scale_score(eval_criterion(row[eval_col], crit), criteria[crit])\n",
    "                      for crit in criteria}\n",
    "            scores[key_col] = row[key_col]\n",
    "            results.append(scores)\n",
    "\n",
    "        scored_df = pd.DataFrame(results)\n",
    "        # Merge & compute total\n",
    "        merged = df.merge(scored_df, on=key_col)\n",
    "        merged[\"TotalScore\"] = merged[list(criteria)].sum(axis=1)\n",
    "        return merged\n",
    "\n",
    "    @classmethod\n",
    "    def log_model(\n",
    "        cls, \n",
    "        model_name: str, \n",
    "        llama_model_path: str, \n",
    "        config_path: str,\n",
    "        experiment_name: str = EXPERIMENT_NAME\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Logs and registers this model in MLflow.\n",
    "        \"\"\"\n",
    "        # Define artifacts\n",
    "        artifacts = {\n",
    "            \"llama_model_path\": llama_model_path,\n",
    "            \"config_path\": config_path,\n",
    "            \"demo\": \"../demo\",\n",
    "            }\n",
    "\n",
    "        params_schema = ParamSchema([\n",
    "            ParamSpec(\"key_column\",  DataType.string,  'title'),\n",
    "            ParamSpec(\"eval_column\", DataType.string,  'abstract'),\n",
    "            ParamSpec(\"criteria\",    DataType.string,  '[\"Originality\",\"Clarity\",\"Relevance\",\"Feasibility\",\"Feasibility\"]'),\n",
    "        ])\n",
    "        \n",
    "        signature = ModelSignature(inputs=None, outputs=None, params=params_schema)\n",
    "\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=model_name,\n",
    "            python_model=cls(),\n",
    "            artifacts=artifacts,\n",
    "            signature=signature,\n",
    "            registered_model_name=model_name,\n",
    "            pip_requirements='../requirements.txt'\n",
    "        )\n",
    "        logger.info(f\"Model '{model_name}' logged and registered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a821057-ff9b-40b9-906a-70dce9b74d5a",
   "metadata": {},
   "source": [
    "# Log the Model to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53a7ea0a-d48c-4ea7-b050-1127851ae7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/05 11:56:25 INFO mlflow.tracking.fluent: Experiment with name 'EvaluationExperiment' does not exist. Creating a new experiment.\n",
      "2025-08-05 11:56:26 - INFO - Run ID: ad240e7bbe9b41d3ae4fb166d1584d91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acedbcdb3b44230bad205d2ba5f24ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790ba53f869a4ac4a2cf8660d8fdf14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f6138267274d7e97de05b202e4b06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'EvaluationModel'.\n",
      "Created version '1' of model 'EvaluationModel'.\n",
      "2025-08-05 11:59:18 - INFO - Model 'EvaluationModel' logged and registered.\n",
      "Registered model 'EvaluationModel' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'EvaluationModel'.\n",
      "2025-08-05 11:59:18 - INFO - Registered model: EvaluationModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.43 s, sys: 26.4 s, total: 27.9 s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlflow.set_tracking_uri('/phoenix/mlflow')\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    run_id = run.info.run_id\n",
    "    logger.info(\"Run ID: %s\", run_id)\n",
    "\n",
    "    EvaluatorModel.log_model(\n",
    "        model_name=MODEL_NAME,\n",
    "        llama_model_path=LLAMA_MODEL_PATH,\n",
    "        config_path=CONFIG_PATH,\n",
    "    )\n",
    "\n",
    "    mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run_id}/{MODEL_NAME}\",\n",
    "        name=MODEL_NAME\n",
    "    )\n",
    "    logger.info(\"Registered model: %s\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c15ef-955e-46a4-ba60-9a21f4ba3a99",
   "metadata": {},
   "source": [
    "# Fetch the Latest Model Version from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bd52a98-1ac0-422f-8480-c534f6dd0437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 11:59:18 - INFO - Latest model version: 2\n"
     ]
    }
   ],
   "source": [
    "# Load latest model\n",
    "client = MlflowClient()\n",
    "latest_version = client.get_latest_versions(MODEL_NAME, stages=[\"None\"])[0].version\n",
    "logger.info(f\"Latest model version: {latest_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94baee8f-b46b-48ad-bfba-936fb8bb7cce",
   "metadata": {},
   "source": [
    "# Load the Model and Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ceda054-f992-48f4-be35-494e38005502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.2 s, sys: 2.76 s, total: 3.96 s\n",
      "Wall time: 48.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_uri = f\"models:/{MODEL_NAME}/{latest_version}\"\n",
    "model = mlflow.pyfunc.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adb29ecd-b249-48d9-96a4-4b90d7060c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 12:00:08 - INFO - Sample inference result:                                                title          category  \\\n",
      "0  Dynamic Response of a Human Neck Replica to Ax...  Energy: Physical   \n",
      "\n",
      "     year schools                                           abstract  \\\n",
      "0  2014.0   set()  Purpose: A human neck replica was made to simu...   \n",
      "\n",
      "                    country State Province   awards  Originality  \\\n",
      "0  United States of America    MN      NaN  ['nan']            0   \n",
      "\n",
      "   ScientificRigor  Clarity  Relevance  Feasibility  Brevity  TotalScore  \n",
      "0                4        2          0            1        1           8  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.95 s, sys: 113 ms, total: 2.07 s\n",
      "Wall time: 2.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Sample input\n",
    "sample = df\n",
    "params = {\n",
    "    \"key_column\": KEY_COLUMN,\n",
    "    \"eval_column\": EVAL_COLUMN,\n",
    "    \"criteria\": json.dumps(CRITERIA),\n",
    "}\n",
    "preds = model.predict(sample, params=params)\n",
    "logger.info(\"Sample inference result: %s\", preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de6c9df-21d5-4e6b-9702-69b96c084b95",
   "metadata": {},
   "source": [
    "# Display Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1f645d8-ef62-49d0-8ac5-cf23e4e971d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category_x</th>\n",
       "      <th>year_x</th>\n",
       "      <th>schools_x</th>\n",
       "      <th>abstract_x</th>\n",
       "      <th>country_x</th>\n",
       "      <th>State_x</th>\n",
       "      <th>Province_x</th>\n",
       "      <th>awards_x</th>\n",
       "      <th>category_y</th>\n",
       "      <th>...</th>\n",
       "      <th>State_y</th>\n",
       "      <th>Province_y</th>\n",
       "      <th>awards_y</th>\n",
       "      <th>Originality</th>\n",
       "      <th>ScientificRigor</th>\n",
       "      <th>Clarity</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Feasibility</th>\n",
       "      <th>Brevity</th>\n",
       "      <th>TotalScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dynamic Response of a Human Neck Replica to Ax...</td>\n",
       "      <td>Energy: Physical</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>set()</td>\n",
       "      <td>Purpose: A human neck replica was made to simu...</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>Energy: Physical</td>\n",
       "      <td>...</td>\n",
       "      <td>MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['nan']</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        category_x  \\\n",
       "0  Dynamic Response of a Human Neck Replica to Ax...  Energy: Physical   \n",
       "\n",
       "   year_x schools_x                                         abstract_x  \\\n",
       "0  2014.0     set()  Purpose: A human neck replica was made to simu...   \n",
       "\n",
       "                  country_x State_x Province_x awards_x        category_y  \\\n",
       "0  United States of America      MN        NaN  ['nan']  Energy: Physical   \n",
       "\n",
       "   ...  State_y Province_y awards_y Originality ScientificRigor Clarity  \\\n",
       "0  ...       MN        NaN  ['nan']           0               4       2   \n",
       "\n",
       "  Relevance  Feasibility  Brevity  TotalScore  \n",
       "0         0            1        1           8  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge original data with evaluation results on the key column\n",
    "final_df: pd.DataFrame = df.merge(preds, on=KEY_COLUMN)\n",
    "\n",
    "# Compute total score by summing across all criteria\n",
    "final_df[\"TotalScore\"] = final_df[list(CRITERIA)].sum(axis=1)\n",
    "\n",
    "# Sort the DataFrame by total score in descending order\n",
    "final_df.sort_values(by=\"TotalScore\", ascending=False, inplace=True)\n",
    "\n",
    "# Preview the top 10 evaluated entries\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5159c9-2ea2-448f-ab19-8fe6768589d4",
   "metadata": {},
   "source": [
    "# Save Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8eb105d-0da1-4d0a-abec-35499daa74b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 12:00:09 - INFO - ✅ Evaluation results successfully saved to: ../data/outputs/Evaluated - 2025 ISEF Project Abstracts.csv - 2025-08-05 11-56-21\n"
     ]
    }
   ],
   "source": [
    "final_df.to_csv(OUTPUT_PATH, index=False)\n",
    "logger.info(f\"✅ Evaluation results successfully saved to: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff332e64-69b8-4411-a682-3f91146cc627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 12:00:09 - INFO - ⏱️ Total execution time: 3m 48.03s\n",
      "2025-08-05 12:00:09 - INFO - ✅ Notebook execution completed successfully.\n"
     ]
    }
   ],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"⏱️ Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"✅ Notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029db574-9378-4c43-90c9-ebf33cdbf551",
   "metadata": {},
   "source": [
    "Built with ❤️ using [**HP AI Studio**](https://hp.com/ai-studio)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
