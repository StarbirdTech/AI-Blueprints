import streamlit as st
import base64
import requests
import json
from pathlib import Path

st.set_page_config(page_title="ğŸ¤– Fine Tuning with Orpo", layout="centered")

st.markdown("""
Â Â Â  <style>
        .result-box {
            border: 2px solid #4e54c8;
            border-radius: 10px;
            padding: 1rem;
            margin-top: 1rem;
            background-color: #f4f6ff;
        }
Â Â Â Â Â Â Â  hr, .stHorizontalRule {
Â Â Â Â Â Â Â Â Â Â Â  border-color: rgba(0,77,204,0.20);
Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â  img[alt="HP Logo"],
Â Â Â Â Â Â Â  img[alt="AI Studio Logo"],
Â Â Â Â Â Â Â  img[alt="Z by HP Logo"] {
Â Â Â  width: 50px !important;
Â Â Â  height: auto !important;
}

Â Â Â  </style>
""", unsafe_allow_html=True)

# --- Logo ---

def uri_from(path: Path) -> str:
    return f"data:image/{path.suffix[1:].lower()};base64," + base64.b64encode(path.read_bytes()).decode()

assets = Path("assets")
hp_uri = uri_from(assets / "HP-Logo.png")
ais_uri = uri_from(assets / "AI-Studio.png")
zhp_uri = uri_from(assets / "Z-HP-logo.png")

st.markdown(f"""
Â Â Â  <div style="display:flex;justify-content:space-between;
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  align-items:center;margin-bottom:1.5rem">
Â Â Â Â Â Â Â  <img src="{hp_uri}"Â  alt="HP Logo" style="width:90px;height:auto;">
Â Â Â Â Â Â Â  <img src="{ais_uri}" alt="AI Studio Logo" style="width:90px;height:auto;">
Â Â Â Â Â Â Â  <img src="{zhp_uri}" alt="Z by HP Logo" style="width:90px;height:auto;">
Â Â Â  </div>
""", unsafe_allow_html=True)

st.title("Fine Tuning with Orpo")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1 â–¸ MLflow API Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Standardized MLflow endpoint for containerized deployment

MLFLOW_ENDPOINT = "http://localhost:5002/invocations"
api_url = MLFLOW_ENDPOINT

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2 â–¸ Main â€“Â data input
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

user_prompt = st.text_input("Add a Prompt")

user_finetuning = st.checkbox("Use Finetuning")

max_tokens = st.number_input("Tokens", value=0, step=1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3 â–¸ Call the model
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if st.button("Get response"):
    if not user_prompt or not max_tokens:
        st.warning("âš ï¸ Please fill all the fields")
    else:
        with st.spinner("Generating response..."):
            payload = {
                "inputs":{
                    "prompt":[user_prompt],
                    "use_finetuning":[user_finetuning],
                    "max_tokens":[max_tokens]
                }
            }

           
        try:
            response = requests.post(api_url, json=payload, verify=False)
            response.raise_for_status()
            data = response.json()
            
            # Extract the actual string from the list of dictionaries
            raw_response = data.get("predictions")[0].get("response")
            
            # Replace newline characters with <br>
            formatted_response = raw_response.replace("\n", "<br>")
            
            if formatted_response:
                st.success("âœ… Here is your response!")
                st.markdown(f'<div class="result-box">{formatted_response}</div>', unsafe_allow_html=True)
            else:
                st.error("âŒ Unexpected response format. Please try again.")
        except requests.exceptions.RequestException as e:
            st.error("âŒ Error fetching response.")
            st.error(str(e))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4 â–¸ Footer
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown(
"""
> Built with â¤ï¸ using HP AI Studio.
""",
unsafe_allow_html=True,
)