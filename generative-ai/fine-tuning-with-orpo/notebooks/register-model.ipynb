{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "# Configure logger\n",
    "logger: logging.Logger = logging.getLogger(\"register_model_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent duplicate logs from parent loggers\n",
    "\n",
    "# Set formatter\n",
    "formatter: logging.Formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Configure and attach stream handler\n",
    "stream_handler: logging.StreamHandler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9dc43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()  \n",
    "\n",
    "logger.info(\"Model registration notebook execution started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9162d3a3",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-size: 50px;\"> Fine-Tuned Model Registration Service </h1>\n",
    "\n",
    "This notebook demonstrates how to register a fine-tuned LLM comparison service that allows switching between base and fine-tuned models through a single MLflow endpoint. This follows the same pattern used across all AI-Blueprints for consistent model deployment and serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d2e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5add58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import warnings\n",
    "import mlflow\n",
    "\n",
    "# Add the core directory to the path to import utils\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# ===============================\n",
    "# üöÄ Deployment & Registration\n",
    "# ===============================\n",
    "from core.deploy.deploy_fine_tuning import register_llm_comparison_model\n",
    "\n",
    "# ===============================\n",
    "# ‚öôÔ∏è Utility Functions\n",
    "# ===============================\n",
    "from src.utils import (\n",
    "    load_config_and_secrets,\n",
    "    configure_proxy,\n",
    "    get_configs_dir,\n",
    "    get_fine_tuned_models_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c53dba",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Python warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration paths and parameters\n",
    "CONFIG_PATH = str(get_configs_dir() / \"config.yaml\")\n",
    "SECRETS_PATH = str(get_configs_dir() / \"secrets.yaml\")\n",
    "MLFLOW_EXPERIMENT_NAME = \"AIStudio-Fine-Tuning-Experiment\"\n",
    "MODEL_SERVICE_RUN_NAME = \"AIStudio-Fine-Tuning-Service-Run\"\n",
    "MODEL_SERVICE_NAME = \"AIStudio-Fine-Tuning-Model\"\n",
    "\n",
    "# Model configuration - update these based on your training\n",
    "BASE_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # Update to match your base model\n",
    "FINE_TUNED_MODEL_NAME = \"Orpo-TinyLlama-1.1B-Chat-v1.0-FT\"  # Update to match your fine-tuned model\n",
    "\n",
    "logger.info(f\"Base model: {BASE_MODEL}\")\n",
    "logger.info(f\"Fine-tuned model: {FINE_TUNED_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd99766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration and configure proxy if needed\n",
    "config, secrets = load_config_and_secrets(CONFIG_PATH, SECRETS_PATH)\n",
    "configure_proxy(config)\n",
    "\n",
    "logger.info(\"‚úÖ Configuration loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9191436c",
   "metadata": {},
   "source": [
    "## Verify Model Assets\n",
    "\n",
    "Before registering the models, let's verify that both the base model and fine-tuned model are accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18944ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_model_assets():\n",
    "    \"\"\"Verify that the required model assets are available.\"\"\"\n",
    "    \n",
    "    # Check fine-tuned model directory\n",
    "    fine_tuned_dir = get_fine_tuned_models_dir()\n",
    "    fine_tuned_path = fine_tuned_dir / FINE_TUNED_MODEL_NAME\n",
    "    \n",
    "    if fine_tuned_path.exists():\n",
    "        logger.info(f\"‚úÖ Fine-tuned model found: {fine_tuned_path}\")\n",
    "    else:\n",
    "        logger.warning(f\"‚ö†Ô∏è Fine-tuned model not found: {fine_tuned_path}\")\n",
    "        logger.info(\"Please run the run-workflow.ipynb notebook first to create the fine-tuned model\")\n",
    "        return False\n",
    "    \n",
    "    # Base model is typically a HuggingFace model ID, so we don't need to check its existence\n",
    "    logger.info(f\"‚úÖ Base model ID: {BASE_MODEL}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Verify assets\n",
    "assets_verified = verify_model_assets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df91317",
   "metadata": {},
   "source": [
    "## Model Registration Service\n",
    "\n",
    "This section demonstrates how to register the LLM comparison model that allows switching between the base and fine-tuned models through a single API endpoint. The service is automatically documented using Swagger (via MLflow) and provides:\n",
    "\n",
    "- **Base Model Inference**: Access to the original pre-trained model\n",
    "- **Fine-Tuned Model Inference**: Access to the ORPO fine-tuned model  \n",
    "- **Comparison Mode**: Switch between models using the `use_finetuning` parameter\n",
    "- **Flexible Input**: Support for custom prompts and generation parameters\n",
    "\n",
    "The registered model follows the same pattern used across all AI-Blueprints for consistent deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6afec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MLflow tracking URI and experiment\n",
    "mlflow.set_tracking_uri('/phoenix/mlflow')\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "if assets_verified:\n",
    "    try:\n",
    "        # Register the LLM comparison model\n",
    "        register_llm_comparison_model(\n",
    "            model_base_path=BASE_MODEL,\n",
    "            model_finetuned_path=FINE_TUNED_MODEL_NAME,\n",
    "            experiment=MLFLOW_EXPERIMENT_NAME,\n",
    "            run_name=MODEL_SERVICE_RUN_NAME,\n",
    "            registry_name=MODEL_SERVICE_NAME,\n",
    "            config_path=CONFIG_PATH\n",
    "        )\n",
    "        \n",
    "        logger.info(\"‚úÖ LLM comparison model registered successfully!\")\n",
    "        logger.info(f\"Model name: {MODEL_SERVICE_NAME}\")\n",
    "        logger.info(f\"Experiment: {MLFLOW_EXPERIMENT_NAME}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Failed to register comparison model: {str(e)}\")\n",
    "        logger.info(\"Please check the error details above and ensure all dependencies are installed\")\n",
    "        \n",
    "else:\n",
    "    logger.error(\"‚ùå Cannot register model - required assets not found\")\n",
    "    logger.info(\"Please run the run-workflow.ipynb notebook first to create the fine-tuned model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418bd15",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "\n",
    "Once the model is registered, you can use it through the MLflow model serving interface. Here's how to interact with the registered model:\n",
    "\n",
    "### Input Format\n",
    "The model expects a pandas DataFrame with the following columns:\n",
    "- `prompt` (string): The text prompt to generate from\n",
    "- `use_finetuning` (boolean): Whether to use the fine-tuned model (True) or base model (False)\n",
    "- `max_tokens` (integer, optional): Maximum number of tokens to generate (default: 128)\n",
    "\n",
    "### Example Usage\n",
    "```python\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "# Load the registered model\n",
    "model = mlflow.pyfunc.load_model(f\"models:/{MODEL_SERVICE_NAME}/latest\")\n",
    "\n",
    "# Create input data\n",
    "input_data = pd.DataFrame({\n",
    "    \"prompt\": [\"Explain the importance of sustainable agriculture.\"],\n",
    "    \"use_finetuning\": [True],  # Use fine-tuned model\n",
    "    \"max_tokens\": [200]\n",
    "})\n",
    "\n",
    "# Generate response\n",
    "response = model.predict(input_data)\n",
    "print(response[\"response\"].iloc[0])\n",
    "```\n",
    "\n",
    "### Comparison Mode\n",
    "You can easily compare outputs by running the same prompt with different `use_finetuning` values:\n",
    "\n",
    "```python\n",
    "# Compare base vs fine-tuned\n",
    "prompts = [\"Your test prompt here\"]\n",
    "\n",
    "for use_ft in [False, True]:\n",
    "    input_data = pd.DataFrame({\n",
    "        \"prompt\": prompts,\n",
    "        \"use_finetuning\": [use_ft],\n",
    "        \"max_tokens\": [150]\n",
    "    })\n",
    "    response = model.predict(input_data)\n",
    "    model_type = \"Fine-tuned\" if use_ft else \"Base\"\n",
    "    print(f\"{model_type} Model: {response['response'].iloc[0]}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"‚è±Ô∏è Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"‚úÖ Model registration notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4483b4c0",
   "metadata": {},
   "source": [
    "Built with ‚ù§Ô∏è using [**HP AI Studio**](https://hp.com/ai-studio)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
