{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f8d3ca-e260-4d56-967d-dc4feb92e2e4",
   "metadata": {},
   "source": [
    "<h1 style=\\\"text-align: center; font-size: 50px;\\\"> <h1 style=\\\"text-align: center; font-size: 50px;\\\"> 📦 Register Model </h1> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74217537-b174-49e0-b746-f3c53b5b0043",
   "metadata": {},
   "source": [
    "📘 Project Overview: \n",
    " This notebook demonstrates a modular architecture for answering natural language questions \n",
    " over one or more feedback documents using only local and open-source models (e.g., LLaMA.cpp).\n",
    " The system processes long documents chunk-by-chunk and synthesizes a final answer using a multi-step LLM workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f858ca",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "- Start Execution\n",
    "- Define User Constants\n",
    "- Install and Import Libraries\n",
    "- Configure Settings\n",
    "- Verify Assets\n",
    "- KV Memory\n",
    "- LLM Setup\n",
    "- State Model\n",
    "- Node Functions\n",
    "- Graph Definition\n",
    "- Graph Visualization\n",
    "- Generated Answer\n",
    "- Message History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a533df-f921-4f06-9197-9e33b9e5c799",
   "metadata": {},
   "source": [
    "# Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "490becc1-2ff2-4273-a49f-0fdacf30c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────── Standard Library Imports ───────\n",
    "import os  # OS-level utilities like path and environment operations\n",
    "import sys  # Access to interpreter variables and runtime configuration\n",
    "import time  # Time-related functions\n",
    "\n",
    "# Extend sys.path to include parent directory for local module resolution\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# ─────── Local Application Imports ───────\n",
    "from src.utils import (  # Core utilities for logging, LLM interaction, and schema generation\n",
    "    display_image,\n",
    "    get_response_from_llm,\n",
    "    json_schema_from_type,\n",
    "    log_timing,\n",
    "    logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d77c68-e160-4c24-9844-de484272733e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:43:41 - INFO - Notebook execution started.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()  \n",
    "logger.info(\"Notebook execution started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84444adc-85c6-45cd-8769-7159e29fbace",
   "metadata": {},
   "source": [
    "# Define User Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21d3385-704e-4107-ae45-749decdd305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC: str = \"Focus Flow\"  \n",
    "QUESTION: str = \"Which poeple provided the feedback?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7b5e0-2acd-4729-b8a2-03e81cf0df2d",
   "metadata": {},
   "source": [
    "# Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b876fc6-cbb8-4330-9529-d2936b202d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CPU times: user 18.3 ms, sys: 0 ns, total: 18.3 ms\n",
      "Wall time: 991 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b95da1c-2715-497b-b1e0-2aaefe09dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations  # Enables postponed evaluation of type annotations (PEP 563)\n",
    "\n",
    "# ─────── Standard Library Imports ───────\n",
    "import base64  # Encoding and decoding binary data\n",
    "import functools  # Functional programming utilities like lru_cache, partial, etc.\n",
    "import json  # JSON serialization and deserialization\n",
    "import logging  # Logging framework\n",
    "import multiprocessing  # Parallel execution using subprocesses\n",
    "import os  # OS-level utilities\n",
    "import shutil  # File and directory operations\n",
    "import sys  # Access to runtime environment and system-specific parameters\n",
    "import time  # Time tracking and delays\n",
    "import warnings  # Warning control and filtering\n",
    "from collections import namedtuple  # Lightweight object types\n",
    "from pathlib import Path  # Object-oriented filesystem paths\n",
    "from typing import Any, Dict, List, Literal, Optional, TypedDict  # Static typing annotations\n",
    "\n",
    "# ─────── Third-Party Package Imports ───────\n",
    "import mlflow  # Model tracking and serving framework\n",
    "from mlflow.tracking import MlflowClient  # Interface to interact with MLflow tracking server for experiments, runs, and artifacts\n",
    "import yaml  # YAML file parsing\n",
    "from IPython.display import HTML, display, Markdown  # Rich output formatting in Jupyter environments\n",
    "from tqdm import tqdm  # Progress bar for loops\n",
    "\n",
    "# ─────── LangChain Core & Community Imports ───────\n",
    "from langchain.docstore.document import Document  # Document abstraction\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Intelligent text splitting\n",
    "from langchain_community.document_loaders import (  # Document loaders for different file types\n",
    "    CSVLoader,\n",
    "    PyPDFLoader,\n",
    "    TextLoader,\n",
    "    UnstructuredExcelLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    "    UnstructuredWordDocumentLoader,\n",
    ")\n",
    "from langchain_community.llms import LlamaCpp  # Integration for running LlamaCpp locally\n",
    "\n",
    "# ─────── LangGraph Imports ───────\n",
    "from langgraph.graph import END, START, StateGraph  # Constructs and controls stateful agent graphs\n",
    "\n",
    "# ─────── Local Application-Specific Imports ───────\n",
    "from src.agentic_feedback_model import AgenticFeedbackModel  # Core agent logic for feedback analysis\n",
    "from src.simple_kv_memory import SimpleKVMemory  # In-memory store for agent state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14909251-86d2-4eff-b15e-4a8c4cbddc61",
   "metadata": {},
   "source": [
    "# Configure Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27be6c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Python warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b49f4d0-7662-43ce-ae95-59c13af024bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH: Path = Path(\"../data/input\")  \n",
    "\n",
    "MEMORY_PATH: Path = Path(\"../data/memory\")   \n",
    "\n",
    "MODEL_PATH = \"/home/jovyan/datafabric/meta-llama3.1-8b-Q8/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\"\n",
    "CONTEXT_WINDOW = 8192\n",
    "MAX_TOKENS = CONTEXT_WINDOW // 8\n",
    "CHUNK_SIZE = CONTEXT_WINDOW // 2\n",
    "CHUNK_OVERLAP = CHUNK_SIZE // 8  \n",
    "\n",
    "EXPERIMENT_NAME = \"AIStudio-Agentic-Customer-Feedback-Analyzer-with-LangGraph-Experiment\"\n",
    "RUN_NAME = \"AIStudio-Agentic-Customer-Feedback-Analyzer-with-LangGraph-Run\"\n",
    "MODEL_NAME = \"AIStudio-Agentic-Customer-Feedback-Analyzer-with-LangGraph-Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c8dc01-e50f-4077-9056-b966895ad8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:43:45 - INFO - Notebook execution started.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.info('Notebook execution started.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dad079",
   "metadata": {},
   "source": [
    "## Verify Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98593ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_asset_status(asset_path: str, asset_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Logs the status of a given asset based on its existence.\n",
    "\n",
    "    Parameters:\n",
    "        asset_path (str): File or directory path to check.\n",
    "        asset_name (str): Name of the asset for logging context.\n",
    "    \"\"\"\n",
    "    if Path(asset_path).exists():\n",
    "        logger.info(f\"{asset_name} is properly configured.\")\n",
    "    else:\n",
    "        logger.info(f\"{asset_name} is not properly configured. Please ensure the required asset is correctly configured in your AI Studio project according to the README file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61dd389c-4a0c-421f-9f29-fe9080aec9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:43:45 - INFO - Input Data is properly configured.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:43:45 - INFO - LLM is properly configured.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_asset_status(\n",
    "    asset_path=INPUT_PATH,\n",
    "    asset_name=\"Input Data\",\n",
    ")\n",
    "log_asset_status(\n",
    "    asset_path=MODEL_PATH,\n",
    "    asset_name=\"LLM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5f0b3a-b878-4528-99f9-64678ae273bf",
   "metadata": {},
   "source": [
    "# KV Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa0e3126-b7c4-407f-82ac-73955213f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory: SimpleKVMemory = SimpleKVMemory(MEMORY_PATH)\n",
    "memory.set('dummy key', 'dummy value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ec21b-ac6e-44c8-ba14-955edb9ddab3",
   "metadata": {},
   "source": [
    "# Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da62e7ed-cd98-46a3-a954-a7a3cf39d8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:43:45 - INFO - 📂 Scanning directory for documents: ../data/input\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:43:45 - INFO - ✅ Loaded 1 docs from csv.csv\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "short text: \"docx test\". Defaulting to English.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:43:47 - INFO - ✅ Loaded 1 docs from docx.docx\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "short text: \"md test\". Defaulting to English.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:43:47 - INFO - ✅ Loaded 1 docs from md.md\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:43:47 - INFO - ✅ Loaded 1 docs from pdf.pdf\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:43:47 - INFO - ✅ Loaded 1 docs from sample-product-feedback-doc.md\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:43:47 - INFO - ✅ Loaded 1 docs from txt.txt\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "short text: \"excel test excel test\". Defaulting to English.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:43:48 - INFO - ✅ Loaded 1 docs from xlsx.xlsx\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.info(\"📂 Scanning directory for documents: %s\", INPUT_PATH)\n",
    "\n",
    "supported_extensions = {\n",
    "\".txt\": TextLoader,\n",
    "\".csv\": lambda path: CSVLoader(path, encoding=\"utf-8\", csv_args={\"delimiter\": \",\"}),\n",
    "\".xlsx\": UnstructuredExcelLoader,\n",
    "\".docx\": UnstructuredWordDocumentLoader,\n",
    "\".pdf\": PyPDFLoader,\n",
    "\".md\": UnstructuredMarkdownLoader,\n",
    "}\n",
    "\n",
    "all_docs = []\n",
    "\n",
    "for file_path in Path(INPUT_PATH).rglob(\"*\"):\n",
    "    # Skip hidden/system folders\n",
    "    if any(part.startswith(\".\") and part not in {\".\", \"..\"} for part in file_path.parts):\n",
    "        continue\n",
    "    \n",
    "    ext = file_path.suffix.lower()\n",
    "    loader_class = supported_extensions.get(ext)\n",
    "    \n",
    "    if loader_class:\n",
    "        try:\n",
    "            loader = loader_class(str(file_path))\n",
    "            docs = loader.load()\n",
    "            all_docs.extend(docs)\n",
    "            logger.info(\"✅ Loaded %d docs from %s\", len(docs), file_path.name)\n",
    "        except Exception as e:\n",
    "            logger.warning(\"❌ Failed to load %s: %s\", file_path.name, e)\n",
    "    else:\n",
    "        logger.info(\"⚠️ Unsupported file type: %s\", file_path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f2df425-9816-4337-b573-e8ecb48a122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TEXT = '\\n\\n'.join([doc.page_content for doc in all_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e9213-a911-400f-a79f-b8fe944b887d",
   "metadata": {},
   "source": [
    "# MLflow Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "914f9774-40d1-4186-a16a-1b7bc22d7858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLflow tracking URI: /phoenix/mlflow\n",
      "Experiment: AIStudio-Agentic-Customer-Feedback-Analyzer-with-LangGraph-Experiment\n"
     ]
    }
   ],
   "source": [
    "# 1. Set MLflow tracking URI and experiment\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\", \"/phoenix/mlflow\"))\n",
    "mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "print(f\"Using MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1c56599-743c-4ded-a3c9-4f03c0fbb04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/02 06:43:49 INFO mlflow.models.signature: Inferring model signature from type hints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Started MLflow run: e015ccbb3a024c3e9ab35a177ab9d238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c424f3037b145a981b31fb2441ad4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012591891e464dd99bf0a6fa5f7386b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'AIStudio-Agentic-Customer-Feedback-Analyzer-with-LangGraph-Model'.\n",
      "Created version '1' of model 'AIStudio-Agentic-Customer-Feedback-Analyzer-with-LangGraph-Model'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:47:52 - INFO - ✅ Model 'AIStudio-Agentic-Customer-Feedback-Analyzer-with-LangGraph-Model' successfully logged and registered.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 s, sys: 15.7 s, total: 16.7 s\n",
      "Wall time: 4min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# These should point to the actual files you're using for model and memory\n",
    "MODEL_ARTIFACTS = {\n",
    "    \"model_path\": str(MODEL_PATH),\n",
    "    \"memory_path\": str(MEMORY_PATH),\n",
    "}\n",
    " \n",
    "# === Start MLflow run, log, and register ===\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    print(f\"🚀 Started MLflow run: {run.info.run_id}\")\n",
    "\n",
    "    # Log and register the model using the classmethod\n",
    "    AgenticFeedbackModel.log_model(\n",
    "        model_name=MODEL_NAME,\n",
    "        model_artifacts=MODEL_ARTIFACTS\n",
    "    )\n",
    "\n",
    "logger.info(f\"✅ Model '{MODEL_NAME}' successfully logged and registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "139d19b6-c12f-4cdd-84eb-4ecd2466330a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:47:52 - INFO - Latest registered version of 'AIStudio-Agentic-Customer-Feedback-Analyzer-with-LangGraph-Model': 1\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:47:52 - INFO - Signature: inputs: \n",
       "  [{input_text: string (required), question: string (required), topic: string (required)} (required)]\n",
       "outputs: \n",
       "  [{answer: string (required), messages: string (required)} (required)]\n",
       "params: \n",
       "  None\n",
       "\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Retrieve the latest version from the Model Registry\n",
    "client = MlflowClient()\n",
    "versions = client.get_latest_versions(MODEL_NAME, stages=[\"None\"])\n",
    "\n",
    "if not versions:\n",
    "    raise RuntimeError(f\"No registered versions found for model '{MODEL_NAME}'.\")\n",
    "    \n",
    "latest_version = versions[0].version\n",
    "model_info = mlflow.models.get_model_info(f\"models:/{MODEL_NAME}/{latest_version}\")\n",
    "\n",
    "logger.info(f\"Latest registered version of '{MODEL_NAME}': {latest_version}\")\n",
    "logger.info(f\"Signature: {model_info.signature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "051d1f33-6f06-4c07-a7e3-dd60e478f95a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:05 - INFO - Successfully loaded model 'AIStudio-Agentic-Customer-Feedback-Analyzer-with-LangGraph-Model' version 1 for inference.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 2.34 s, total: 3.56 s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 4. Load the model from the Model Registry\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri=f\"models:/{MODEL_NAME}/{latest_version}\")\n",
    "logger.info(f\"Successfully loaded model '{MODEL_NAME}' version {latest_version} for inference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f9435e6-b591-416a-b263-b2432e61f0b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Sample Inference ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:05 - INFO - 🗣️ Ingested user question: Which poeple provided the feedback?\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:05 - INFO - Function 'ingest_question' took 0.0015 seconds.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:15 - INFO - 🧠 Relevance response: yes → Relevant\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:15 - INFO - Function 'check_relevance' took 9.8045 seconds.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:15 - INFO - 🧭 Cache miss for question: Which poeple provided the feedback?\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:15 - INFO - Function 'check_memory' took 0.0010 seconds.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:15 - INFO - ✏️ Rewritten user question:\n",
       "→ Who are the individuals mentioned in the document as providing feedback?\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:15 - INFO - Function 'rewrite_question' took 0.5131 seconds.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:15 - INFO - 📑 Starting chunking for 1 loaded documents\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:15 - INFO - 🧩 Created 2 total chunks (size=4096, overlap=256)\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:15 - INFO - Function 'create_chunks' took 0.0032 seconds.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:15 - INFO - 🧩 Generating answers for 2 chunks using rewritten question: 'Who are the individuals mentioned in the document as providing feedback?'\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔁 Processing each chunk: 100%|██████████| 2/2 [00:01<00:00,  1.96it/s, group=✅ Chunk 2 response length: 28 chars]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:16 - INFO - 🧠 Finished generating 2 chunk-level responses.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:16 - INFO - Function 'generate_answer_per_chunks' took 1.0253 seconds.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:16 - INFO - 🧠 Synthesizing across 1 chunk groups\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:16 - INFO - 🧠 Synthesizing final answer from 2 chunk responses\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🔁 Processing each grouped chunk answers: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it, group=🧠 Synthesized partial answer (1/1)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:18 - INFO - ✅ Synthesized 1 group-level summaries.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:18 - INFO - Function 'generate_synthetized_answer' took 1.3871 seconds.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:18 - INFO - 💾 Stored question-answer pair in memory (key: which poeple provided the feedback?)\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:18 - INFO - Function 'update_memory' took 0.0227 seconds.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔚 === Final Answer ===\n",
      "\n",
      "# 🧠 Synthesized partial answer (1/1)\n",
      "\n",
      "Since the user's question is about individuals mentioned in the document as providing feedback, and neither Chunk 1 nor Chunk 2 mentions any individuals providing feedback, the final answer is:\n",
      "\n",
      "**No individuals are mentioned in the document as providing feedback.**\n",
      "\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:18 - INFO - 📤 Delivered final answer (304 characters)\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:18 - INFO - Function 'output_answer' took 0.0012 seconds.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Run a sample inference using the loaded model\n",
    "input_payload = [{\"topic\": TOPIC, \"question\": QUESTION, \"input_text\": INPUT_TEXT, }]\n",
    "\n",
    "print(\"\\n=== Running Sample Inference ===\")\n",
    "results = loaded_model.predict(input_payload)\n",
    "result = results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d05ba-ed68-46a5-971a-491ffb93c17a",
   "metadata": {},
   "source": [
    "# Generated Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3216c60d-5bfe-405f-868c-bf353d3609f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# 🧠 Synthesized partial answer (1/1)\n",
       "\n",
       "Since the user's question is about individuals mentioned in the document as providing feedback, and neither Chunk 1 nor Chunk 2 mentions any individuals providing feedback, the final answer is:\n",
       "\n",
       "**No individuals are mentioned in the document as providing feedback.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result.answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16159a90-d40d-4d20-b9e6-57cb3bd14cf3",
   "metadata": {},
   "source": [
    "# Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "370f4cac-c92f-4f8b-b2e5-10cd12e08a87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"role\": \"developer\",\n",
      "        \"content\": \"User submitted a question.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"Which poeple provided the feedback?\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"developer\",\n",
      "        \"content\": \"\\ud83e\\udde0 Relevance check result:\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"yes\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"developer\",\n",
      "        \"content\": \"\\ud83e\\udded No cached answer found for question: 'Which poeple provided the feedback?'\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"developer\",\n",
      "        \"content\": \"\\u270f\\ufe0f Rewritten user question:\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Who are the individuals mentioned in the document as providing feedback?\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"developer\",\n",
      "        \"content\": \"\\ud83e\\udde9 Chunked 1 documents into 2 chunks (size=4096, overlap=256)\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"developer\",\n",
      "        \"content\": \"\\ud83e\\udde0 Processed 2 chunks for question: 'Who are the individuals mentioned in the document as providing feedback?'\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"developer\",\n",
      "        \"content\": \"\\u2705 Synthesized 1 group-level summaries.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"# \\ud83e\\udde0 Synthesized partial answer (1/1)\\n\\nSince the user's question is about individuals mentioned in the document as providing feedback, and neither Chunk 1 nor Chunk 2 mentions any individuals providing feedback, the final answer is:\\n\\n**No individuals are mentioned in the document as providing feedback.**\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"developer\",\n",
      "        \"content\": \"\\ud83d\\udcbe Stored answer in memory for question key: 'which poeple provided the feedback?'\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"developer\",\n",
      "        \"content\": \"\\ud83d\\udce4 Final answer delivered: # \\ud83e\\udde0 Synthesized partial answer (1/1)\\n\\nSince the user's question is about individuals mentioned in the document as providing feedback, and neither Chunk 1 nor Chunk 2 mentions any individuals providing feedback, the final answer is:\\n\\n**No individuals are mentioned in the document as providing feedback.**\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(result.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1723e941-2523-4db6-ab89-fedffbc0be0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:18 - INFO - ⏱️ Total execution time: 5m 36.38s\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #228B22; color: white;\n",
       "                    padding: 4px 8px; font-family: monospace; border-radius: 4px;\">\n",
       "            ✅ 2025-08-02 06:49:18 - INFO - ✅ Notebook execution completed successfully.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"⏱️ Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"✅ Notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c45acb",
   "metadata": {},
   "source": [
    "Built with ❤️ using [**HP AI Studio**](https://hp.com/ai-studio)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
