{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31714085-065e-47da-bb2c-3c80ff88f6c8",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-size: 50px;\">Scientific Presentation Script Generator with Local LLM & ChromaDB</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438b733e",
   "metadata": {},
   "source": [
    "## üéØ **Overview**\n",
    "\n",
    "This notebook demonstrates how to build a comprehensive **Scientific Presentation Script Generator** using:\n",
    "\n",
    "- **arXiv Paper Retrieval**: Search and download academic papers  \n",
    "- **Document Processing**: Text extraction and chunking for optimal processing  \n",
    "- **Vector Database**: ChromaDB for semantic search and retrieval  \n",
    "- **Local LLM Integration**: Meta Llama 3.1 model for analysis and generation  \n",
    "- **Interactive Generation**: Step-by-step script creation with user approval  \n",
    "\n",
    "**Pipeline Flow**: arXiv ‚Üí Text Extraction ‚Üí Vector Storage ‚Üí Analysis ‚Üí Script Generation ‚Üí Interactive Refinement\n",
    "\n",
    "---\n",
    "\n",
    "## üõ† **What You'll Learn**\n",
    "\n",
    "- Paper retrieval from arXiv using search queries  \n",
    "- Text extraction and chunking strategies  \n",
    "- Vector database setup with ChromaDB  \n",
    "- LLM configuration for local inference  \n",
    "- Script generation and evaluation workflows  \n",
    "- MLflow model registration and deployment  \n",
    "\n",
    "---\n",
    "\n",
    "## üìã **Prerequisites**\n",
    "\n",
    "- LangChain setup and configuration  \n",
    "- Vector database fundamentals  \n",
    "- Basic understanding of embeddings and retrieval systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb6d677-8e73-411d-828e-a63f70edb461",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "This step installs the necessary libraries for local LLM processing and document analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6521a055-e62f-45bd-ba11-ff3104cdbafa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdf4a81-6b8c-41c9-a107-aad52d5583ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:137: FutureWarning: Model's `predict` method contains invalid parameters: {'df', '_'}. Only the following parameter names are allowed: context, model_input, and params. Note that invalid parameters will no longer be permitted in future versions.\n",
      "  param_names = _check_func_signature(func, \"predict\")\n"
     ]
    }
   ],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import mlflow\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "# Add the src directory to the path to import utils\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from src.utils import configure_hf_cache\n",
    "from src.utils import configure_proxy\n",
    "from src.utils import load_config_and_secrets\n",
    "from src.utils import initialize_llm\n",
    "\n",
    "# Import transformers from huggingface\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# Import components of notebook\n",
    "from core.extract_text.arxiv_search import ArxivSearcher\n",
    "from core.generator.script_generator import ScriptGenerator\n",
    "from core.analyzer.scientific_paper_analyzer import ScientificPaperAnalyzer\n",
    "from core.deploy.text_generation_service import TextGenerationService\n",
    "\n",
    "# Import langchain libraries\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEndpoint\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "# Libraries from python\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686a593c",
   "metadata": {},
   "source": [
    "## Configurations and Secrets Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073ab4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Python warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "150df526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create logger ===\n",
    "logger = logging.getLogger(\"text-generation-notebook\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", \n",
    "                             datefmt=\"%Y-%m-%d %H:%M:%S\") \n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a7b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ML and data processing\n",
    "import mlflow\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from operator import itemgetter\n",
    "\n",
    "# === Project-Specific Imports (from src.utils) ===\n",
    "from src.utils import (\n",
    "    load_config_and_secrets,\n",
    "    configure_proxy,\n",
    "    initialize_llm,\n",
    "    login_huggingface,\n",
    "    clean_code,\n",
    "    generate_code_with_retries,\n",
    "    get_model_context_window,\n",
    "    get_context_window,\n",
    "    dynamic_retriever,\n",
    "    format_docs_with_adaptive_context,\n",
    "    estimate_tokens_accurate\n",
    ")\n",
    "\n",
    "# === Core Module Imports ===\n",
    "from core.extract_text.arxiv_search import ArxivSearcher\n",
    "from core.analyzer.scientific_paper_analyzer import ScientificPaperAnalyzer\n",
    "from core.generator.script_generator import ScriptGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ef827b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac48c2a7-503f-4e9b-b7cb-1523277b952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, secrets = load_config_and_secrets(CONFIG_PATH, SECRETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596cf12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:24:22 - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "# Initialize logging for notebook execution\n",
    "logger.info('Notebook execution started - Local text generation pipeline')\n",
    "logger.info('All dependencies loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4754b897",
   "metadata": {},
   "source": [
    "### Verify Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b15966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:24:22 - INFO - local llama model is properly configured. \n",
      "2025-07-01 19:24:22 - INFO - Config is properly configured. \n",
      "2025-07-01 19:24:22 - INFO - Secrets is properly configured. \n"
     ]
    }
   ],
   "source": [
    "# Load configuration and secrets\n",
    "config, secrets = load_config_and_secrets()\n",
    "\n",
    "# Configure proxy if specified in config\n",
    "configure_proxy(config)\n",
    "\n",
    "print(\"‚úÖ Configuration loaded successfully.\")\n",
    "print(f\"üìÅ Model source: {config.get('model_source', 'local')}\")\n",
    "\n",
    "# Setup HuggingFace authentication if available\n",
    "if \"HUGGINGFACE_API_KEY\" in secrets:\n",
    "    try:\n",
    "        login_huggingface(secrets)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è HuggingFace login failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No HuggingFace API key found - using models without authentication\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb301df",
   "metadata": {},
   "source": [
    "### Proxy Configuration\n",
    "\n",
    "For certain enterprise networks, you might need to configure proxy settings to access external services. If this is your case, set up the \"proxy\" field in your config.yaml and the following cell will configure the necessary environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488a1d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_proxy(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e98e41",
   "metadata": {},
   "source": [
    "### Configuration of Hugging face caches\n",
    "\n",
    "In the next cell, we configure HuggingFace cache, so that all the models downloaded from them are persisted locally, even after the workspace is closed. This is a future desired feature for AI Studio and the GenAI addon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bce2146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure HuggingFace cache\n",
    "configure_hf_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "739ef1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:24:23,473 | INFO | PyTorch version 2.7.0 available.\n",
      "2025-07-01 19:24:24,368 | INFO | Use pytorch device_name: cuda\n",
      "2025-07-01 19:24:24,370 | INFO | Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "# Initialize HuggingFace Embeddings\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c24c88-59aa-4d2b-a7fa-674e9130e2c7",
   "metadata": {},
   "source": [
    "## üéØ Step 4: Script Generation and Evaluation\n",
    "\n",
    "### Interactive Script Generation\n",
    "\n",
    "The ScriptGenerator orchestrates the prompt flow, allowing users to generate each section of the presentation interactively, with built-in approval workflows for quality control.\n",
    "\n",
    "**Key Features:**\n",
    "- **Interactive Approval**: Review and approve each generated section  \n",
    "- **Iterative Refinement**: Regenerate content until satisfied  \n",
    "- **Structured Output**: Organized presentation script format  \n",
    "- **Context-Aware Generation**: Uses analyzed content for accurate scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9034bdfe-71a7-47fa-85d0-dae9ad26f53f",
   "metadata": {},
   "source": [
    "### 1. ‚úÖ **Local LLM Initialization**\n",
    "\n",
    "Initialize the local language model for content analysis and script generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678462e-7d6b-4c77-9b69-b6029239522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:24:38,277 | INFO | Extracted text from 'Lost in Translation: Large Language Models in Non-English Content\n",
      "  Analysis':\n",
      "Lost in Translation\n",
      "May 2023\n",
      "A report from\n",
      "Gabriel Nicholas\n",
      "Aliya Bhatia\n",
      "Large Language Models in \n",
      "Non-English Content Analysis\n",
      "GABRIEL NICHOLAS\n",
      "Research Fellow at the Center for Democracy & Technology.\n",
      "ALIYA BHATIA\n",
      "Policy Analyst, Free Expression Project at the Center for \n",
      "Democracy & Technology.\n",
      "T...\n",
      "\n",
      "2025-07-01 19:24:38,987 | INFO | Extracted text from 'Cedille: A large autoregressive French language model':\n",
      "CEDILLE:\n",
      "A LARGE AUTOREGRESSIVE LANGUAGE MODEL IN FRENCH\n",
      "Martin M√ºller‚àó\n",
      "Florian Laurent‚àó\n",
      "Cedille AI1\n",
      "hello@cedille.ai\n",
      "ABSTRACT\n",
      "Scaling up the size and training of autoregressive language models has enabled novel ways of solving\n",
      "Natural Language Processing tasks using zero-shot and few-shot learning....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration is already loaded - no additional setup needed\n",
    "print(\"‚úÖ Environment configured for local LLM processing\")\n",
    "print(\"üîß Ready to proceed with document analysis and script generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9286a-6f07-489f-bd77-2275deed3ad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Lost in Translation: Large Language Models in Non-English Content\\n  Analysis',\n",
       "  'text': 'Lost in Translation\\nMay 2023\\nA report from\\nGabriel Nicholas\\nAliya Bhatia\\nLarge Language Models in \\nNon-English Content Analysis\\nGABRIEL NICHOLAS\\nResearch Fellow at the Center for Democracy & Technology.\\nALIYA BHATIA\\nPolicy Analyst, Free Expression Project at the Center for \\nDemocracy & Technology.\\nThe Center for Democracy & Technology (CDT) is the leading \\nnonpartisan, nonprofit organization fighting to advance civil rights and \\ncivil liberties in the digital age. We shape technology policy, governance, \\nand design with a focus on equity and democratic values. Established in \\n1996, CDT has been a trusted advocate for digital rights since the earliest \\ndays of the internet. The organization is headquartered in Washington, \\nD.C., and has a Europe Office in Brussels, Belgium.\\nA report from\\nGabriel Nicholas and Aliya Bhatia\\nWITH CONTRIBUTIONS BY\\nSamir Jain, Mallory Knodel, Emma Llans√≥, Michal Luria, Nathalie Mar√©chal, Dhanaraj Thakur, and \\nCaitlin Vogus.\\nACKNOWLEDGMENTS \\nWe thank Pratik Joshi, Sebastin Santy, and Aniket Kesari for their invaluable feedback on the technical \\naspects of this report. We also thank Jacqueline Rowe, Damini Satija, and √Ångel D√≠az for their \\ninsightful comments and suggestions. The translation of our executive summary is made possible by \\nGlobal Voices Translations and with the help of Iverna McGowan, Maria Villamar, Oph√©lie Stockhem, \\nand Tom√°s Pomar. All views in this report are those of CDT. \\nThis work is made possible through a grant from the John S. and James L. Knight Foundation.\\nSuggested Citation: Nicholas, G. and Bhatia, A. (2023) Lost in Translation: Large Language Models \\nin Non-English Content Analysis. Center for Democracy & Technology. https://cdt.org/insights/lost-\\nin-translation-large-language-models-in-non-english-content-analysis/\\nReferences in this report include original links and links archived and shortened by the Perma.cc service. \\nThe Perma.cc links also contain information on the date of retrieval and archive. \\nThis report is licensed under a Creative Commons Attribution 4.0 International License.\\nLost in Translation\\nLarge Language Models in Non-\\nEnglish Content Analysis\\nLost in Translation\\nCDT Research\\n4\\nCDT Research\\n4\\nContents\\nExecutive Summary\\x08\\n5\\nIntroduction\\x08\\n8\\nI.\\t Background\\x08\\n12\\nA. How Large Language Models Work\\x08\\n12\\nB. The Resourcedness Gap: Why the Largest Language \\nModels are in English\\x08\\n15\\nC. Multilingual Language Models: Efforts to Bridge the \\nResourcedness Gap\\x08\\n19\\nII.\\t Limitations of Language Models in English and \\nNon-English Contexts\\x08\\n23\\nA. Concerns with Building and Deploying Large \\nLanguage Models\\x08\\n23\\nB. Limitations of Multilingual Language Models\\x08\\n25\\nIII.\\tRecommendations\\x08\\n31\\nA. Companies\\x08\\n31\\nB. Researchers and Funders\\x08\\n33\\nC. Governments\\x08\\n36\\nWorks Cited\\x08\\n39\\n5\\nLost in Translation\\nExecutive \\nSummary\\nT\\nhe internet is the primary source of information, economic \\nopportunity, and community for many around the world. \\nHowever, the automated systems that increasingly mediate our \\ninteractions online ‚Äî such as chatbots, content moderation \\nsystems, and search engines ‚Äî are primarily designed for and work far \\nmore effectively in English than in the world‚Äôs other 7,000 languages.\\nIn recent years, large language models have become the dominant \\napproach for building AI systems to analyze and generate language \\nonline, but again, they have been built primarily for the English \\nlanguage. A large language model (e.g., Open AI‚Äôs GPT-4, Meta‚Äôs \\nLLaMa, Google‚Äôs PaLM) is a machine learning algorithm that scans \\nenormous volumes of text to learn which words and sentences \\nfrequently appear near one another and in what context. Large language \\nmodels can be adapted to perform a wide range of tasks across different \\ndomains. They are most known for being used to build chatbots, \\nsuch as ChatGPT, but researchers and technology companies also \\nuse them for content analysis tasks, such as sentiment analysis, text \\nsummarization, and hate speech detection. Google, Meta, Microsoft, \\nand other companies have already incorporated large language models \\ninto their core product functions, such as content moderation and \\nsearch. Other vendors soon may incorporate them into automated \\ndecision-making systems, such as resume scanners.\\nRecently though, researchers and technology companies have attempted \\nto extend the capabilities of large language models into languages other \\nthan English by building what are called multilingual language models. \\nInstead of being trained on text from only one language, multilingual \\nlanguage models are trained on text from dozens or hundreds of \\nlanguages at once. Researchers posit that multilingual language models \\ninfer connections between languages, allowing them to apply word \\nassociations and underlying grammatical rules learned from languages \\nwith more text data available to train on (in particular English) to \\nthose with less. In some applications, multilingual language models \\noutperform models trained on only one language ‚Äî for instance, a \\nmodel trained on lots of text from lots of languages, including Hindi, \\nmight perform better in Hindi contexts than a model just trained on \\nHindi text.\\nMultilingual language models give technology companies a way to scale \\ntheir AI systems to many languages at once, and some have already \\nbegun to integrate them into their products. Online service providers \\nin particular have deployed multilingual language models to moderate\\nLost in Translation\\nCDT Research\\n6\\ncontent: Meta uses a multilingual language model to detect harmful content on its \\nplatforms in over 100 languages; Alphabet‚Äôs Perspective API uses one to detect toxic \\ncontent in eighteen different languages; Bumble uses one to detect and take action on \\nunwanted sexual messages around the world.\\nMultilingual language models allow technologists to attempt to build models in languages \\nfor which they otherwise might not have enough digitized text. Languages vary widely \\nin resourcedness, or the volume, quality, and diversity of text data they have available to \\ntrain language models on. English is the highest resourced language by multiple orders of \\nmagnitude, but Spanish, Chinese, German, and a handful of other languages are sufficiently \\nhigh resource enough to build language models in. Medium resource languages, with fewer \\nbut still high-quality data sets, such as Russian, Hebrew, and Vietnamese, and low resource \\nlanguages, with almost no training data sets, such as Amharic, Cherokee, and Haitian \\nCreole, have too little text for training their own large language models. Language data in \\nlow resource languages is also often of particularly poor quality: either it is mistranslated or \\neven nonsensical language scraped from the internet, or is limited to sources with narrow \\ndomains, such as religious texts and Wikipedia. This gap in data availability between \\nlanguages is known as the resourcedness gap.\\nMultilingual language models are designed to address these gaps in data availability by \\ninferring semantic and grammatical connections between higher- and lower-resource \\nlanguages, allowing the former to bootstrap the latter. However, this architecture \\nraises its own concerns. Multilingual language models are still usually trained \\ndisproportionately on English language text and thus end up transferring values and \\nassumptions encoded in English into other language contexts where they may not \\nbelong. For example, a multilingual model might associate the word ‚Äúdove‚Äù in all \\nlanguages with ‚Äúpeace‚Äù even though the Basque word for dove (‚Äúuso‚Äù) can be an insult. \\nThe disparity in available data also means multilingual language models work far better \\nin higher resource languages and languages similar to them than lower resource ones. \\nModel developers will sometimes try to fill in these gaps with machine-translated text, \\nbut translation errors may further compound language misrepresentation. And when \\nmultilingual language models do fail, their unintuitive connections between languages \\ncan make those problems harder to identify, diagnose, and fix.\\nLarge language models‚Äô general use in content analysis raises further concerns. \\nComputational linguists argue that large language models are limited in their capacity \\nto analyze forms of expression not included in their training data, meaning they may \\nstruggle to perform in new contexts. They may also reproduce any biases present in \\ntheir training data. Often, this text is scraped from the internet, meaning that large \\nlanguage models may encode and reinforce dominant views expressed online.\\nLarge Language Models in Non-English Content Analysis\\n7\\n\\u200bCompanies, researchers, and governments each have a role to play in protecting the \\npublic from the potential dangers of multilingual language model content analysis \\nsystems. To ensure better public accountability, companies that deploy large language \\nmodels should always be transparent about how they use them and in which languages. \\nCompanies should deploy language models with narrow remits and adequate channels \\nfor human review.\\nResearchers and research funders meanwhile should invest in efforts to improve the \\nuse and performance of language models in languages other than English, in particular, \\nto reduce failures that disparately impact speakers of lower-resourced languages. The \\nbest way to do this is by supporting language-specific research communities, who can \\npromote the virtuous cycle of collecting data, curating datasets, training language \\nmodels, publishing, and building applications. Local language speakers and context \\nexperts need to be part of each step of this process and also be curating the data and \\nassessing the language models deployed by large, global online services.\\nFinally, governments need to be careful about how they use or encourage the use of \\nlarge language models. Large language models should never power systems used to make \\nhigh-stakes decisions without oversight, such as decisions about immigration status or \\nhealthcare, nor should governments mandate or inadvertently require by law the use of \\nlarge language model-powered systems to moderate content from online services. Instead, \\ngovernments should convene different stakeholders to align on what norms and guardrails \\nshould be around developing and deploying large language models.\\nLarge language models in general and multilingual language models in particular \\nhave the potential to create new economic opportunities and improve the web for \\nall. However, mis- or over-application of these technologies poses real threats to \\nindividuals‚Äô rights, such as undermining their right to free expression by inaccurately \\ntaking down a person‚Äôs post on social media or their right to be free of discrimination \\nby misinterpreting an individual‚Äôs job or visa application. Multilingual language \\nmodels specifically can inadvertently further entrench the Anglocentrism they are \\nintended to address. In light of these limitations, technology companies, researchers, \\nand governments must consider potential human and civil rights risks when studying, \\nprocuring, developing, or using multilingual language models to power systems, in \\nparticular when they are used to make critical information available or play a role \\nin decisions affecting people‚Äôs access to economic opportunities, liberty, or other \\nimportant interests or rights.\\nExecutive Summary\\nLost in Translation\\nCDT Research\\n8\\nIntroduction\\nD\\nespite the modern internet‚Äôs power to mobilize and connect \\npeople around the world, the web still does not reflect the \\nlinguistic diversity of its users. In particular, the automated \\nsystems that increasingly mediate our interactions online ‚Äî \\nsuch as chatbots, search engines, and content moderation systems ‚Äî \\nare built using and perform far better on English-language text than \\nthe world‚Äôs other 7,000 languages (Kornai, 2013; Sengupta, 2022). \\nIndividuals speaking languages other than English face barriers to \\nexpressing themselves freely online and may face greater challenges \\nwhen it comes to accessing critical information, public services, and \\neven asylum and safety (Torbati, 2019).\\nIn the last few years, however, there have been rapid advancements in \\ndeveloping machine learning tools that can analyze content in a wide \\nvariety of languages and across different domains. Large language \\nmodels, machine learning tools trained on enormous amounts of text \\nto recognize patterns in language, power many of these systems. Large \\nlanguage models already underlie translation apps, search autocomplete, \\nand chatbots such as ChatGPT. They are known for being adaptable to \\nmany different language tasks, and today, researchers and technologists \\nare constantly on the lookout for new applications and contexts \\nin which to deploy them. Since the late 2010s, major U.S.-based \\ntechnology companies have mostly invested in building large language \\nmodels that work primarily for English, such as Open AI‚Äôs GPT-4, \\nMeta‚Äôs LLaMa, and Google‚Äôs PaLM.\\nRecently, companies and researchers have begun building and researching \\nmultilingual language models, large language models trained on text \\ndata from several different languages at once. Meta‚Äôs XLM-RoBERTa \\n(XLM-R) for instance is trained on text from 100 languages (Meta AI, \\n2019) at once. Google‚Äôs mBERT, a multilingual version of its popular \\nBERT model, is trained on 104 languages. Researchers claim that these \\nmodels extend the multifaceted capabilities of large language models to \\nlanguages other than English, even to languages for which there is little or \\nno text data for the model to learn from (Artetxe & Schwenk, 2019; Wu \\n& Dredze, 2019).\\nTechnology companies have their own interests in improving how \\nwell large language models work in different languages. Some may \\nwant to make their products available in multiple languages to gain a \\ncompetitive edge in emerging and populous markets. Online services\\nLarge Language Models in Non-English Content Analysis\\n9\\nthat host user-generated content may especially be interested in using multilingual \\nlanguage models to detect and take action on hate speech, disinformation, and other \\ncontent that violates their policies or the law (Dulhanty et al., 2019). This is top of \\nmind for services after facing criticism for not taking more aggressive action against \\ncontent that incited violence and genocide in Ethiopia, Nigeria, and Myanmar, among \\nothers. Services have begun to deploy multilingual language models into their content \\nmoderation systems: Meta claims their XLM-R model can detect harmful content \\nin all 100 languages it is trained on (Meta AI, 2021); Alphabet‚Äôs Perspective API uses \\na large language model to detect toxic content in eighteen different languages (Lees \\net al., 2022); Bumble uses one to detect rude and abusive messages in at least fifteen \\nlanguages (Belloni, 2021). Technology companies are also repurposing these models to \\nmake health care information available and soon may reach into other domains as well \\n(Lunden, 2023).\\nIn the future, governments could also seek to use automated systems built using \\nlarge language models to make information available, answer questions in languages \\nspoken by their constituents (in the form of chatbots), or, more dangerously, analyze \\ninformation to make critical decisions such as benefits allocation or refugee status \\ndeterminations (Kinchin & Mougouei, 2022).\\nStill, studies show that even multilingual language models struggle to deal with the \\nwide disparities between different languages in how much text data they have available \\nto train and test language models. English has, by multiple orders of magnitude, more \\ntext data available than any other language and commands most of the attention of the \\nnatural language processing research community. The abundance of English language \\ndata stems from its position as the official or de facto language of international business, \\npolitics, and media, itself a legacy of British colonialism and American neocolonialism \\nand the subsequent erasure of regional and indigenous languages. American technology \\ncompanies have further entrenched English as the predominant language of the internet \\nby rolling out early standards, coding languages, and social media platforms in English \\nlong before other languages.\\nThe hegemony of English data means that most large language models, even \\nmultilingual ones, are built predominantly using Standard English language text and \\nwork best in Standard English language contexts. Spanish, Chinese, Arabic, and a few \\nother ‚Äúhigh resource‚Äù languages also have significant amounts of text data available, but \\nmany ‚Äúmedium resource‚Äù languages, such as Hindi and Portuguese, and ‚Äúlow resource‚Äù \\nlanguages, such as Haitian Creole and Swahili, have hardly any data available at all, and \\nmultilingual language models perform much worse in those languages. This skewed \\nemphasis fails to reflect the diversity of languages spoken by the world‚Äôs internet users \\nand further perpetuates the dominance of the English language.\\nIntroduction\\nLost in Translation\\nCDT Research\\n10\\nDespite being deployed in real-world systems, multilingual language models have largely \\nbeen absent from public discourse, particularly about digital rights and public policy, \\nand have instead been relegated to computer science academia and tech company public \\nrelations. This paper seeks to address this gap by offering several resources to bolster \\npolicy discussions. Part I provides a simple technical explanation of how large language \\nmodels work in general, why there is a gap in available data between English and other \\nlanguages, and how multilingual language models attempt to bridge that gap. Part II \\naccounts for the challenges of doing content analysis with large language models in \\ngeneral and multilingual language models in particular, namely:\\n1.\\t Multilingual language models often rely on machine-translated text that can \\ncontain errors or terms native language speakers don‚Äôt actually use. \\n2.\\t When multilingual language models fail, their problems are hard to identify, \\ndiagnose, and fix.\\n3.\\t Multilingual language models do not and cannot work equally well in all languages.\\n4.\\t Multilingual language models fail to account for the contexts of local language \\nspeakers.\\nFinally, Part III provides recommendations for companies, researchers, and \\npolicymakers to keep in mind when considering studying, developing, and deploying \\nlarge and multilingual language models to do content analysis. These recommendations \\noffer guidance concerning when large language models should or should not be \\ndeployed, how to improve their performance in non-English languages, and how to \\nensure better accountability and transparency to local language stakeholders.\\nBefore proceeding, two notes on the terminology used in this primer. First, this paper \\nfocuses specifically on one category of applications for large language models: content \\nanalysis, or, the inference and extraction of information, themes, and concepts from \\ntext. The Center for Democracy & Technology (CDT) has written many times about \\nthe limitations of automated content analysis systems (Duarte et al., 2017; Shenkman \\net al., 2021) and the civil liberty risks they can pose, particularly in areas such as content \\nmoderation, student activity monitoring, hiring and more (Grant-Chapman et al., \\n2021; Nicholas, 2022; Vallee & Duarte, 2019). Large language models are already deeply \\nintegrated into many of these technical systems, particularly content moderation, and will \\nsoon become part of many more. Public discourse about large language models has so far \\ndisproportionately focused on text generation, an important area but not the only one. \\nMany of the shortcomings of large language models presented in this report also apply \\nto text generation. As such, this report can be read as a primer on some of the limits of \\ngenerative AI systems as well. However, we choose to focus on content analysis for this \\nreport because of the potential dangers associated with using these models to host and \\nmake information available and the impacts on free expression rights.\\nLarge Language Models in Non-English Content Analysis\\n11\\nSecond, this paper focuses on how multilingual language models perform in languages \\nother than English. We use the shorthand of ‚Äúnon-English languages‚Äù for easy reading \\nand because it is the terminology used in the machine learning and policy literature. \\nWe recognize the irony that this term centers the English language and misleadingly \\nimplies all other languages are a monolith. Where possible, we elaborate upon the types \\nof languages we are writing about and make distinct references to specific languages and \\ncultural contexts that will elude models trained primarily in English. In some instances, \\nwe think the term ‚Äúnon-English‚Äù captures the sheer Anglocentrism of many of these \\nmodels well by articulating the limited scope in which they are trained and tested.\\nIntroduction\\nLost in Translation\\nCDT Research\\n12\\nI. Background\\nA. How Large Language Models Work\\nNatural language processing (NLP) is a subfield of artificial intelligence \\nand linguistics concerned with building computer systems that can \\nprocess and analyze language. NLP underlies many technologies we \\nencounter every day ‚Äî spellcheck, voice assistants like Siri or Alexa, \\nresume scanners, language translators, and automated hate speech \\ndetection tools, to name a few. Until only a few years ago, when \\ntechnologists wanted to teach a computer to perform a given NLP task, \\nthey would build a system specifically tailored to that task. To create a \\nspam detection system for instance, a technologist might gather many \\nemails, mark which ones are and are not spam, use some of those emails to \\ntrain an algorithm and use others to test how well that algorithm works.\\nToday though, the field has fundamentally reoriented itself around \\nrepurposing large language models to solve nearly every problem. \\nA language model is a mathematical function trained to solve a text \\nprediction task like the following, ‚ÄúGiven a sequence of words, predict \\nwhat word will likely come next.‚Äù For example, a language model might be \\ngiven the phrase ‚ÄúI was a bad student, I used to skip ____,‚Äù and generate \\nas an output that there is a high percent chance the missing word is \\n‚Äúclass,‚Äù a low percent it is ‚Äúrope,‚Äù and a near zero percent it is ‚Äúclamoring.‚Äù\\nThe distribution of language that the model learns in the process can \\neasily be repurposed to many different language tasks. The most often \\ndiscussed application is text generation: conversational agents like \\nChatGPT can repurpose this text prediction task to answer questions, \\nsummarize text, and generate overall ‚Äúhuman‚Äù-sounding speech. \\nHowever, chatbots are just one application of large language models. \\nOnce a large language model is built, it can be further trained on a \\nsmaller dataset to improve its performance in a specific task, a process \\ncalled fine-tuning. Today, for example, a developer building a spam \\ndetection system might take a general large language model already \\nbuilt by someone else ‚Äî say Google‚Äôs BERT ‚Äî and fine-tune it to the \\nspecific task of spam detection using a handful of emails already labeled \\nspam or not spam. By building it on top of a language model, the spam \\ndetection system will do a better job of detecting spam that doesn‚Äôt \\nperfectly match the language available in the email dataset.\\nLanguage models are not new. Computational linguists have used \\nstatistical models to try to infer rules about language since the 1980s \\n(Nadkarni et al., 2011) and have used ‚Äúneural networks‚Äù (an algorithm \\nloosely modeled on how neurons connect in the brain) to do so since \\nthe early 2010s (Mikolov et al., 2013). What is new though is their\\nLarge Language Models in Non-English Content Analysis\\n13\\nlargeness. Early language models could not be trained on as much data, since they had \\nto read text in sequence, a process that could not be sped up by using more computing \\npower. These early language models struggled to analyze words within the broader \\ncontext of a sentence or document: for instance, one fine-tuned to detect suicidal \\nideation might have difficulty distinguishing between expressions of self-harm (‚ÄúI \\njust wish I was dead‚Äù) and humor (‚Äúomg I‚Äôm dead‚Äù). But in 2017, Google researchers \\nreleased a paper on a new architecture called transformers, which allowed language \\nmodels to train on lots of data at the same time, in parallel rather than in sequence \\n(Vaswani et al., 2017). These transformer-based language models could ingest so much \\ndata simultaneously that they could learn associations between entire sequences of \\nwords, not just individual words. Instead of being shown just {‚Äúdead‚Äù}, the model \\nwould see a word in its entire context, {‚Äúdead‚Äù, [‚Äúomg‚Äù, ‚ÄúI‚Äôm‚Äù, ‚Äú_____‚Äù]}, thus creating \\na much richer representation of language. Today, the only limit on the size of a language \\nmodel ‚Äî how much data it ingests and how many connections it makes between \\ndifferent sequences of words (i.e. parameters) ‚Äî is how much data one can find and \\nhow much developers are willing to spend on processing power.\\nThe output a language model produces is called a representation space, a map of the \\nsequences of words that commonly appear near one another in the training text. For \\nexample, the phrases ‚ÄúIt‚Äôs so cold outside!‚Äù and ‚ÄúI better wear a jacket‚Äù may be near one \\nanother in a language model‚Äôs representation space, since those sentences often appear \\nclose to one another in writing. This kind of proximity can lead to language models \\ninferring patterns within language that can then help them conduct tasks that it is not \\nexplicitly trained in. In this case, sentences about cold weather being mapped near each \\nother mean the large language model could be trained to detect whether a given phrase \\nis about temperature.\\nWith enough data, a large language model may have such a rich and multifaceted \\nrepresentation of a language that it can learn to do new tasks with only a few, or even \\nzero examples to fine-tune on. For instance, the spam detection system described earlier \\ncould be built with little to no spam to fine-tune on. This capability is called ‚Äúfew-shot‚Äù \\nor ‚Äúzero-shot learning‚Äù and is one of the greatest promises of large language models, so \\nmuch so that the original GPT-3 white paper is entitled ‚ÄúLanguage Models are Few-\\nShot Learners‚Äù (Brown et al., 2020).\\nImportantly though, large language models only learn the distribution of language, not \\nits meaning (Bender & Koller, 2020). In the previous ‚Äúcold‚Äù example, the model has not \\nlearned that when one is cold, one puts on a jacket or anything about the deeper meanings \\nof ‚Äúcold‚Äù and ‚Äújacket,‚Äù only that the words often appear near one another. If one of the \\ndocuments a large language model trains on is a humorous blogpost about the best shorts \\nto wear in cold temperatures, the model could just as easily learn that ‚Äúshorts‚Äù and ‚Äúcold‚Äù \\nare related. Similarly, if a model is trained only on very formal language data, it may never \\nlearn that ‚Äúnippy‚Äù or ‚Äúbrick‚Äù (New York City slang) can refer to cold as well.\\nI. Background\\nLost in Translation\\n14\\nTechnologists often try to address these shortcomings by training language models \\non more and more data. If a model is exposed to more data, the idea is that it will be \\nfamiliar with more contexts, and outliers like the ironic cold-weather shorts blogpost \\nwill be outweighed by more representative data. This has led to ballooning in the size \\nof large language models. BERT, a popular open-source model built by Google in \\n2018, was trained on 800 million words from free books and 2.5 billion words from \\nEnglish Wikipedia (Devlin et al., 2019). Two years later, OpenAI released its closed \\nsource GPT-3, which was trained on half a trillion mostly-English words crawled from \\nthe internet (Brown et al., 2020). Google‚Äôs PaLM, released in 2022, trained on 780 \\nbillion words, mostly from English-language websites and social media conversations \\n(Chowdhery et al., 2022). As models have grown in size, so have the computation costs \\nof training them. While BERT costs a few thousand dollars in computing power to \\ntrain from scratch and is often trained by academics to build new topic- or language-\\nspecific models (Izsak et al., 2021), GPT-3 and PaLM-sized models cost millions or \\ntens of millions of dollars to train (Sharir et al., 2020). Future models will only be \\nmore expensive, leaving only the most well-off companies able to afford to build them \\n(Bommasani et al., 2021).\\nFigure 1. Language model \\nrepresentation space. A langauge model‚Äôs \\nreprsentation space, collapsed into two \\ndimensions. In reality, these models often \\nhave thousands or tens of thousands of \\ndimensions.\\nSource: (Amer, 2022)\\nLost in Translation\\n14\\nWhen is \\nBoxing Day?\\nWhat is the date \\nof Boxing Day?\\nHow many species \\nof sharks are there?\\nHow many species of the \\nGreat White shark are there?\\nIt‚Äôs so cold \\noutside!\\nI better wear \\na jacket.\\nLarge Language Models in Non-English Content Analysis\\n15\\nModels are expensive to initially train, but once built, their representations are relatively \\ncheap to use and be fine-tuned for different tasks. Thus, many technologists simply \\nuse pretrained large language models built by others (usually large companies, with the \\nexpertise and resources) instead of paying to create their own. The few big pretrained \\nmodels that exist have thus become a sort of infrastructure, known as ‚Äúfoundation \\nmodels‚Äù (Bommasani et al., 2021). This gives many technologists access to the state of \\nthe art capabilities, but it also creates a single point of failure for the sector as a whole: \\nif a foundation model has a problem, it will persist across many applications. And these \\nmodels are so large and complicated that even when they are open source, researchers \\ncannot understand the underlying logic they use to come up with individual decisions.\\nMany of the largest and most advanced of these foundation models ‚Äî such as \\nOpenAI‚Äôs GPT-4, Google‚Äôs PaLM, and Meta‚Äôs LLaMa ‚Äî are trained primarily on \\nEnglish language data. In the next section, we explore one reason why that may be: the \\nresourcedness gap.\\nB. The Resourcedness Gap: Why the Largest \\nLanguage Models are in English\\nEnglish is the closest thing there is to a global lingua franca. It is the dominant language \\nin science, popular culture, higher education, international politics, and global \\ncapitalism; it has the most total speakers and the third-most first-language speakers \\n(Ethnologue, 2023b). It is the primary language spoken on the internet, accounting \\nfor 63.7% of websites, despite being spoken by only 16% of the world‚Äôs population \\n(Richter, n.d.). This dominance does not stem from any sort of inherent linguistic \\nsuperiority: rather it is the colonial and neocolonial legacy of nearly three hundred \\nyears of the preeminent global superpower speaking English ‚Äî first Great Britain, \\nthen the United States. The British government prioritized the English language \\nthrough official language policies to facilitate trade and in an attempt to ‚Äúmodernize‚Äù \\nits colonies, and as British, and later American trade became globally dominant, so too \\ndid English (Corradi, 2017; Phillipson, 1992). Prioritization of the English language \\ncame at the expense of other regional and indigenous languages and accelerated \\nlanguage endangerment and economic marginalization, which still impedes digital \\ninvestment into these languages worldwide (Rowe, 2022; S. Zhang et al., 2022). \\nAmerican companies continue to perpetuate the dominance of the English language in \\na new more insidious form, by making online services available to global users without \\ncomparable investment into the languages they speak (Amrute et al., 2022; Kupfer & \\nMuyumba, 2022).\\nI. Background\\nLost in Translation\\nCDT Research\\n16\\nAs a result of these forces, English also dominates the field of natural language \\nprocessing, and there is vastly more raw text data available in English than in any other \\nlanguage by orders of magnitude (Joshi et al., 2020).\\xa0English has the most digitized \\nbooks and patents, the largest Wikipedia, and the biggest internet presence. English is \\nalso by far the language paid the most attention by the global NLP research community. \\nIt is so hegemonic within the field that NLP papers about the English language \\ntypically do not even mention the language in the title or abstract (Bender, 2019). As \\nFigure 2 shows, even among NLP papers that do mention a language in the abstract, \\nEnglish is mentioned over ten times as often as the next most mentioned language, \\nGerman (ACL Rolling Review Dashboard, 2022).\\nThis wealth of data and research makes it significantly easier to build large language \\nmodels in English than in any other language. More raw text data, also known as \\nunlabeled data, means more data for the model to be trained on; more research means \\nthat there are more datasets annotated with information, also known as labeled data, \\nthat can be used to test how well models complete different types of language tasks. \\nThis creates a virtuous cycle for English-language NLP ‚Äî\\xa0more labeled and unlabeled \\ndata leads to more research attention, which leads to increased demand for labeled and \\nunlabeled data, and so on.\\nEnglish is the prime example of a high resource language, a language for which a lot of \\nhigh-quality data resources exist. Though it has the most data available of any language \\n(English could be called an ‚Äúextremely‚Äù high resource language), there are six other \\nlanguages that could be considered high resource ‚Äî the official UN languages list, \\nminus Russian, plus Japanese (see Table 1). There are also a few dozen medium resource \\nlanguages, such as Urdu, Italian, and Tagalog, with another one or two orders of \\nmagnitude less data, or about one hundredth or one-thousandth of available English data. \\nThe rest of the world‚Äôs 6,000 plus languages can be considered low resource or extremely \\nlow resource, with only small amounts of written text available (Joshi et al., 2020).\\nResourcedness can vary within languages as well. Languages such as Arabic and Spanish \\ndiffer so much between dialects that many are mutually incomprehensible, even if \\nthey mostly use the same written form. Languages can also have different sociolects, \\nvarying across different social groups, identity groups, and contexts (e.g. formal versus \\ninformal). Regional dialects and sociolects can vary in degrees of difference from \\nhaving different vocabulary and grammatical structures (e.g. Australian English or \\nAfrican American English versus Standard American English) to make extensive use of \\nborrowed words from other languages (e.g. Nigerian English, Indian English), to fully \\nhybrid bilingual dialects (e.g. Spanglish, Hinglish). However, the available digitized \\ntext of language often doesn‚Äôt reflect the full spectrum of variation that exists within a \\nlanguage. (Bergman & Diab, 2022). Data scraped from the internet in particular over-\\nindexes Standard English spoken by younger people in developed countries (Luccioni \\n& Viviano, 2021). Other languages have just as much dialectical diversity as English and \\nalso likely over-index on certain dialects.\\nLarge Language Models in Non-English Content Analysis\\n17\\nFigure 2. Languages mentioned in \\npaper abstracts. Top most mentioned \\nlanguages in abstracts of papers published \\nby the Association for Computational \\nLinguistics, May 2022-January 2023.\\nSource: (Santy et al., 2023)\\nPaper Abstracts\\nLanguages with less data available also often have lower quality data available, either \\nbecause it is mislabeled or otherwise not representative of how people actually speak \\nthe language. This is particularly true with web-crawled data, a key data source for \\nlarge language models (Khan & Hanna, 2023). Non-English language data scraped \\nfrom the internet is more often machine translated, scanned from an image, or both, \\nand each of those processes introduces opportunities for error (Dodge et al., 2021). \\nLow- and medium-resource language data on the internet is more often pornographic, \\nnonsensical, or non-linguistic content (Kreutzer et al., 2022). It is also often labeled as \\nthe incorrect language ‚Äì around 95% of the time for many low resource languages ‚Äì \\nbecause automatic language identification works much more poorly with insufficient \\ndata, thus creating a circular problem (Caswell et al., 2020). Languages with the worst \\nquality web data are disproportionately those written in non-Latin scripts (e.g. Urdu, \\nJapanese, Arabic) and those spoken in the Global South (e.g. African languages, \\nminority languages in the Middle East, non-Mandarin Chinese languages) (Kreutzer et \\nal., 2022).\\n17\\n0\\n200\\n300\\n100\\nEnglish\\nKorean\\nIndonesian\\nThai\\nFrench\\nGreek\\nTurkish\\nFinnish\\nGerman\\nSpanish\\nSwahili\\nClassical Chinese\\nHindi\\nHebrew\\nPolish\\nItalian\\nKinyarwanda\\nArabic\\nRussian\\nTalugu\\nDutch\\nJapanese\\nVietnamese\\nPortuguese\\nLatin\\nMarathi\\n311\\n27\\n18\\n16\\n16\\n16\\n16\\n13\\n10\\n7\\n7\\n7\\n6\\n5\\n5\\n5\\n4\\n4\\n4\\n4\\n4\\n3\\n3\\n3\\n3\\n3\\nI. Background\\nLost in Translation\\nCDT Research\\n18\\nLow resource languages also tend to have data that comes from a less diverse set of \\nsources. The clean data that does exist often comes from places such as Wikipedia, the \\nBible, and parliamentary proceedings, particularly in large language models that depend \\non drawing parallels between low and high resource languages (see III.B and III.C) \\n(Nekoto et al., 2020). None of these data sources is representative of a language as a \\nwhole. For example, there is a significant gender gap when it comes to who contributes \\nto Wikipedia, with studies finding that the percentage of women who edit Wikipedia \\narticles remains ‚Äúdismally low‚Äù (Callahan & Herring, 2011; Vitulli, 2018), and it \\ndoesn‚Äôt reflect a more casual style of speech. Some text on Wikipedia is also machine-\\ntranslated ‚Äî Cebuano, Swedish, and Waray for instance are some of the Wikipedia \\nlanguages with the most articles, but most are translated by the same bot (Lokhov, \\n2021). The Bible is similarly its own unique domain, unrepresentative of language at \\nlarge, but is overrepresented in the training data for non-English large language models. \\nThis can lead to errors in the tone and substance of language. For example, for a period \\nof time, running a word repeated enough times through Google translate produced a \\nreligious-sounding text: the word ‚Äúdog‚Äù pasted two dozen times and translated from \\nMaori to English produced text about Jesus‚Äô return at the end of days (Christian, 2018).\\nThe resourcedness of a language is often out of sync with the number of speakers or \\ninternet users that language has. Hindi, Bengali, and Indonesian are medium-resource \\nlanguages yet each has hundreds of millions of speakers (Joshi et al., 2020). Guaran√≠, \\nan Indigenous language spoken by most of the ~7 million-person population of \\nParaguay, hardly has any data resources at all (G√≥ngora et al., 2021). Fula, a language \\nspoken by tens of millions of West Africans, also has few data sets (Nguer et al., 2020). \\nDespite over 600 million internet users across the African continent, nearly all African \\nlanguages remain low-resourced.\\nTable 1. Categories of language \\nresourcedness. Languages divided into \\ndifferent levels of resourcedness, according \\nto labeled and unlabeled datasets available \\nas of 2020.\\nSource: (Joshi et al., 2020)\\nResourcedness\\nLanguages\\nNumber of Languages\\nNumber of Speakers\\nExtremely High Resource\\nEnglish\\n1\\n1.1B\\nHigh Resource\\nArabic, French, Japanese, German, \\nSpanish, Mandarin\\n6\\n2.7B\\nMedium Resource\\nDutch, Vietnamese, Korean, \\nPortuguese, Hindi, Slovak, Hebrew, \\nIndonesian, Afrikaans, Bengali, etc.\\nDozens\\n2.7B\\nLow Resource\\nHaitian Creole, Tigrinya, Swahili, \\nBavarian, Cherokee, Zulu, Burmese, \\nTelugu, Maltese, Amharic, etc.\\nHundreds\\n0.5B\\nExtremely Low Resource\\nDahalo, Warlpiri, Popoloca, \\nWallisian, Bora, etc.\\nThousands\\n1.1B\\nLost in Translation\\n18\\nLarge Language Models in Non-English Content Analysis\\n19\\nMany scholars have worked to try to close this resourcedness gap between high and low \\nresource languages. Individual NLP communities have formed around many languages in \\norder to kickstart and perpetuate the virtuous cycle of research attention and benchmark \\ndevelopment, including collectives such as IndoNLP for languages spoken in Indonesia \\nand Masakhane for African languages (Cahyawijaya et al., 2022; Nekoto et al., 2020; Orife \\net al., 2020), and conferences such as the Association for Computational Linguistics‚Äô \\nlow resource language track, and AmericasNLP for indigenous languages (ACL, 2021; \\nAmericasNLP, 2022; Masakhane, n.d.). Tech companies have also sought to expand the \\nnumber of language models their models work in, in part by creating more data sets, \\nincluding with projects like Facebook‚Äôs No Language Left Behind project and Google‚Äôs \\n1000 Languages Initiative (NLLB Team et al., 2022; Vincent, 2022). DARPA even \\nfunded the Low Resource Languages for Emergent Incidents (LORELEI) program in \\n2014 to improve translation about emergency incidents into low resource languages \\n(Corvey, 2014). But the gaps between English, other high resource languages, and low \\nresource languages remain large and are growing exponentially greater by the day, at least \\nin terms of available, raw digitized data.\\nThe response by the NLP community has not just been to collect more language \\ndata but also to employ technical tricks to help language models squeeze the most \\nperformance out of the little data they have. In the next section, we discuss the primary \\ntechnical architecture developers use to do this: multilingual language models.\\nC. Multilingual Language Models: Efforts to \\nBridge the Resourcedness Gap\\nIn English, most large language models are monolingual, meaning that they train mostly \\non data from one language. Researchers have also built monolingual models in non-\\nEnglish languages: for instance, the architecture for Google‚Äôs BERT model ‚Äî one of \\nthe most popular and cheapest to train ‚Äî has been utilized for French (CamemBERT), \\nItalian (AlBERTo), Arabic (AraBERT), Dutch (BERTje), Basque (BERTeus), Maltese \\n(BERTu), and Swahili (SwahBERT), to name a few (Agerri et al., 2020; Antoun et al., \\n2020; de Vries et al., 2019; G. Martin et al., 2022; L. Martin et al., 2020; Micallef et al., \\n2022; Polignano et al., 2019). However, in general, these monolingual models perform \\nworse in their respective languages than the best English models do in English because \\nthey don‚Äôt have as much data to train on.\\nThis lack of data manifests in different ways depending on the specific task a model is \\nfine-tuned to perform. Some language model capabilities ‚Äî usually ones that depend \\non fact retrieval ‚Äî improve linearly with size. For instance, the more data a language \\nmodel is exposed to, the better it is at answering trivia questions or reformatting \\ndata (Srivastava et al., 2022). Other capabilities ‚Äî usually ones with multiple steps \\nI. Background\\nLost in Translation\\nCDT Research\\n20\\nor components ‚Äî exhibit a ‚Äúbreakthrough‚Äù behavior, where once a model reaches a \\ncertain size, it improves sharply at the task. For instance, language models typically are \\nunable to write code or add three digit numbers until they train on a certain amount \\nof data, at which point their performance improves dramatically (Ganguli et al., 2022). \\nLow and extremely low resource languages often do not have enough data to train a \\nlarge language model at all, but medium and even high resource languages may not \\nhave the hundreds of millions, or billions of words of text data necessary to achieve the \\nbreakthroughs that English can (Y. Zhang et al., 2021).\\nBesides technical limitations, companies may not be interested in deploying a different \\nmonolingual model for every language their product is available in for business reasons \\nas well. Maintaining and debugging one large language model for each language \\nintroduces costs that scale per language introduced, introducing complexity and \\nadditional overhead costs. Companies that seek to expand into new global markets \\nwill likely try to keep their costs fixed by reusing as much infrastructure as possible, \\nincluding language models.\\nTherefore, instead of using monolingual models to do NLP tasks in non-English \\nlanguages, researchers and developers most often use multilingual language models, \\nsuch as Google‚Äôs mBERT and Meta‚Äôs XLM-R, which are trained on texts from \\nmany different languages at once. Like their monolingual counterparts, multilingual \\nlanguage models are trained on a fill-in-the-blank task. However, by training on text \\nfrom several different languages, multilingual language models can, at least in theory, \\ninfer connections between languages, acting as a sort of bridge between high and low \\nresource languages, allowing the former to bootstrap the latter.\\nFor instance, imagine that an Indian climate change researcher wants to use a language \\nmodel to collect all Hindi-language tweets about the weather. A monolingual language \\nmodel trained on just Hindi text may not have enough data to have seen the words \\n‚Äúthaand‚Äù (‚Äúcold‚Äù in Hindi) and ‚Äúshaal‚Äù or (‚Äúshawl‚Äù in Hindi) appear near one another \\nin text, so it may miss that tweets to the effect of ‚ÄúMain Agast mein shaal pahanta \\nhoon‚Äù (‚ÄúI put a shawl on in August‚Äù) is a sentence about cold weather.1 A multilingual \\nmodel, trained on data from English, Hindi, and many other languages may have seen \\ntext where ‚Äúthaand‚Äù appears near ‚Äúcold,‚Äù ‚Äúshaal‚Äù appears near ‚Äúshawl,‚Äù and ‚Äúcold‚Äù \\nappears near ‚Äúshawl,‚Äù thereby allowing the model to infer that ‚Äúthaand‚Äù and ‚Äúshaal‚Äù are \\ninterrelated terms.\\nMultilingual language models are usually not trained on equal volumes of data from \\neach language: mBERT for instance is trained on 15.5 GB of English text but as little \\nas 10 MB of Yoruba text (Wu & Dredze, 2020). Even BLOOM, a popular multilingual \\nmodel by BigScience with a particular focus on language representation, has 30% of its \\n1\\t  Transliterated into Roman script for ease of reading for an English-language reader.\\nLarge Language Models in Non-English Content Analysis\\n21\\nFigure 3. Monolingual vs multilingual \\nlanguage model representation \\nspace. A visualization of a monolingual \\nand a multilingual langauge model‚Äôs \\nrepresentation space, collapsed into three \\ndimensions.\\nSource: (Schwenk, 2019) \\ntraining text in English (BigScience Workshop et al., 2023). In large part, this is because \\nof the lack of available data in these languages, which come disproportionately from \\nWikipedia and religious texts, as discussed earlier (see Part I.C).\\nJust as a monolingual language model can be fine-tuned to work better on an individual \\ntask, a multilingual language model can be fine-tuned to work better in an individual \\nlanguage. Imagine for instance a developer who wants to use a multilingual language \\nmodel to detect Indonesian election disinformation on social media. One way they \\ncould do it is by using an out-of-the-box multilingual model, such as BLOOM, and \\nfine-tuning it by showing examples of false narratives circulated in Indonesian related \\nto the local election. This likely would not work very well though, since BLOOM has \\nonly been exposed to a limited amount of data on Indonesian text ‚Äî\\xa0only 1.2% of its \\ntraining data is in Indonesian (BigScience Workshop et al., 2023). Another better way \\nto do it, if the developer has access to more Indonesian language data, would be first to \\nfine-tune the model on additional Indonesian text (essentially, continuing to learn the \\nfill-in-the-missing-word task, but this time just in Indonesian) and then further fine-\\ntuning it on the task election disinfo detection using that dataset.\\nModel developers though do not always have enough text data to sufficiently fine-\\ntune a multilingual model to work in a specific language. To make up for this, they \\noften use imperfect machine-translated text. The two main methods of incorporating \\ntranslated text are called translate-train or translate-test methods. With translate-train, \\na multilingual language model is fine-tuned on data that has been translated from \\n(usually) English into a desired lower resource language (Conneau & Lample, 2019). \\nWith translate-test, a (usually) English monolingual language model is fine-tuned \\non data translated from the desired language into English, and all testing data gets \\ntranslated into English as well (Artetxe, Labaka, et al., 2020).\\nI. Background\\n21\\nThe tree is green.\\nThe tree is green.\\nEl √°rbol es verde.\\nMonolingual model\\nIt is cold today.\\nMultlingual model\\nI put on a shawl.\\nI like to sing. \\nI like to sing. \\nJ‚Äôaime chanter. \\nAaj bohut thaand hai.\\nMain ek shaal pahanta hoon.\\nI put on a shawl.\\nIt is cold today.\\nLost in Translation\\nCDT Research\\n22\\nImagine, for example, a developer building a language model to detect terrorist content \\nin the Basque language with a handful of examples of terrorist content in Basque \\nbut not enough Basque text data to properly fine-tune a language model. With the \\ntranslate-train approach, a developer would take a large volume of English text data, \\nmachine translate it into Basque, use that data to fine-tune a pretrained multilingual \\nlanguage model, and then further fine-tune it to the task of terrorist content detection \\nusing the native Basque data. With translate-test, a developer would fine-tune a \\npretrained English language model on data translated from Basque to English, and \\nthen further fine-tune it by translating the terrorist content data they have into English. \\nSubsequently, to analyze Basque text, it would first have to be translated into English \\nbefore being evaluated by the model. Reliance on translated data raises many concerns, \\nas discussed in Part II.C.1.\\nHowever, translated texts can help multilingual language models learn connections \\nbetween languages. By feeding a model parallel texts ‚Äî for instance, explicitly \\ninforming it that ‚Äúbaahar bohut thand hai‚Äù and ‚ÄúIt‚Äôs so cold outside‚Äù have the same \\nmeaning ‚Äî it can better extrapolate other language parallels as well (e.g. NLLB Team et \\nal., 2022; Reid & Artetxe, 2022). Multilingual language models can learn connections \\nbetween languages without explicit labeling, instead inferring relationships between \\nlanguages on its own through borrowed words, numbers, and URLs (Pires et al., 2019). \\nIn general, NLP researchers understand little about why it is that multilingual language \\nmodels can be effectively fine-tuned to work in languages that they have relatively little \\ndata for (Conneau, Khandelwal, et al., 2020; Pires et al., 2019; Wu & Dredze, 2019). \\nSome argue that it is because multilingual language models have inferred language-\\nagnostic concepts and universal rules that can be applied to any language (Artetxe, Ruder, \\net al., 2020; Chi et al., 2020; Conneau, Wu, et al., 2020; Tsvetkov et al., 2016). Others \\nsay that multilingual language models are just effective imitators (Bender et al., 2021; \\nLauscher et al., 2020). The debate is impossible to fully resolve because of the overall \\ncomplexity and opacity of large language models, but so far evidence suggests that at \\nbest, the linguistic universals they learn are limited to narrow semantic and syntactic \\ndomains (Libovick√Ω et al., 2019; Wu & Dredze, 2019), such as learning plural/singular \\nverb agreement across multiple languages (de Varda & Marelli, 2023). But even if a model \\ncan infer syntactic or semantic commonalities between languages, such inferences will \\nnot necessarily help it manage more complex, context-dependent tasks (Choi et al., 2021). \\nFor instance, in some languages, multilingual language models do no better than random \\nguessing at detecting hate speech (Lin et al., 2022). As will be discussed in the next section, \\nthese are hardly the only limits of multilingual language models.\\n23\\nLost in Translation\\nII. Limitations of \\nLanguage Models \\nin English and Non-\\nEnglish Contexts T\\nhe press, technology companies, and social media are abuzz \\nabout the potential of large language models. In this section, \\nhowever, we discuss the shortcomings of these models, \\nparticularly as they operate in non-English language contexts. \\nIn the first section, we discuss general concerns with building and \\ndeploying large language models. These concerns apply both to the \\nEnglish and non-English contexts. In the second section, we look at the \\nproblems more specifically raised by multilingual language models.\\nA. Concerns with Building and \\nDeploying Large Language Models\\n1. LARGE LANGUAGE MODELS ARE BOUND BY \\nLANGUAGE THEY HAVE SEEN BEFORE AND STRUGGLE \\nTO PERFORM IN NEW CONTEXTS.\\nA large language model does not understand language; instead, it makes \\nprobabilistic inferences about text based on the distribution of language \\nwithin the data it is trained on. Bender and Koller argue that this means \\nlanguage models are limited to contexts they have encountered before \\nand struggle greatly in those they have not (2020). NLP researchers have \\nalready proven this is the case in generative AI by demonstrating several \\nunintuitive outcomes: for instance, language models are better able to \\nperform mathematical operations with numbers that appear frequently \\nin written language (e.g., multiplying numbers by 24), than numbers \\nthat appear infrequently (e.g. multiplying numbers by 23) (Razeghi \\net al., 2022). Large language models may exhibit similar limitations in \\ncontent analysis as well. For instance, if a large language model were \\nused to analyze a candidate‚Äôs resume, it may struggle to account for \\nlesser-known companies or newer skill sets without up-to-date, domain-\\nspecific data to fine-tune on. These tasks are reliant on in-context \\nknowledge and without domain-specific training, i.e. training an off-\\nthe-shelf large language model with text relevant to the task at hand, \\nthese models are likely to perform poorly and their purported domain-\\nagnostic abilities should garner skepticism (Duarte et al., 2017).\\nLost in Translation\\nCDT Research\\n24\\n2. LARGE LANGUAGE MODELS REPRODUCE THE BIASES, VALUES, \\nAND HARMS OF THE DATA THEY TRAIN ON.\\nLarge language models are built using vast quantities of text scraped from the internet \\nand exhibit all the biases and limitations of their data source (Okerlund et al., 2022). \\nSome commonly used datasets, such as Common Crawl, include large volumes of \\nhate speech and sexually explicit content (Luccioni & Viviano, 2021). Other problems \\nare more nefarious. For example, researchers found that when GPT-3 generated \\ncompletions for the prompt ‚ÄúTwo Muslims walked into a___,‚Äù 66% of completions \\nincluded violent language, three times more than for other religious groups (Abid et \\nal., 2021). Others have found similar entrenched biases against people with disabilities, \\nfor example inferring negative sentiment from sentences that include disability-related \\nterms (Hutchinson et al., 2020).\\nThough technologists often try to pull out explicitly harmful data from training \\nsets, models can still reify harms, such as referring to ‚Äúwomen doctors‚Äù or calling \\nundocumented immigrants ‚Äúillegals‚Äù (Bender et al., 2021). Removing these instances \\nof harmful data from training datasets, which are disproportionately outsourced \\nto underpaid staff around the world, also imposes labor and psychological burdens \\n(Williams et al., 2022). \\nEven if datasets are rid of specific examples of harmful text, they will nonetheless \\ncontain values and assumptions that are encoded into the language we speak and the \\ndominant perspectives that exist in many pieces of written text, particularly government \\ndocuments or state-run media pieces that may make up the bulk of text available for \\nlow resource languages (Bender et al., 2021). Many machine learning researchers fail to \\nconsider these problems in their work ‚Äî one study found that 98% of machine learning \\npapers mention no negative potential of the technologies they are describing (Birhane \\net al., 2022). Yet the risks are very real: as Birhane & Prabhu put it, ‚ÄúFeeding AI systems \\non the world‚Äôs beauty, ugliness, and cruelty, but expecting it to reflect only the beauty \\nis a fantasy‚Äù (2021). When these problems exist in any particularly popular foundation \\nmodel, they proliferate across many different applications built on top of that model.\\n3. THE DATA LARGE LANGUAGE MODELS TRAIN ON RAISE \\nCOPYRIGHT AND PRIVACY CONCERNS.\\nLegal experts also raise concerns about copyright and ownership of text that make up \\nthe vast quantities of data that train and distinguish large models (Ebers et al., 2022; \\nOkerlund et al., 2022). Getty Images has sued the creators of Stable Diffusion, an AI \\ntool that creates images based on written prompts, claiming that the toolscraped Getty‚Äôs \\ndatabases of proprietary images and photos without permission (Vincent, 2023a). Legal \\nquestions about ownership of text and whether scraping proprietary text is lawful (e.g., \\nbecause it constitutes fair use) or not remain unanswered (Kublik, n.d.).\\nLarge Language Models in Non-English Content Analysis\\n25\\nII. Limitations of Language Models in English and Non-English Contexts\\nSome datasets that large language models train on are likely to capture examples of \\nlanguage from sites such as social media, raising personal data privacy concerns. There \\nis a high possibility that in gathering exchanges from social media networks, training \\ndatasets inadvertently contain private and even sensitive information, which increases \\nthe risk of models leaking details like names, phone numbers, or addresses from the data \\non which they‚Äôre trained (Carlini et al., 2021, 2023).\\n4. TRAINING LARGE LANGUAGE MODELS COULD HAVE A \\nSIGNIFICANT ENVIRONMENTAL IMPACT.\\nFinally, there are increasing concerns about the environmental cost of producing large \\nlanguage models. Scholars and advocates have raised concerns about the environmental \\nimpact of training these models, particularly the largest ones with billions of \\nparameters, due to their intense computation requirements (Crawford, 2021; Okerlund \\net al., 2022). There is preliminary research attempting to quantify the energy impacts \\nof computation at this scale (Kaack et al., 2022), but some early estimates suggest that \\ntraining a single BERT model, one that serves as the foundation for some multilingual \\nlanguage models, requires as much energy as a trans-American flight (Strubell et al., \\n2019). Large language models, like GPT-3, require thousands of times more (Heikkil√§, \\n2022). Png writes that these costs may be concentrated in poorer countries, where \\nserver farms and raw materials required to build necessary infrastructure are often \\nlocated (2022).\\nB. Limitations of Multilingual Language Models\\n1. MULTILINGUAL LANGUAGE MODELS OFTEN RELY ON MACHINE-\\nTRANSLATED TEXT THAT CAN CONTAIN ERRORS OR TERMS NATIVE \\nLANGUAGE SPEAKERS DON‚ÄôT ACTUALLY USE.\\nIncorporating machine-translated data into the training and fine-tuning of multilingual \\nlanguage models creates various opportunities for the model to malfunction. \\nMultilingual language models that depend on translation may struggle to build \\naccurate representations of words or concepts which have different connotations in \\ndifferent languages. For instance, in English, ‚Äúdove‚Äù is a term associated with peace, but \\nits equivalent in Basque, ‚Äúuso,‚Äù is an emasculating insult. A translation-based cross-\\nlingual model that does not train on the word ‚Äúuso‚Äù used in its native context could \\npotentially fail to see it used in a call for violence since the English mapping is so closely \\nassociated with ‚Äúpeace.‚Äù\\nLost in Translation\\nCDT Research\\n26\\nAnother issue is what NLP practitioners call the ‚Äútranslationese‚Äù problem (Yu et al., \\n2022) ‚Äî that is, machine-translated language materially differs from how human \\nnative speakers naturally use language (Bizzoni et al., 2020; Teich, 2003). In generative \\nAI, translationese can result in mono- or multilingual language models simplifying \\nor overcomplicating sentences, producing repeated words, using too common or too \\nuncommon words, borrowing too much or too little from the original language, and \\nother patterns of speech native speakers would not use (Volansky et al., 2015). These \\nmistakes are not consistent between languages or systems, so it would be difficult for \\nmodels to be able to systematically root them out, though some argue that it is possible \\n(Yu et al., 2022).\\nThe problems of machine translation spread beyond models that intentionally train on \\nit. The web is filled with machine-translated text, and models that train on web-scraped \\ndata will inadvertently encounter a lot of it, particularly in low resource languages \\n(Kreutzer et al., 2022). For instance, a lot of the Catalan data that exists on the web, \\nparticularly on websites using the .cat top-level domain, is translated using Google \\nTranslate, even on official government websites (Pym et al., 2022). Even benchmarks to \\ntest how well multilingual language models work in high and low resource languages are \\noften translated from another language, leaving researchers with less of a sense of how \\nwell these models work on language as spoken by native speakers. For instance, OpenAI \\ntested GPT-4‚Äôs capabilities in 26 languages, but using only benchmarks translated from \\nEnglish (OpenAI, 2023).\\n2. MULTILINGUAL LANGUAGE MODELS FAIL TO ACCOUNT FOR THE \\nCONTEXTS OF LOCAL LANGUAGE SPEAKERS.\\nAs discussed earlier, large language models only work well in contexts similar to \\ncontexts of the data they are trained on. A language model trained on legal texts, \\nfor instance, will perform much better on law-related tasks than medical tasks \\nor interpreting the Quran (Koehn & Knowles, 2017). This poses a problem for \\nmultilingual language models, which, particularly in low resource languages, are trained \\non text that is translated from other language contexts or comes from a few distinctive \\ncontexts, such as Wikipedia and the Bible. Multilingual language models that are not \\ntrained on large volumes of text from native speakers of a given language will more \\noften fail at tasks that require knowledge of an individual speaker‚Äôs local context, such \\nas hate speech detection and resume scanning (Lin et al., 2022).\\nImagine, for example, a multilingual language model fine-tuned to detect anti-\\nMuslim content in Assamese, a low-resource language with fifteen million speakers, \\npredominantly in northeast India (Ethnologue, 2023a). Assamese and Bengali are both \\nmedium resource languages, so a multilingual model may draw connections between \\nthe two. However, anti-Muslim hate speech is very closely tied to historical events and \\nthe specific political conditions of Assam. For instance, the term ‚ÄúBangladeshi Muslim,‚Äù\\nLarge Language Models in Non-English Content Analysis\\n27\\nII. Limitations of Language Models in English and Non-English Contexts\\nneutral in many other languages and contexts, is a hate speech dog whistle in Assamese \\nbecause it casts Assamese Muslims as foreigners (a concept that is itself closely tied to the \\nIndian government‚Äôs repatriation efforts) (Avaaz, 2019). A multilingual model neither \\ntrained on extensive native Assamese text nor explicitly trained by a language expert would \\nlikely not be able to capture this hyperlocal distinction.\\nMultilingual language models work by transferring between language contexts, but that \\ntransfer often means simply that the context of higher resource languages overwrites \\nlower resource ones. Spanish, for instance, tends to use more adjectives and analogies \\ndescribing extreme situations than English, so a sentiment detection algorithm that \\ntransfers linguistic properties over from English may mischaracterize Spanish text as \\nhaving a stronger emotional valence than it would to a native speaker (Stadthagen-\\nGonzalez et al., 2017). This structure transfer can also bring the biases of a source \\nlanguage into a target language (Savoldi et al., 2021). For instance, if a language without \\ngender pronouns, such as Hungarian or Yoruba, is mapped onto a language with \\ngendered third-person pronouns, such as English or French, the language model could \\nforce gender associations and biases of the gendered language onto the non-gendered \\none, as often occurs in translation (Prates et al., 2020) (see Figure 4).\\nFigure 4. Google Translate from \\nHungarian to English. A screenshot of \\nGoogle Translate, circa 2020, showing how \\nthe multilingual language models project \\ngender onto genderless languages.\\nSource: (Prates et al., 2020)\\n27\\nLost in Translation\\nCDT Research\\n28\\n3. MULTILINGUAL LANGUAGE MODELS DO NOT AND CANNOT WORK \\nEQUALLY WELL IN ALL LANGUAGES.\\nMultilingual language models not only do not work equally well in all languages but \\nthey cannot, since the more languages a multilingual model is trained on, the less it \\ncan capture unique traits of any specific languages. This problem is called the curse \\nof multilinguality (Lauscher et al., 2020). Large language model developers are thus \\nforced to trade off performance between disparate languages; making a model work \\nbetter in Hindi for example, may come at a cost to its performance in English. In \\npractice, when technology companies must choose which languages to deprioritize \\nwithin their multilingual language models, they may be incentivized to have them \\nbe languages where speakers tend to be less wealthy, have less political power, or live \\noutside of the company‚Äôs priority markets, thus exacerbating the resourcedness gap they \\nare designed to address.\\nIn general, semantic and syntactic similarity to a high resource language protects \\nfrom the curse of multilinguality (Eronen et al., 2023). For instance, Muller et al. \\ntested mBERT on languages it had not explicitly trained on before and found that it \\nworked better in Swiss German (related to German, a high resource language), than \\nit did in Estonian (a Uralic language, like medium resource languages Hungarian and \\nFinnish), than it does Uyghur (a Turkic language, distant from any high or medium \\nresource language, with four alphabets) (2021). In general, multilingual language \\nmodels struggle with languages written in non-Latin scripts (Pires et al., 2019; Ruder \\net al., 2021), language isolates (languages etymologically distinct from all other \\nlanguages, such as Basque), and families of languages less connected to those of high \\nresource languages. This threatens to create a poor-get-poorer dynamic for languages \\nthat are only similar to other low resource languages, as is the case with many widely \\nspoken African languages including Swahili, Amharic, and Kabyle (Joshi et al., 2020). \\nThis dynamic further strengthens the post-colonial structural inequality discussed \\nthroughout this report.\\nMultilingual language models are also forced to trade off between languages in the \\nvocabulary they use. Large language models train on the problem of predicting the next \\nword in a sentence. If a model is trying to guess the word to fill in ‚ÄúToday I feel ___,‚Äù it \\nwill have a harder time doing so if it has to choose between ten million possible words \\nfrom any language instead of just a few hundred thousand English words. The total \\nnumber of words a language model has to choose from is called its vocabulary size. The \\nlarger a model‚Äôs vocabulary size, the more different possible words it can generate and \\nrecognize, but also the more computational resources it takes to train. Multilingual \\nlanguage models use all kinds of shortcuts to get their vocabulary size down. For instance,\\nLarge Language Models in Non-English Content Analysis\\n29\\nthey will often transliterate languages into Latin scripts or train the model to guess the \\nnext subword (e.g. breaking ‚Äútasks‚Äù into ‚Äúta‚Äù and ‚Äú##sks‚Äù) or letter instead of the full \\nword, thus collapsing the barrier between languages (Tay et al., 2022; C. Wang et al., \\n2020). These shortcuts cut down on costs, but they also reduce a model‚Äôs ability to \\ncapture semantic relationships between words, thus degrading its performance overall.\\nVocabulary is often decided by how frequently different words, subwords, and \\nletters appear in a model‚Äôs training text, and since multilingual language models are \\ntrained mostly on English data, their vocabularies will skew towards English as well. \\nA multilingual model may have a relatively obscure word like ‚Äúriposte‚Äù in its English \\nvocabulary, but be may missing common words in other high resource languages (e.g., \\n‚Äúescritorio‚Äù in Spanish), common subwords in medium resource languages, (e.g., ‚Äútzv‚Äù \\nin Hebrew), and entire letters in low resource languages (e.g., a character that appears in \\nTigrinya but not other Ge‚Äôez-based scripts). This inferior representation makes models \\nperform worse in a variety of tasks, and makes content analysis systems far easier to trick \\nby doing things like changing white space, using typos, or in the case of toxic content \\ndetection, adding common, positive words like ‚Äúlove‚Äù (Gr√∂ndahl et al., 2018; Lees et al., \\n2022).\\n4. WHEN MULTILINGUAL LANGUAGE MODELS FAIL, THEIR \\nPROBLEMS ARE HARD TO IDENTIFY, DIAGNOSE, AND FIX.\\nNLP practitioners depend on benchmarks to determine both how well a language \\nmodel performs at specific tasks and how close it is in general to achieving ‚Äúnatural \\nlanguage understanding‚Äù (Bender & Koller, 2020). This latter type of benchmarking \\nis very difficult in all languages, since it is hard to generalize about a language model‚Äôs \\ncapabilities from only a handful of disparate tests (Raji et al., 2021). However, the \\nchallenges of both types of benchmarks are exacerbated in the multilingual context. \\nThe disparities in NLP research attention and labeled data between languages mean \\nthat there are far more benchmarks and tasks that can be used to test models in English \\nthan in other languages, particularly low resource ones. Models developed to operate in \\nnon-English contexts are still usually tested with benchmarks translated from English \\nwhich, as discussed earlier, is often markedly different from the target language.\\nThe alternative to translation is hiring people local to the contexts a model is being \\napplied to and paying them to create data sets and develop benchmarks. This works \\nparticularly well for models built to do a specific task in a specific language (Nguyen, \\n2020; Tattle, n.d.), but is very expensive and resource intensive to scale up for models \\nmeant to work in many languages and contexts. It also raises challenging questions \\nfor detecting bias in language models (Talat et al., 2022) and performing inherently \\nII. Limitations of Language Models in English and Non-English Contexts\\nLost in Translation\\nCDT Research\\n30\\npolitical tasks, such as content moderation. For instance, a social media company trying \\nto create a dataset of inflammatory content posted in Bosnia and Herzegovina needs \\npeople who are experts in multiple ethnic conflicts and languages (Bosnian, Serbian, \\nMontenegrin, and Macedonian) but also unbiased in those conflicts, all in a country \\nthat lacks media pluralism or a strong civil society sector (Article 19, 2022). Scaling this \\nto every geopolitical problem discussed in all languages on a given online service is a \\ndaunting, if not impossible, task.\\nWhen problems with multilingual language models can be found, it is often difficult \\nto determine why they are occurring. Large language models are already opaque, even \\nto those who develop them ‚Äî neural networks, the core technology underlying large \\nlanguage models, are known for being particularly obtuse and for representing language \\nin a way that doesn‚Äôt map cleanly onto human-understandable concepts (Nicholas, \\n2020). However, multilingual language models are particularly opaque because they \\nmake unintuitive, hard-to-trace connections between languages. Take for instance, \\nthis case from an NLP paper: the Google researchers behind the Perspective API, a \\nmodel for detecting ‚Äútoxic‚Äù content, found that their model flagged tweets that used \\nthe Italian word ‚Äúsfiga‚Äù (which roughly translates to ‚Äúbad luck‚Äù) as hate speech because \\ntwo of the three examples included in the training dataset that contained the subword \\n‚Äúsfiga‚Äù were labeled as hate speech (‚Äúsfigati‚Äù is an insult meaning ‚Äúloser‚Äù) (Lees et \\nal., 2020). If this were a multilingual model that had mapped Italian learnings onto \\nTurkish analysis, perhaps sentences with the equivalent Turkish word for ‚Äúunlucky‚Äù \\n(‚Äú≈üanssƒ±z‚Äù) would also be flagged as hate speech. Even if researchers had access to all the \\ndata used to train that multilingual model, it would be extremely difficult to locate and \\nfix this bug without knowing Italian or understanding how the model had mapped \\nthese relationships.\\n31\\nLost in Translation\\nIII. Recommendations E\\nfforts to improve language models‚Äô performance in various \\nlanguages and contexts are exciting, as they may boost \\nconnectivity and information exchange for billions of users \\naround the world. However, language models are limited in their \\ncapabilities, and employing them too widely, without safeguards, or for \\nthe wrong kinds of tasks has the potential to raise civil liberties concerns \\nand erect new barriers (Maundu, 2023). Unthinking deployment \\nof large language models may impede peoples‚Äô ability to access \\ninformation, employment, and public benefits, with disparate impacts \\nfor individuals in the Global South where many of the low resource \\nlanguages are spoken. We should be cautious about the rapid adoption \\nof these technologies, especially as building blocks for other types of \\nautomation in high-stakes arenas like content moderation, employment \\nsoftware, and resource allocation.\\nIn this section, we offer recommendations for companies, researchers, and \\ngovernments to take into consideration as they build, study, and regulate \\nlarge language models, particularly in non-English language contexts.\\nA. Companies\\nTECHNOLOGY COMPANIES SHOULD DISCLOSE WHEN, \\nHOW, AND IN WHAT LANGUAGES THEY USE LARGE \\nLANGUAGE MODELS.\\nTo better understand the problems and challenges with deploying large \\nlanguage models in different languages, researchers and the public need \\nto know where to look. Companies that incorporate language models \\ninto their technical systems should always disclose how they are using \\nthem, which languages they are using them in, and what languages they \\nhave been trained on. Currently, the approach of many companies to AI \\ntransparency consists of trumpeting the capabilities of their AI systems \\nin blog posts and press releases, and, for a few larger firms, releasing \\nresearch versions of their language models that still differ from the ones \\nthey use in production. Despite publishing on AI and pushing the field \\nforward, technology companies tend to hold information about their \\nproduction AI systems, even basic information about what languages \\nthey are used in, close to the chest.\\nLost in Translation\\nCDT Research\\n32\\nAcademics and civil society have written extensively about how technology companies, \\nparticularly online service providers, could offer better transparency and accountability \\nfor their AI systems, including language models. The Santa Clara Principles, a set of \\nprinciples developed and revised by global civil society groups, provides examples of \\nthe types of disclosures companies can make about their content moderation policies \\nand processes (2021). Groups like BigScience also pave the way, exemplifying the type \\nof documentation other model-developers can publish about their content analysis \\nsystems, including model cards, transparency reports, and other avenues to disclose \\nmore information about the linguistic makeup of a model‚Äôs training data (e.g. what \\nlanguages it has trained on, how much data from each language, where those datasets \\ncome from). Better transparency creates opportunities for external actors to more \\nimmediately identify potential risks and impacts on users and for technology companies \\nto mitigate the potential dangers of deploying large language models in English and \\nnon-English contexts.\\nWHEN DEPLOYED, LARGE LANGUAGE MODELS SHOULD BE \\nACCOMPANIED BY ADEQUATE REMEDIAL CHANNELS AND \\nMECHANISMS THAT ENSURE INDIVIDUALS CAN APPEAL OUTCOMES \\nAND DECISIONS MADE BY THESE SYSTEMS.\\nBecause of the complexities of human speech and the error-prone nature of automated \\ntools, decision-making systems built on top of large language models should be used \\nwithin narrow remits and with adequate remedial channels for users encountering \\nthem. Those remedial channels and processes should have human reviewers with \\nthe same language proficiencies that their systems are deployed in. Language- and \\ncontext-specific remedial channels are particularly important for allowing users to \\nappeal decisions made by online services, especially when those decisions either restrict \\ntheir expression or access to information or fundamentally determine their access \\nto economic or social rights like the right to housing, education, and social security \\n(United Nations Human Rights Office of the High Commissioner, n.d.).\\nTechnology companies can also offer accountability at a system level, not just the \\nlevel of individual decisions. One way to do this is to conduct and publish human \\nrights impact assessments at the different phases of the language model‚Äôs life cycle \\n‚Äî development, testing, deployment, and evaluation (Prabhakaran et al., 2022). \\nPublishing human rights impact assessments will also aid in other actors‚Äô decisions \\nwhen procuring these systems to conduct tasks in different domains and contexts. In \\nparticular, these human rights impact assessments should consider the disparate risks \\nto different language speakers in advance of a model being deployed in those languages. \\nOnline service providers can provide transparency by disclosing the systems and \\nlanguages they use large language models in.\\nLarge Language Models in Non-English Content Analysis\\n33\\nIII. Recommendations\\nCOMPANIES SHOULD INVEST IN IMPROVING LANGUAGE MODEL \\nPERFORMANCE IN INDIVIDUAL LANGUAGES BY BRINGING IN \\nLANGUAGE AND CONTEXT EXPERTS.\\nRecently, an arms race has begun between Google and Meta to see who can include \\nmore languages in their multilingual language model. Meta‚Äôs ‚ÄúNo Language Left \\nBehind‚Äù initiative trained a model on over 200 languages (NLLB Team et al., 2022); \\nmonths later, Google one upped Meta with its ‚Äú1,000 Languages Initiative‚Äù (Vincent, \\n2022). This race puts a premium on the number of languages the model trains on, \\nrather than how well it works in each language. In particular, it is unclear how these \\nmodels will handle the ‚Äúcurse of multilinguality,‚Äù where, as explained in II.B.3, the \\nmore languages a model trains on, the less it can capture the idiosyncrasies of each \\nlanguage. It is also unclear how these companies define a model ‚Äúworking‚Äù in any of \\nthese languages.\\nCompanies building large language models should not just focus on the number of \\nlanguages their model is trained on but the quality of its performance in each language. \\nIn part, that means better benchmarks, but benchmarks can only go so far. To evaluate \\nthe full range of potential applications and pitfalls that could come with applying a \\nlanguage model in a specific language context, it is necessary to involve language experts, \\ncivil society, local experts, heritage and language preservation advocates, linguists, and \\nhuman rights experts. These actors are crucial to ensuring that labeled training datasets \\nadequately capture the nuances and variations of a given language. Many organizations \\nare already doing this type of work. Uli is an example of this, where two India-based \\nnonprofit organizations ‚Äî Tattle and Centre for Internet & Society ‚Äî convened a \\nrange of gender, gender-based violence, communal violence, and other language experts \\nto annotate training datasets in Indian English, Tamil, and Hindi to build a tool capable \\nof parsing sentiment and toxicity on Twitter. Other researchers have also pointed to \\nusing annotators to label training datasets as a way to equip models with the ability to \\nparse variations in the speech of a certain language (Bergman & Diab, 2022; Nkemelu \\net al., 2022). \\nB. Researchers and Funders\\nRESEARCH FUNDERS SHOULD INVEST IN SPECIFIC NLP LANGUAGE \\nCOMMUNITIES TO KICKSTART THE VIRTUOUS CYCLE OF \\nDEVELOPMENT.\\nDeveloping NLP capabilities in any language is a cyclical process, and for high resource \\nlanguages ‚Äî particularly English ‚Äî\\xa0that cycle is virtuous. When a language has lots \\nof clean, human-annotated datasets, researchers and developers are better equipped \\nto build models and benchmarks to test models in that language. More models and\\nLost in Translation\\nCDT Research\\n34\\nbenchmarks lead to more publications, conferences, and real-world use cases. And \\nfinally, increased demand for research and software in a language drives demand for \\nmore datasets. For low resource languages, however, the virtuous cycle is hard to \\nkickstart. Without tools, annotators, and financial investment earmarked for different \\nlanguage communities, NLP researchers cannot create the datasets needed to build \\nmodels or benchmarks, and even if they could, they face difficulties publishing or \\ngetting attention for their work in popular journals and conferences. The most \\nprestigious NLP publications focus disproportionately on English; languages without \\ntheir own self-sustaining NLP communities end up to a handful of specialized outlets.\\nInvestments into non-English NLP should particularly focus on creating self-sustaining \\nscholarly NLP communities, and doing this requires investing in all levels at once. The \\ngroups that are best set up to properly allocate these investments are the language- and \\ngeography-specific NLP research communities that have cropped up over the years, \\nsuch as such as Masakhane, AmericasNLP, ARBML, and others who can convene \\npractitioners around common goals to advance the field (Alyafeai & Al-Shaibani, 2020; \\nAmericasNLP, 2022; Orife et al., 2020). These communities know what kind of data \\nsets should be built, which community actors are needed to properly vet them, and \\nwhat kind of competitions and conferences should be run to keep the virtuous cycles \\ngoing. One model for how this can work is exemplified by EVALITA, an event hosted \\nby the Italian Association for Computational Linguistics. In it, researchers first submit \\ndata sets for new language tasks, such as identifying misogyny or dating documents. \\nThen, researchers compete to train models to perform those tasks the best. Finally, \\nthose results get published, thus generating interest and attention toward Italian NLP \\nand ensuring researchers continue to build tools for the language (Basile et al., 2020).\\nPrivate companies can contribute not only by financially supporting these efforts \\nbut by sharing more of the non-English datasets they use to train their large language \\nmodels, both for transparency and to support research. Large tech companies have \\nalready shared the code for training many of their multilingual language models \\n‚Äî Meta‚Äôs XLM-R and Google‚Äôs mBERT are the subjects of most multilingual \\nmodel research in publication ‚Äî and disclosed the data they train them on ‚Äî \\nCommonCrawl, and\\xa0Wikipedia and BooksCorpus, respectively. However, the models \\nthat Google, Meta, OpenAI, and other large companies use in their products train on \\nother, proprietary, language data. Companies should share more of their training data, \\nboth for public accountability and to bolster research.\\nLarge language models have by and large been built by private companies, but private \\nincentives may be at odds with developing these models in safe and equitable ways. \\nGovernment investment into non-English large language model research could lead \\nto improvements in areas private companies may be underinvesting in (Mazzucato, \\n2014). DARPA‚Äôs late 2010‚Äôs LORELEI project, aimed at spurring research into low\\nLarge Language Models in Non-English Content Analysis\\n35\\nIII. Recommendations\\nresource languages to improve translation for humanitarian efforts, is a good first step, \\nbut further government incentives could help assure that NLP researchers invest in \\na broad range of approaches and languages, rather than focus disproportionately on \\nEnglish. BigScience‚Äôs BLOOM is a good example of how large language models can \\nbe developed in the open and with public support. The French government is one of \\nmany funders which has allowed BLOOM to remain open to inquiry by other NLP \\npractitioners. The multilingual language model was trained using ROOTs, a 1.6TB \\nmultilingual dataset that is clearly documented and available for NLP practitioners to \\nanalyze (Lauren√ßon et al., 2022).\\nRESEARCHERS SHOULD FOCUS ON MEASURING AND ADDRESSING \\nTHE IMPACTS OF LARGE LANGUAGE MODELS.\\nTechnologists understand little about the internal logic of how large language models \\noperate and therefore have a difficult time predicting when they make mistakes, \\nwhat the effects of these mistakes will be, and how to fix them. Multilinguality only \\nexacerbates this problem. Better tools are needed to interrogate large language models, \\nparticularly multilingual language models, about why they make the decisions and \\nmistakes they do, and how to fix them.\\nIn particular, the increased use of multilingual language models has the potential to \\nhelp and harm language communities. Enabling greater digital participation amongst \\na language community raises something that researchers call the ‚ÄúJanus-face nature \\nof digital participation‚Äù (NLLB Team et al., 2022): it allows more to participate and \\nbenefit from the digital economy, however, it may also expose more people to the harms \\npresent online, often without their consultation and consent (Hao, 2022; Toyama, \\n2015). More research on the effects and externalities of the increased use of language \\nmodels and specifically multilingual language models must grapple with the impacts \\nthese tools have on different linguistic communities, linguistic preservation and \\ndiversity efforts, and access to opportunity for all. \\nDifferent actors have different roles to play here. Civil society has a role in documenting \\nthe impacts of these models and imagining what these ‚Äúbetter‚Äù models should look like. \\nThere are many open questions around the types of problems that need automated \\nsolutions, what more representative datasets might look like, how to manage the tradeoffs \\nbetween languages, how large language models affect linguistic preservation efforts, and \\nwhat the rights implications are of using large language models, among other things. \\nAcademics and corporate researchers have a role in better defining the contexts and tasks \\nthese models hope to address, and developing quantitative and qualitative methods to \\nevaluate these desired normative values. And companies that deploy language models \\ncan provide researchers more transparency into how their models work, what data they \\nare trained on, and in what situations they use them so researchers can better tailor their \\nresearch to reflect what is happening in real-world systems.\\nLost in Translation\\nCDT Research\\n36\\nC. Governments\\nGOVERNMENTS SHOULD CAUTION AGAINST USING AUTOMATED \\nDECISION-MAKING SYSTEMS THAT RELY ON LARGE LANGUAGE \\nMODELS TO MAKE HIGH-STAKES DECISIONS.\\nMany governments have deployed or are considering deploying systems that use natural \\nlanguage processing technology as part of AI systems to make high-impact decisions, \\nsuch as determining immigration status or selecting judicial cases to try (Patel et al., \\n2020; Rionda & Mejia, 2021). Vendors who build these systems may soon follow the \\nlarger industry trend of incorporating large language models since they are relatively \\ncheap to build and easy to adapt as requirements change. However, as discussed \\nthroughout this paper, large language models are a relatively novel technology that has \\ntechnical limitations. These tools pose serious civil liberty concerns that are magnified \\nin non-English contexts and when used to make decisions that may affect a person‚Äôs \\nlivelihood. For instance, if a large language model is used as the basis of an algorithm \\nto evaluate affordable housing applications and the text that large language model was \\ntrained on exhibits anti-Muslim bias, the resulting affordable housing algorithm may \\ndisproportionately deny Muslims‚Äô applications. Relying on large language models to \\nmake high-stakes decisions can have outsized, negative impacts on individuals‚Äô lives, \\nimpeding safety and access to economic opportunities.\\nGovernments should therefore never rely solely on automated systems that incorporate \\nlarge language models to make high-risk decision-making areas, such as pretrial risk \\nassessment, allocation of social services, and immigration status. Policymakers should \\nconsider the impact on rights and access to services when procuring new tools and \\nvendors to build these systems and conduct and disclose any assessments conducted \\non these systems. They should also be cautious when adopting these systems for \\ninformation sharing services, such as chatbots about social services or that provide \\nhealthcare information, and test them extensively in every language in which they are \\ndeployed, and never use them to entirely replace human intermediaries.\\nGOVERNMENTS SHOULD NOT MANDATE OR INADVERTENTLY \\nREQUIRE BY LAW THE USE OF AUTOMATED CONTENT ANALYSIS \\nSYSTEMS TO DETECT OR REMOVE CONTENT IN ANY LANGUAGE.\\nGovernments around the world are increasingly pressuring online service providers to \\nlimit content they find to be inaccurate or harmful, such as misinformation related to \\nhealth care, or preemptively monitor online speech which may incite violence. Given \\nthe scale of content available on social media and other services, this has driven an \\ninterest amongst governments to mandate that online service providers use automated \\ncontent analysis systems to detect or remove content they deem as ‚Äúillegal‚Äù or harmful \\nto their constituents.\\nLarge Language Models in Non-English Content Analysis\\n37\\nIII. Recommendations\\nThis is ill-advised. Mandating the use of automated content moderation technologies \\nor requiring companies to take down content in a limited time period (effectively \\nrequiring the use of automated technologies) opens the door for the overbroad removal \\nof speech. Large language models, especially in non-English language contexts, are not \\na magical technology that can perfectly distinguish between ‚Äúgood‚Äù and ‚Äúbad‚Äù speech. \\nAt best, they are an imprecise technology that fails to understand the context of speech \\n‚Äî for instance, when an individual uses a slur versus when a journalist documents \\nthe use of a slur by that individual. At worst, they are tools that can be appropriated \\nby governments to squash dissent and freedom of expression. Efforts to persuade tech \\ncompanies to improve their automated systems, clarify their policies, introduce more \\naccountability, and promote parity between languages are all welcome, but requiring \\ncompanies to adopt certain technologies is not an effective way to achieve those ends.\\nINTERNATIONAL AND MULTILATERAL STANDARDS BODIES, \\nREGULATORY AGENCIES, AND OTHERS SHOULD CONVENE \\nMULTI-STAKEHOLDER DISCUSSIONS ABOUT STANDARDS AND \\nGUARDRAILS FOR THE DEVELOPMENT AND USE OF LARGE \\nLANGUAGE MODELS.\\nThe norms around when and how multilingual language models should be deployed \\nare very much in flux. Those norms so far have mostly been established implicitly by \\ntechnology companies in the ways they build and deploy these models, but trends in \\nthese norms may be at odds with the public interest. For instance, OpenAI revealed \\nsome information about the training data they used for GPT-3 but almost nothing \\nabout GPT-4; Open AI co-founder Ilya Sutskever described having shared information \\nabout GPT-3‚Äôs training data as ‚Äújust not wise‚Äù and something the company would \\nunlikely do again (Vincent, 2023b).\\nCompanies should not have a monopoly on the norms around language models. \\nGovernmental and nongovernmental\\xa0convening bodies need to organize and push back \\nto establish counter-norms that better serve the public‚Äôs interests. This field is early on \\nenough that these bodies should discuss what positive outcomes even look like. Users \\naffected by the deployment of large language models need to be at the table for those \\nconversations. Government agencies and multilateral organizations (e.g. the Internet \\nEngineering Task Force, United Nations) can play a coordinating role to get together \\nthe relevant stakeholders to come up with such standards.\\nThere are also larger questions to reckon with when it comes to the use of large \\nlanguage models in non-English contexts. At once, companies are increasingly \\ndeploying multilingual language models to bridge the gap between the functionality in \\nEnglish and other languages across a myriad of tasks, such as harmful content detection, \\nsentiment analysis, and content scanning. However, as we show in this paper, these \\nmultilingual systems are relatively new and perform inconsistently across languages.\\nLost in Translation\\nCDT Research\\n38\\nIf deployed prematurely and without guardrails, these models pose real risks to \\nindividuals around the world and in particular their ability to express themselves freely. \\nThese risks have the potential to compound existing challenges in the information \\nenvironment for individuals in Western democracies where there are real vacuums of \\navailable information in languages other than English and in countries in the Global \\nSouth where there are already real threats to the free expression and exchange of \\ninformation posed by majoritarian and institutional powers (Golebiewski & boyd, \\n2018). Alternatively, companies may decide to only roll out systems that have been \\nfine-tuned for English and wait until there is enough data and tooling available for non-\\nEnglish language tools ‚Äî something that will take an enormous amount of financial \\ninvestment, time, effort, and rare consensus ‚Äî further entrenching the digital divide \\nand Anglocentrism present online. Both scenarios are lose-lose for all speakers on the \\nweb. This is a wicked problem and the current incentives are at play to build bigger \\nmodels, and with more languages. Multi-stakeholder bodies are much better positioned \\nthan companies to determine when the risks associated with building larger, more \\nmultilingual language models are worth taking.\\nLarge Language Models in Non-English Content Analysis\\n39\\nWorks Cited\\nAbid, A., Farooqi, M., & Zou, J. (2021). Large language models associate Muslims with violence. Nature Machine \\nIntelligence, 3(6), Article 6. [perma.cc/HK4B-3AAQ]\\nACL. (2021, August 3). ACL 2022 Theme Track: ‚ÄúLanguage Diversity: from Low-Resource to Endangered \\nLanguages.‚Äù ACL. [perma.cc/F2YW-QZBP]\\nACL Rolling Review Dashboard. (2022). Papers Mentioning >0 Languages. [perma.cc/EQU9-5CWQ]\\nAgerri, R., Vicente, I. S., Campos, J. A., Barrena, A., Saralegi, X., Soroa, A., & Agirre, E. (2020). Give your Text \\nRepresentation Models some Love: The Case for Basque. Proceedings of the 12th Conference on Language \\nResources and Evaluation, 4781‚Äì4788. [perma.cc/R2DA-GGQZ]\\nAlyafeai, Z., & Al-Shaibani, M. (2020). ARBML: Democratizing Arabic Natural Language Processing Tools. \\nProceedings of Second Workshop for NLP Open Source Software (NLP-OSS), 8‚Äì13. [perma.cc/4TFY-E9EJ]\\nAmer, M. (2022, July 13). Large Language Models and Where to Use Them: Part 2. Cohere. [perma.cc/CRT5-\\nHDX8]\\nAmericasNLP. (2022, December 7). Second Workshop on NLP for Indigenous Languages of the Americas \\n(AmericasNLP). [perma.cc/SC88-9WGF]\\nAmrute, S., Singh, R., & Guzm√°n, R. L. (2022). A Primer on AI in/from the Majority World. Data & Society. \\n[perma.cc/SR8B-J2L9]\\nAntoun, W., Baly, F., & Hajj, H. (2020). AraBERT: Transformer-based Model for Arabic Language \\nUnderstanding. Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a \\nShared Task on Offensive Language Detection, 9‚Äì15. [perma.cc/X5VJ-JKXQ]\\nArtetxe, M., Labaka, G., & Agirre, E. (2020). Translation Artifacts in Cross-lingual Transfer Learning. Proceedings \\nof the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 7674‚Äì7684. \\n[perma.cc/MZY5-DL83]\\nArtetxe, M., Ruder, S., & Yogatama, D. (2020). On the Cross-lingual Transferability of Monolingual \\nRepresentations. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, \\n4623‚Äì4637. [perma.cc/7WMN-5QPR]\\nArtetxe, M., & Schwenk, H. (2019). Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual \\nTransfer and Beyond. Transactions of the Association for Computational Linguistics, 7, 597‚Äì610. [perma.cc/\\nLB6R-GH9K]\\nArticle 19. (2022). Bridging the Gap: Local voices in content moderation. Bosnia and Herzegovina. [perma.cc/ASU5-\\nST4N]\\nAvaaz. (2019). Megaphone for Hate: Disinformation and Hate Speech on Facebook During Assam‚Äôs Citizenship \\nCount. Avaaz. [perma.cc/5MXS-7P7N]\\nLost in Translation\\n40\\nLost in Translation\\nCDT Research\\nBasile, V., Maro, M. D., Croce, D., & Passaro, L. (2020, December 17). EVALITA 2020: Overview of the 7th \\nEvaluation Campaign of Natural Language Processing and Speech Tools for Italian. Seventh Evaluation \\nCampaign of Natural Language Processing and Speech Tools for Italian, Online. [perma.cc/76EK-EJQ8]\\nBelloni, M. (2021, December 8). Multilingual message content moderation at scale. Bumble Tech. [perma.cc/\\nRL2A-L2BD]\\nBender, E. (2019, September 15). The #BenderRule: On Naming the Languages We Study and Why It Matters. \\nThe Gradient. [perma.cc/J3ZM-A5UP]\\nBender, E., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the Dangers of Stochastic Parrots: Can \\nLanguage Models Be Too Big? ü¶ú. Proceedings of the 2021 ACM Conference on Fairness, Accountability, and \\nTransparency, 610‚Äì623. [perma.cc/3KLC-TBUY]\\nBender, E., & Koller, A. (2020). Climbing towards NLU: On Meaning, Form, and Understanding in the Age of \\nData. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 5185‚Äì5198. \\n[perma.cc/TN3W-5NTC]\\nBergman, A., & Diab, M. (2022). Towards Responsible Natural Language Annotation for the Varieties of Arabic. \\nFindings of the Association for Computational Linguistics: ACL 2022, 364‚Äì371. [perma.cc/Q37M-8F2Y]\\nBigScience Workshop, Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Iliƒá, S., Hesslow, D., Castagn√©, R., Luccioni, A. \\nS., Yvon, F., Gall√©, M., Tow, J., Rush, A. M., Biderman, S., Webson, A., Ammanamanchi, P. S., Wang, T., \\nSagot, B., Muennighoff, N., ‚Ä¶ Wolf, T. (2023). BLOOM: A 176B-Parameter Open-Access Multilingual \\nLanguage Model (arXiv:2211.05100). arXiv. [perma.cc/2K4Z-F5U7]\\nBirhane, A., Kalluri, P., Card, D., Agnew, W., Dotan, R., & Bao, M. (2022). The Values Encoded in Machine \\nLearning Research. 2022 ACM Conference on Fairness, Accountability, and Transparency, 173‚Äì184. \\n[perma.cc/9GNB-JHQ5]\\nBirhane, A., & Prabhu, V. U. (2021). Large image datasets: A pyrrhic win for computer vision? 2021 IEEE Winter \\nConference on Applications of Computer Vision, 1536‚Äì1546. [perma.cc/Q8LP-THYK]\\nBizzoni, Y., Juzek, T. S., Espa√±a-Bonet, C., Dutta Chowdhury, K., van Genabith, J., & Teich, E. (2020). How \\nHuman is Machine Translationese? Comparing Human and Machine Translations of Text and Speech. \\nProceedings of the 17th International Conference on Spoken Language Translation, 280‚Äì290. [perma.\\ncc/4DTZ-DVKC]\\nBommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosselut, \\nA., Brunskill, E., Brynjolfsson, E., Buch, S., Card, D., Castellon, R., Chatterji, N., Chen, A., Creel, K., \\nDavis, J. Q., Demszky, D., ‚Ä¶ Liang, P. (2021). On the Opportunities and Risks of Foundation Models. \\nStanford Center for Research on Foundation Models. [perma.cc/3TKJ-UM2F]\\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., \\nAskell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., \\nWu, J., Winter, C., ‚Ä¶ Amodei, D. (2020). Language Models are Few-Shot Learners. Advances in Neural \\nInformation Processing Systems, 33, 1877‚Äì1901. [perma.cc/7EES-WDAB]\\nCahyawijaya, S., Lovenia, H., Aji, A. F., Winata, G. I., Wilie, B., Mahendra, R., Wibisono, C., Romadhony, A., \\nVincentio, K., Koto, F., Santoso, J., Moeljadi, D., Wirawan, C., Hudi, F., Parmonangan, I. H., Alfina, \\nI., Wicaksono, M. S., Putra, I. F., Rahmadani, S., ‚Ä¶ Purwarianti, A. (2022). NusaCrowd: Open Source \\nInitiative for Indonesian NLP Resources (arXiv:2212.09648). arXiv. [perma.cc/UQ3Y-4LKW]\\n41\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nCallahan, E. S., & Herring, S. C. (2011). Cultural bias in Wikipedia content on famous persons. Journal of the \\nAmerican Society for Information Science and Technology, 62(10), 1899‚Äì1915. [perma.cc/2S8K-YEJK]\\nCarlini, N., Ippolito, D., Jagielski, M., Lee, K., Tramer, F., & Zhang, C. (2023, February 1). Quantifying \\nMemorization Across Neural Language Models. The Eleventh International Conference on Learning \\nRepresentations. [perma.cc/678U-9PAQ]\\nCarlini, N., Tramer, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Brown, T., Song, D., \\nErlingsson, U., Oprea, A., & Raffel, C. (2021). Extracting Training Data from Large Language Models \\n(arXiv:2012.07805). arXiv. [perma.cc/58MA-VWRZ]\\nCaswell, I., Breiner, T., van Esch, D., & Bapna, A. (2020). Language ID in the Wild: Unexpected Challenges on \\nthe Path to a Thousand-Language Web Text Corpus. Proceedings of the 28th International Conference on \\nComputational Linguistics, 6588‚Äì6608. [perma.cc/8RFD-DTUK]\\nChi, E. A., Hewitt, J., & Manning, C. D. (2020). Finding Universal Grammatical Relations in Multilingual BERT. \\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 5564‚Äì5577. \\n[perma.cc/8LNR-VNY9]\\nChoi, H., Kim, J., Joe, S., Min, S., & Gwon, Y. (2021). Analyzing Zero-shot Cross-lingual Transfer in Supervised \\nNLP Tasks (arXiv:2101.10649). arXiv. [perma.cc/NEB9-8THZ]\\nChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., \\nGehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., \\nPrabhakaran, V., ‚Ä¶ Fiedel, N. (2022). PaLM: Scaling Language Modeling with Pathways. Google Research. \\n[perma.cc/NZ7N-6GPB]\\nChristian, J. (2018, July 20). Why Is Google Translate Spitting Out Sinister Religious Prophecies? Vice. [perma.\\ncc/8YQU-NUFM]\\nConneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzm√°n, F., Grave, E., Ott, M., \\nZettlemoyer, L., & Stoyanov, V. (2020). Unsupervised Cross-lingual Representation Learning at Scale. \\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 8440‚Äì8451. \\n[perma.cc/2MP6-9W3J]\\nConneau, A., & Lample, G. (2019). Cross-lingual Language Model Pretraining. Advances in Neural Information \\nProcessing Systems, 32. [perma.cc/N7EE-JM83]\\nConneau, A., Wu, S., Li, H., Zettlemoyer, L., & Stoyanov, V. (2020). Emerging Cross-lingual Structure in \\nPretrained Language Models. Proceedings of the 58th Annual Meeting of the Association for Computational \\nLinguistics, 6022‚Äì6034. [perma.cc/3NHR-G7Y4]\\nCorradi, A. (2017, April 25). The Linguistic Colonialism of English. Brown Political Review. [perma.cc/5M3M-\\n9EMN]\\nCorvey, W. (2014). Low Resource Languages for Emergent Incidents. Defense Advanced Research Projects Agency. \\n[perma.cc/4FDR-M3YC]\\nCrawford, K. (2021). Atlas of AI: Power, politics, and the planetary costs of artificial intelligence. Yale University \\nPress.\\n42\\nLost in Translation\\nCDT Research\\nde Varda, A. G., & Marelli, M. (2023). Data-driven Cross-lingual Syntax: An Agreement Study with Massively \\nMultilingual Models. Computational Linguistics, 1‚Äì39. [perma.cc/7LQP-EEBQ]\\nde Vries, W., van Cranenburgh, A., Bisazza, A., Caselli, T., van Noord, G., & Nissim, M. (2019). BERTje: A Dutch \\nBERT Model (arXiv:1912.09582). arXiv. [perma.cc/MGU3-WPXR]\\nDevlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional \\nTransformers for Language Understanding. Proceedings of the 2019 Conference of the North American \\nChapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long \\nand Short Papers), 4171‚Äì4186. [perma.cc/E46R-UYDE]\\nDodge, J., Sap, M., Marasoviƒá, A., Agnew, W., Ilharco, G., Groeneveld, D., Mitchell, M., & Gardner, M. (2021). \\nDocumenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus. Proceedings \\nof the 2021 Conference on Empirical Methods in Natural Language Processing, 1286‚Äì1305. [perma.\\ncc/3GC6-UEWJ]\\nDuarte, N., Llans√≥, E., & Loup, A. C. (2017). Mixed Messages? The Limits of Automated Social Media Content \\nAnalysis. Center for Democracy & Technology. [perma.cc/9BRH-5ZZN]\\nDulhanty, C., Deglint, J. L., Daya, I. B., & Wong, A. (2019, November 26). Taking a Stance on Fake News: Towards \\nAutomatic Disinformation Assessment via Deep Bidirectional Transformer Language Models for Stance \\nDetection. NeurIPS 2019, Vancouver. [perma.cc/P5JD-5AD9]\\nEbers, M., Poncib√≤, C., & Zou, M. (Eds.). (2022). Contracting and Contract Law in the Age of Artificial \\nIntelligence. Hart Publishing. [perma.cc/G4XR-VYNL]\\nEronen, J., Ptaszynski, M., & Masui, F. (2023). Zero-shot cross-lingual transfer language selection using linguistic \\nsimilarity. Information Processing & Management, 60(3), 103250. [perma.cc/S78N-C9MR]\\nEthnologue. (2023a). Assamese. Ethnologue, Languages of the World. [perma.cc/BE78-H3PN]\\nEthnologue. (2023b). Statistics. Ethnologue, Languages of the World. [perma.cc/H27U-44TK]\\nGanguli, D., Hernandez, D., Lovitt, L., DasSarma, N., Henighan, T., Jones, A., Joseph, N., Kernion, J., Mann, \\nB., Askell, A., Bai, Y., Chen, A., Conerly, T., Drain, D., Elhage, N., Showk, S. E., Fort, S., Hatfield-Dodds, \\nZ., Johnston, S., ‚Ä¶ Clark, J. (2022). Predictability and Surprise in Large Generative Models. 2022 ACM \\nConference on Fairness, Accountability, and Transparency, 1747‚Äì1764. [perma.cc/C8YH-6LMA]\\nGolebiewski, M., & boyd, danah. (2018). Data Voids: Where Missing Data Can Easily Be Exploited. Data & \\nSociety. [perma.cc/HE5A-7QTJ]\\nG√≥ngora, S., Giossa, N., & Chiruzzo, L. (2021). Experiments on a Guarani Corpus of News and Social Media. \\nProceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the \\nAmericas, 153‚Äì158. [perma.cc/N6S5-4PGN]\\nGrant-Chapman, H., Laird, E., & Venzke, C. (2021). Student Activity Monitoring Software Research Insights and \\nRecommendations. Center for Democracy & Technology. [perma.cc/FY8G-WC2P]\\nGr√∂ndahl, T., Pajola, L., Juuti, M., Conti, M., & Asokan, N. (2018). All You Need is ‚ÄúLove‚Äù: Evading Hate Speech \\nDetection. Proceedings of the 11th ACM Workshop on Artificial Intelligence and Security, 2‚Äì12. [perma.cc/\\nT6P5-FRX5]\\n43\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nHao, K. (2022, April 22). A new vision of artificial intelligence for the people. MIT Technology Review. [perma.\\ncc/54U3-KU5C]\\nHeikkil√§, M. (2022, November 14). We‚Äôre getting a better idea of AI‚Äôs true carbon footprint. MIT Technology \\nReview. [perma.cc/8PWZ-ESJK]\\nHutchinson, B., Prabhakaran, V., Denton, E., Webster, K., Zhong, Y., & Denuyl, S. (2020). Social Biases in NLP \\nModels as Barriers for Persons with Disabilities. Proceedings of the 58th Annual Meeting of the Association \\nfor Computational Linguistics, 5491‚Äì5501. [perma.cc/8FGR-P3FA]\\nIzsak, P., Berchansky, M., & Levy, O. (2021). How to Train BERT with an Academic Budget. Proceedings of the \\n2021 Conference on Empirical Methods in Natural Language Processing, 10644‚Äì10652. [perma.cc/8MPG-\\nW2QE]\\nJoshi, P., Santy, S., Budhiraja, A., Bali, K., & Choudhury, M. (2020). The State and Fate of Linguistic Diversity and \\nInclusion in the NLP World. Proceedings of the 58th Annual Meeting of the Association for Computational \\nLinguistics, 6282‚Äì6293. [perma.cc/82HQ-EH65]\\nKaack, L. H., Donti, P. L., Strubell, E., Kamiya, G., Creutzig, F., & Rolnick, D. (2022). Aligning artificial \\nintelligence with climate change mitigation. Nature Climate Change, 12(6), Article 6. [perma.cc/7C4S-\\nX2LH]\\nKhan, M., & Hanna, A. (2023). The Subjects and Stages of AI Dataset Development: A Framework for Dataset \\nAccountability. Ohio State Technology Law Journal, 19. [perma.cc/XLG3-AP2J]\\nKinchin, N., & Mougouei, D. (2022). What Can Artificial Intelligence Do for Refugee Status Determination? A \\nProposal for Removing Subjective Fear. International Journal of Refugee Law. [perma.cc/3KER-DZ5R]\\nKoehn, P., & Knowles, R. (2017). Six Challenges for Neural Machine Translation. Proceedings of the First \\nWorkshop on Neural Machine Translation, 28‚Äì39. [perma.cc/9WSQ-HQJY]\\nKornai, A. (2013). Digital Language Death. PLOS ONE, 8(10), e77056. [perma.cc/MMZ8-C9VH]\\nKreutzer, J., Caswell, I., Wang, L., Wahab, A., van Esch, D., Ulzii-Orshikh, N., Tapo, A., Subramani, N., Sokolov, \\nA., Sikasote, C., Setyawan, M., Sarin, S., Samb, S., Sagot, B., Rivera, C., Rios, A., Papadimitriou, I., Osei, \\nS., Suarez, P. O., ‚Ä¶ Adeyemi, M. (2022). Quality at a Glance: An Audit of Web-Crawled Multilingual \\nDatasets. Transactions of the Association for Computational Linguistics, 10, 50‚Äì72. [perma.cc/YZ7B-\\nQ7PN]\\nKublik, V. (n.d.). EU/US Copyright Law and Implications on ML Training Data. Valohai. [perma.cc/LD3Z-\\nRVW7]\\nKupfer, M., & Muyumba, J. (2022). Language & Coloniality: Non-Dominant Languages in the Digital Landscape. \\nPollicy. [perma.cc/PM8N-Y9YW]\\nLauren√ßon, H., Saulnier, L., Wang, T., Akiki, C., Moral, A. V. del, Scao, T. L., Werra, L. V., Mou, C., Ponferrada, \\nE. G., Nguyen, H., Frohberg, J., ≈†a≈°ko, M., Lhoest, Q., McMillan-Major, A., Dupont, G., Biderman, \\nS., Rogers, A., Allal, L. B., Toni, F. D., ‚Ä¶ Jernite, Y. (2022, October 31). The BigScience ROOTS Corpus: \\nA 1.6TB Composite Multilingual Dataset. Thirty-sixth Conference on Neural Information Processing \\nSystems Datasets and Benchmarks Track. [perma.cc/QS7B-YNYU]\\n44\\nLost in Translation\\nCDT Research\\nLauscher, A., Ravishankar, V., Vuliƒá, I., & Glava≈°, G. (2020). From Zero to Hero: On the Limitations of Zero-\\nShot Language Transfer with Multilingual Transformers. Proceedings of the 2020 Conference on Empirical \\nMethods in Natural Language Processing (EMNLP), 4483‚Äì4499. [perma.cc/ZJ3R-95JM]\\nLees, A., Sorensen, J., & Kivlichan, I. (2020). Jigsaw @ AMI and HaSpeeDe2: Fine-Tuning a Pre-Trained \\nComment-Domain BERT Model. In V. Basile, D. Croce, M. Maro, & L. C. Passaro (Eds.), EVALITA \\nEvaluation of NLP and Speech Tools for Italian‚ÄîDecember 17th, 2020 (pp. 40‚Äì47). Accademia University \\nPress. [perma.cc/9D4M-RSCL]\\nLees, A., Tran, V. Q., Tay, Y., Sorensen, J., Gupta, J., Metzler, D., & Vasserman, L. (2022). A New Generation \\nof Perspective API: Efficient Multilingual Character-level Transformers. Proceedings of the 28th ACM \\nSIGKDD Conference on Knowledge Discovery and Data Mining, 3197‚Äì3207. [perma.cc/5K82-WG8J]\\nLibovick√Ω, J., Rosa, R., & Fraser, A. (2019). How Language-Neutral is Multilingual BERT? (arXiv:1911.03310). \\narXiv. [perma.cc/96RW-WXBL]\\nLin, X. V., Mihaylov, T., Artetxe, M., Wang, T., Chen, S., Simig, D., Ott, M., Goyal, N., Bhosale, S., Du, J., \\nPasunuru, R., Shleifer, S., Koura, P. S., Chaudhary, V., O‚ÄôHoro, B., Wang, J., Zettlemoyer, L., Kozareva, Z., \\nDiab, M., ‚Ä¶ Li, X. (2022). Few-shot Learning with Multilingual Generative Language Models. Proceedings \\nof the 2022 Conference on Empirical Methods in Natural Language Processing, 9019‚Äì9052. [perma.\\ncc/5QY9-97G5]\\nLokhov, I. (2021, January 28). Why are there so many Wikipedia articles in Swedish and Cebuano? Datawrapper \\nBlog. [perma.cc/WDL2-TF53]\\nLuccioni, A., & Viviano, J. (2021). What‚Äôs in the Box? An Analysis of Undesirable Content in the Common Crawl \\nCorpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the \\n11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), 182‚Äì189. \\n[perma.cc/2QQU-NRPB]\\nLunden, I. (2023, March 14). Nabla, a digital health startup, launches Copilot, using GPT-3 to turn patient \\nconversations into action. TechCrunch. [perma.cc/MK55-SV54]\\nMartin, G., Mswahili, M. E., Jeong, Y.-S., & Woo, J. (2022). SwahBERT: Language Model of Swahili. Proceedings \\nof the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: \\nHuman Language Technologies, 303‚Äì313. [perma.cc/3ZP6-V6AJ]\\nMartin, L., Muller, B., Su√°rez, P. J. O., Dupont, Y., Romary, L., de la Clergerie, √â. V., Seddah, D., & Sagot, B. \\n(2020). CamemBERT: A Tasty French Language Model. Proceedings of the 58th Annual Meeting of the \\nAssociation for Computational Linguistics, 7203‚Äì7219. [perma.cc/76EU-4LTM]\\nMasakhane. (n.d.). Masakhane. Retrieved December 21, 2022. [perma.cc/A7SA-ALPM]\\nMaundu, C. (2023, February 21). How language denies people access to public information. Nation. [perma.\\ncc/8C4B-JS3Y]\\nMazzucato, M. (2014). The entrepreneurial state: Debunking public vs. private sector myths (Revised edition). \\nAnthem Press.\\nMeta AI. (2019, November 7). XLM-R: State-of-the-art cross-lingual understanding through self-supervision. \\nMeta AI. [perma.cc/J55N-4MV5]\\n45\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nMicallef, K., Gatt, A., Tanti, M., van der Plas, L., & Borg, C. (2022). Pre-training Data Quality and Quantity for a \\nLow-Resource Language: New Corpus and BERT Models for Maltese. Proceedings of the Third Workshop \\non Deep Learning for Low-Resource Natural Language Processing, 90‚Äì101. [perma.cc/QY8V-9Q6H]\\nMikolov, T., Chen, K., Corrado, G., & Dean, J. (2013, September 6). Efficient Estimation of Word Representations \\nin Vector Space. International Conference on Learning Representations. [perma.cc/T869-PDX4]\\nMuller, B., Anastasopoulos, A., Sagot, B., & Seddah, D. (2021). When Being Unseen from mBERT is just the \\nBeginning: Handling New Languages With Multilingual Language Models. Proceedings of the 2021 \\nConference of the North American Chapter of the Association for Computational Linguistics: Human \\nLanguage Technologies, 448‚Äì462. [perma.cc/J5MH-QDW3]\\nNadkarni, P. M., Ohno-Machado, L., & Chapman, W. W. (2011). Natural language processing: An introduction. \\nJournal of the American Medical Informatics Association\\u202f: JAMIA, 18(5), 544‚Äì551. [perma.cc/72PK-\\nUGK9]\\nNekoto, W., Marivate, V., Matsila, T., Fasubaa, T., Fagbohungbe, T., Akinola, S. O., Muhammad, S., Kabongo \\nKabenamualu, S., Osei, S., Sackey, F., Niyongabo, R. A., Macharm, R., Ogayo, P., Ahia, O., Berhe, M. \\nM., Adeyemi, M., Mokgesi-Selinga, M., Okegbemi, L., Martinus, L., ‚Ä¶ Bashir, A. (2020). Participatory \\nResearch for Low-resourced Machine Translation: A Case Study in African Languages. Findings of the \\nAssociation for Computational Linguistics: EMNLP 2020, 2144‚Äì2160. [perma.cc/5BVM-LUMM]\\nNguer, E. M., Lo, A., Dione, C. M. B., Ba, S. O., & Lo, M. (2020). SENCORPUS: A French-Wolof Parallel \\nCorpus. Proceedings of the Twelfth Language Resources and Evaluation Conference, 2803‚Äì2811. [perma.cc/\\nNBE7-QCZW]\\nNguyen, T. (2020, November 27). Why fake news is so hard to combat in Asian American communities. Vox. \\n[perma.cc/45GF-UUEC]\\nNicholas, G. (2020). Explaining Algorithmic Decisions. Georgetown Law Technology Review, 4(711), 20. [perma.\\ncc/UD7D-HF6F]\\nNicholas, G. (2022). Shedding Light on Shadowbanning. Center for Democracy & Technology. [perma.cc/D2TS-\\nY92D]\\nNkemelu, D., Shah, H., Essa, I., & Best, M. L. (2023). Tackling Hate Speech in Low-resource Languages with \\nContext Experts. International Conference on Information & Communication Technologies and \\nDevelopment, Washington, USA. [perma.cc/5QK7-GTMR]\\nNLLB Team, Costa-juss√†, M. R., Cross, J., √áelebi, O., Elbayad, M., Heafield, K., Heffernan, K., Kalbassi, E., Lam, \\nJ., Licht, D., Maillard, J., Sun, A., Wang, S., Wenzek, G., Youngblood, A., Akula, B., Barrault, L., Gonzalez, \\nG. M., Hansanti, P., ‚Ä¶ Wang, J. (2022). No Language Left Behind: Scaling Human-Centered Machine \\nTranslation (arXiv:2207.04672). arXiv. [perma.cc/LZH5-DMUA]\\nOkerlund, J., Klasky, E., Middha, A., Kim, S., Rosenfeld, H., Kleinman, M., & Parthasarathy, S. (2022). What‚Äôs \\nin the Chatterbox? Large Language Models, Why They Matter, and What We Should Do About Them. \\nUniversity of Michigan. [perma.cc/8SXE-RSYE]\\nOpenAI. (2023). GPT-4 Technical Report (arXiv:2303.08774). arXiv. [perma.cc/6ACB-LZYC]\\n46\\nLost in Translation\\nCDT Research\\nOrife, I., Kreutzer, J., Sibanda, B., Whitenack, D., Siminyu, K., Martinus, L., Ali, J. T., Abbott, J., Marivate, V., \\nKabongo, S., Meressa, M., Murhabazi, E., Ahia, O., van Biljon, E., Ramkilowan, A., Akinfaderin, A., \\n√ñktem, A., Akin, W., Kioko, G., ‚Ä¶ Bashir, A. (2020). Masakhane‚ÄîMachine Translation For Africa \\n(arXiv:2003.11529). arXiv. [perma.cc/84Z4-S7AZ]\\nPatel, F., Levinson-Waldman, R., Koreh, R., & DenUyl, S. (2020). Social Media Monitoring. Brennan Center for \\nJustice. [perma.cc/N5LF-ZKP2]\\nPhillipson, R. (1992). Linguistic Imperialism. Oxford University Press.\\nPires, T., Schlinger, E., & Garrette, D. (2019). How Multilingual is Multilingual BERT? Proceedings of the 57th \\nAnnual Meeting of the Association for Computational Linguistics, 4996‚Äì5001. [perma.cc/4DPF-LWWX]\\nPng, M.-T. (2022). At the Tensions of South and North: Critical Roles of Global South Stakeholders in AI \\nGovernance. 2022 ACM Conference on Fairness, Accountability, and Transparency, 1434‚Äì1445. [perma.cc/\\nZ7HD-3T4A]\\nPolignano, M., Basile, P., Degemmis, M., Semeraro, G., & Basile, V. (2019). AlBERTo: Italian BERT Language \\nUnderstanding Model for NLP Challenging Tasks Based on Tweets. Sixth Italian Conference on \\nComputational Linguistics, Bari, Italy. [perma.cc/RBY9-4JHJ]\\nPrabhakaran, V., Mitchell, M., Gebru, T., & Gabriel, I. (2022). A Human Rights-Based Approach to Responsible AI \\n(arXiv:2210.02667). arXiv. [perma.cc/R97H-WQSK]\\nPrates, M., Avelar, P., & Lamb, L. (2020). Assessing gender bias in machine translation: A case study with Google \\nTranslate. Neural Computing and Applications, 32. [perma.cc/CGK2-NMU2]\\nPym, A., Ayvazyan, N., & Prioleau, J. M. (2022). Should raw machine translation be used for public-health \\ninformation? Suggestions for a multilingual communication policy in Catalonia. Just. Journal of Language \\nRights & Minorities, Revista de Drets Ling√º√≠stics i Minories, 1(1‚Äì2), 71‚Äì99. [perma.cc/HSA8-TB3F]\\nRaji, D., Denton, E., Bender, E. M., Hanna, A., & Paullada, A. (2021). AI and the Everything in the Whole \\nWide World Benchmark. Proceedings of the Neural Information Processing Systems Track on Datasets and \\nBenchmarks, 1. [perma.cc/EX84-X9BQ]\\nRazeghi, Y., Logan IV, R. L., Gardner, M., & Singh, S. (2022). Impact of Pretraining Term Frequencies on Few-\\nShot Numerical Reasoning. Findings of the Association for Computational Linguistics: EMNLP 2022, \\n840‚Äì854. [perma.cc/SMG9-BSKV]\\nReid, M., & Artetxe, M. (2022). On the Role of Parallel Data in Cross-lingual Transfer Learning \\n(arXiv:2212.10173). arXiv. [perma.cc/83GW-CVXX]\\nRichter, F. (n.d.). English Is the Internet‚Äôs Universal Language. Statista Infographics. Retrieved December 14, \\n2022, from [perma.cc/WW7B-7X37]\\nRionda, V. P. S., & Mejia, J. C. U. (2021). PretorIA y la automatizaci√≥n del procesamiento de causas de derechos \\nhumanos. Derechos Digitales and Dejusticia. [perma.cc/65MQ-X484]\\nRowe, J. (2022, March 2). Marginalised languages and the content moderation challenge. Global Partners Digital. \\n[perma.cc/GU4K-5HBE]\\n47\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nRuder, S., Constant, N., Botha, J., Siddhant, A., Firat, O., Fu, J., Liu, P., Hu, J., Garrette, D., Neubig, G., & \\nJohnson, M. (2021). XTREME-R: Towards More Challenging and Nuanced Multilingual Evaluation. \\nProceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, 10215‚Äì10245. \\n[perma.cc/W4TJ-SGTB]\\nSanta Clara Principles. (2021). Santa Clara Principles on Transparency and Accountability in Content Moderation. \\nSanta Clara Principles. [perma.cc/T623-AVW6]\\nSanty, S., Kummerfeld, J., & Rubio, H. (2023). Languages mentioned in Paper Abstracts. ACL Rolling Review. \\n[perma.cc/EQU9-5CWQ]\\nSavoldi, B., Gaido, M., Bentivogli, L., Negri, M., & Turchi, M. (2021). Gender Bias in Machine Translation. \\nTransactions of the Association for Computational Linguistics, 9, 845‚Äì874. [perma.cc/9K3F-5VBZ]\\nSchwenk, H. (2019, January 22). LASER natural language processing toolkit‚ÄîEngineering at Meta. Meta AI. \\n[perma.cc/46JG-AZ4T]\\nSengupta, P. B., Claudia Pozo, Anasuya. (2022, March 31). Does the internet speak your language? Launching the \\nfirst-ever State of the Internet‚Äôs Languages report. Whose Knowledge? [https://perma.cc/9KCX-M863]\\nSharir, O., Peleg, B., & Shoham, Y. (2020). The Cost of Training NLP Models: A Concise Overview \\n(arXiv:2004.08900). arXiv. [perma.cc/8KVV-C6P2]\\nShenkman, C., Thakur, D., & Llans√≥, E. (2021). Do You See What I See? Capabilities and Limits of Automated \\nMultimedia Content Analysis. Center for Democracy & Technology. [perma.cc/W85T-HQQF]\\nSrivastava, A., Rastogi, A., Rao, A., Shoeb, A. A. M., Abid, A., Fisch, A., Brown, A. R., Santoro, A., Gupta, A., \\nGarriga-Alonso, A., Kluska, A., Lewkowycz, A., Agarwal, A., Power, A., Ray, A., Warstadt, A., Kocurek, A. \\nW., Safaya, A., Tazarv, A., ‚Ä¶ Wu, Z. (2022). Beyond the Imitation Game: Quantifying and extrapolating the \\ncapabilities of language models (arXiv:2206.04615). arXiv. [perma.cc/278S-ZJV9]\\nStadthagen-Gonzalez, H., Imbault, C., P√©rez S√°nchez, M. A., & Brysbaert, M. (2017). Norms of valence and \\narousal for 14,031 Spanish words. Behavior Research Methods, 49(1), 111‚Äì123. [perma.cc/7FWX-Z3JD]\\nStrubell, E., Ganesh, A., & McCallum, A. (2019). Energy and Policy Considerations for Deep Learning in NLP. \\nProceedings of the 57th Annual Meeting of the Association for Computational Linguistics, 3645‚Äì3650. \\n[perma.cc/9P4Y-J4HT]\\nTalat, Z., N√©v√©ol, A., Biderman, S., Clinciu, M., Dey, M., Longpre, S., Luccioni, S., Masoud, M., Mitchell, M., \\nRadev, D., Sharma, S., Subramonian, A., Tae, J., Tan, S., Tunuguntla, D., & Wal, O. van der. (2022). You \\nreap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings. Proceedings of \\nBigScience Episode #5, 26‚Äì41. [perma.cc/3ECR-4E7U]\\nTattle. (n.d.). Uli. [perma.cc/4AB2-D4GX]\\nTay, Y., Tran, V. Q., Ruder, S., Gupta, J., Chung, H. W., Bahri, D., Qin, Z., Baumgartner, S., Yu, C., & Metzler, D. \\n(2022, February 23). Charformer: Fast Character Transformers via Gradient-based Subword Tokenization. \\nInternational Conference on Learning Representations 2022. [perma.cc/YRL4-E7DT]\\nTeich, E. (2003). Cross-Linguistic Variation in System and Text: A Methodology for the Investigation of \\nTranslations and Comparable Texts. In Cross-Linguistic Variation in System and Text. De Gruyter Mouton. \\n[perma.cc/L8A8-RH8B]\\n48\\nLost in Translation\\nCDT Research\\nTorbati, Y. (2019, September 26). Google Says Google Translate Can‚Äôt Replace Human Translators. Immigration \\nOfficials Have Used It to Vet Refugees. ProPublica. [perma.cc/ZUN6-LHA5]\\nToyama, K. (2015). Geek heresy: Rescuing social change from the cult of technology. PublicAffairs.\\nTsvetkov, Y., Sitaram, S., Faruqui, M., Lample, G., Littell, P., Mortensen, D., Black, A. W., Levin, L., & Dyer, \\nC. (2016). Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic Representation \\nLearning. Proceedings of the 2016 Conference of the North American Chapter of the Association for \\nComputational Linguistics: Human Language Technologies, 1357‚Äì1366. [perma.cc/4RES-KFNM]\\nUnited Nations Human Rights Office of the High Commissioner. (n.d.). \\u200bEconomic, social and cultural rights. \\nOHCHR. [perma.cc/Y6MK-SZZ4]\\nVallee, H. Q. la, & Duarte, N. (2019). Algorithmic Systems in Education: Incorporating Equity and Fairness When \\nUsing Student Data. Center for Democracy and Technology. [perma.cc/CC89-ZVNV]\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. (2017, \\nDecember 5). Attention Is All You Need. Advances in Neural Information Processing Systems. [perma.\\ncc/2ZDX-Z796]\\nVincent, J. (2022, November 2). Google plans giant AI language model supporting world‚Äôs 1,000 most spoken \\nlanguages. The Verge. [perma.cc/3Y48-X7WV]\\nVincent, J. (2023a, January 17). Getty Images is suing the creators of AI art tool Stable Diffusion for scraping its \\ncontent. The Verge. [perma.cc/4CXS-3WNN]\\nVincent, J. (2023b, March 15). OpenAI co-founder on company‚Äôs past approach to openly sharing research: ‚ÄúWe were \\nwrong.‚Äù The Verge. [perma.cc/DPL6-4PD2]\\nVitulli, M. A. (2018). Writing Women in Mathematics Into Wikipedia. Notices of the American Mathematical \\nSociety, 65(03), 330‚Äì334. [perma.cc/X73F-AZPM]\\nVolansky, V., Ordan, N., & Wintner, S. (2015). On the features of translationese. Digital Scholarship in the \\nHumanities, 30(1), 98‚Äì118. [perma.cc/7F8S-3YXK]\\nWang, C., Cho, K., & Gu, J. (2020). Neural Machine Translation with Byte-Level Subwords. Proceedings of the \\nAAAI Conference on Artificial Intelligence, 34(05), Article 05. [perma.cc/5DL7-XSSP]\\nWang, Z., K, K., Mayhew, S., & Roth, D. (2020). Extending Multilingual BERT to Low-Resource Languages. \\nFindings of the Association for Computational Linguistics: EMNLP 2020, 2649‚Äì2656. [perma.cc/ZNC8-\\nC9E7]\\nWilliams, A., Miceli, M., & Gebru, T. (2022). The Exploited Labor Behind Artificial Intelligence. Noƒìma. [perma.\\ncc/GE8H-7SUN]\\nWu, S., & Dredze, M. (2019). Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT. Proceedings \\nof the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International \\nJoint Conference on Natural Language Processing (EMNLP-IJCNLP), 833‚Äì844. [perma.cc/EJ3G-MFYN]\\nWu, S., & Dredze, M. (2020). Are All Languages Created Equal in Multilingual BERT? Proceedings of the 5th \\nWorkshop on Representation Learning for NLP, 120‚Äì130. [perma.cc/5E6X-NNAA]\\n49\\nLarge Language Models in Non-English Content Analysis\\nWorks Cited\\nYu, S., Sun, Q., Zhang, H., & Jiang, J. (2022). Translate-Train Embracing Translationese Artifacts. Proceedings of \\nthe 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), 362‚Äì\\n370. [perma.cc/7F8C-EYM6]\\nZhang, S., Frey, B., & Bansal, M. (2022, April 25). How can NLP Help Revitalize Endangered Languages? A Case \\nStudy and Roadmap for the Cherokee Language. Proceedings of the 60th Annual Meeting of the Association \\nfor Computational Linguistics (Volume 1: Long Papers). ACL 2022, Dublin, Ireland. [perma.cc/2XF2-\\n2GDC]\\nZhang, Y., Warstadt, A., Li, X., & Bowman, S. R. (2021). When Do You Need Billions of Words of Pretraining \\nData? Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the \\n11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 1112‚Äì1125. \\n[perma.cc/43ZK-2ZXC]\\ncdt.org\\ncdt.org/contact\\n202-637-9800\\n@CenDemTech\\nCenter for Democracy & Technology\\n1401 K Street NW, Suite 200\\nWashington, D.C. 20005'},\n",
       " {'title': 'Cedille: A large autoregressive French language model',\n",
       "  'text': 'CEDILLE:\\nA LARGE AUTOREGRESSIVE LANGUAGE MODEL IN FRENCH\\nMartin M√ºller‚àó\\nFlorian Laurent‚àó\\nCedille AI1\\nhello@cedille.ai\\nABSTRACT\\nScaling up the size and training of autoregressive language models has enabled novel ways of solving\\nNatural Language Processing tasks using zero-shot and few-shot learning. While extreme-scale\\nlanguage models such as GPT-3 offer multilingual capabilities, zero-shot learning for languages\\nother than English remain largely unexplored. Here, we introduce Cedille, a large open source\\nauto-regressive language model, speciÔ¨Åcally trained for the French language. Our results show that\\nCedille outperforms existing French language models and is competitive with GPT-3 on a range\\nof French zero-shot benchmarks. Furthermore, we provide an in-depth comparison of the toxicity\\nexhibited by these models, showing that Cedille marks an improvement in language model safety\\nthanks to dataset Ô¨Åltering.\\n1\\nIntroduction\\nLarge autoregressive language models have drawn wide\\nattention due to their zero-shot and few-shot capabilities,\\nallowing them to be used for a wide variety of Natural Lan-\\nguage Processing tasks without the need for task-speciÔ¨Åc\\nÔ¨Ånetuning or annotation data [1, 2]. Additionally, previ-\\nous work highlights the improved sample and compute\\nefÔ¨Åciency of larger models, generally justifying the move\\ntowards larger models [3].\\nAlthough large language models, such as GPT-3 [2], have\\nbeen trained on multilingual corpuses, the performance on\\nNLP tasks may vary signiÔ¨Åcantly between languages. As-\\nsessing zero-shot performance in non-English languages\\nis challenging due to the limited number of human-curated\\nbenchmarks available. However, with the exception of re-\\ncent work in machine translation [4], multilingual models\\ngenerally perform worse than mono- or bilingual language\\nmodels [5].\\nMonolingual autoregressive language models in French\\nhave previously been proposed. GPT-fr [6] and PAGnol [7]\\nhave been trained on Ô¨Åltered versions of Common Crawl2\\nand CCNet [8], respectively. Both works highlight the im-\\nportance of deduplicating and Ô¨Åltering of pre-training data\\nand use decoder-only transformer architectures, closely\\nfollowing the GPT models with model sizes reaching 1B\\nand 1.5B parameters, respectively. It‚Äôs worth noting that\\nthese works do not directly compare performance against\\nextreme-scale large multilingual models, such as GPT-3,\\nin particular with regard to zero-shot tasks.\\nPrevious work on the various encoding biases in large lan-\\nguage models highlights the importance of dataset curation\\nand documentation [9, 10]. Experiments conducted on\\nGPT-3 (which has been trained on 570GB of text data\\nfrom Common Crawl) show that the model may gener-\\nate toxic sentences even when prompted with non-toxic\\ntext [11]. Although applying Ô¨Åltering of training data using\\nautomated toxicity scores may introduce classiÔ¨Åer-speciÔ¨Åc\\nbiases [12], this technique remains more effective than\\n‚àóAuthors contributed equally, order is random\\n1Coteries SA, EPFL Innovation Park, Lausanne, Switzerland\\n2https://commoncrawl.org/\\narXiv:2202.03371v1  [cs.CL]  7 Feb 2022\\ndecoder-based detoxiÔ¨Åcation using methods such as swear\\nword Ô¨Ålters, PPLM [13], soft prompt tuning [14] or toxicity\\ncontrol tokens [15].\\nAs a consequence of the aforementioned risks, the trend\\ntowards larger models coincides with a trend to not release\\nmodels publicly. Controlling access to large language mod-\\nels may protect against certain bad actors but also limits\\nreproducibility and research efforts to mitigate the negative\\nproperties of such models. In a push for building models in\\nthe open, EleutherAI, a grassroot collective of researchers,\\nreleased GPT-J [16], a 6B parameter English language\\nmodel. This model was trained on the Pile [20], a 825GB\\ntext corpus by the same collective.\\nThe contributions of this paper are as follows: (1) We intro-\\nduce Cedille, an openly available French language model\\nbuilt on GPT-J, which is capable of achieving competitive\\nzero-shot performance against existing French language\\nmodels and GPT-3. (2) We release the toxicity scores\\nof the complete French C4 dataset, and (3) we provide a\\ncomparison of Cedille‚Äôs toxicity to other language models\\n(including GPT-3).\\n2\\nMethods\\n2.1\\nModel architecture\\nOur model architecture is identical to GPT-J [16]. GPT-J\\nuses a similar transformer architecture to the one used in\\n6.7B GPT-3 with three main differences: (1) No sparse\\nattention patterns were used; (2) the dimension of the atten-\\ntion head was increased from 128 to 256; and (3) Rotary\\npositional embeddings [17] were used instead of sinusoidal\\nembeddings. See Table 1 for more details.\\nNumber of parameters\\n6,053,381,344\\nNumber of layers N\\n28\\nModel dimensions dmodel\\n4096\\nFeed-forward dimension dff\\n16,384\\nNumber of attention heads nheads\\n16\\nHead dimension dhead\\n256\\nContext size\\n2048\\nVocab size\\n50,257\\nTable 1: Cedille model details.\\n2.2\\nTraining data\\nCedille is trained on a Ô¨Åltered version of the French part\\nof the multilingual C4 (mC4) dataset [18], which contains\\n332M documents or 1.1TB of uncompressed text. mC4 is\\nextracted from 71 Common Crawl snapshots (years 2013\\nto 2020) and uses CLD33, a small feed-forward neural net-\\nwork, for language identiÔ¨Åcation. mC4 Ô¨Åltered out pages\\nof less than three lines of at least 200 characters.\\nWe apply two different forms of Ô¨Åltering to the dataset 1)\\ntoxicity Ô¨Åltering using the Detoxify model [19] and 2) loss\\nÔ¨Åltering using the FlauBERT model [20]. For both Ô¨Åltering\\nsteps we compute the metric on a per document level of the\\nentire base dataset. In some cases chunking the documents\\ninto splits of 1200 characters was necessary due to the\\nÔ¨Åxed context size of the used models. Chunks smaller than\\n600 characters were not evaluated. The predictions were\\nrun on TPU v3-8 machines with 8-fold data parallelism\\neach.\\nEach percentile as well as the tails of both the loss and the\\ntoxicity distribution were sampled and manually inspected\\nto Ô¨Ånd suitable cut-off values for Ô¨Åltering. The inspection\\nof these samples revealed that both toxicity and loss values\\nwere appropriate4. We removed documents correspond-\\ning to a toxicity score higher than 0.5, corresponding to\\n0.25% of the content (0.8M documents). For the loss Ô¨Ål-\\ntering we considered the loss distribution of each of the\\n2048 Ô¨Åles and removed documents below a 0.2 percentile\\nloss (corresponding to a loss value of roughly 4.5) and\\nabove an absolute loss value of 10. This corresponded to\\na removal of roughly 20% of all documents (66M docu-\\nments). The combined Ô¨Åltering led to a Ô¨Ånal training set of\\n265M documents, which corresponds to roughly 773GB\\nof uncompressed text.\\nThe text was then run through the fix_text method of\\nthe Python library ftfy [21] using NFKC normalization\\nand encoded using the unmodiÔ¨Åed GPT-2 tokenizer. Docu-\\nments were simply concatenated and split into samples of\\n2049 tokens. The Ô¨Ånal training set yielded a total of 130M\\nsamples corresponding to 268B tokens.\\n2.3\\nTraining process\\nCedille was trained starting from the ofÔ¨Åcial GPT-J model\\ncheckpoint using the mesh-transformer-jax codebase [22].\\nTraining was conducted on a v3-128 TPU VM using 16-\\nfold data parallelism and 8-fold model sharding. For all\\nour experiments we used an effective batch size of 256.\\nWe used a linear warmup of 42k steps up to a peak learning\\nrate of 5e-5 and a cosine decay to 1e-5. Weight decay was\\nset to 0.1. Cedille was trained for 150k steps, which corre-\\nsponds to 0.3 epochs on the training set or 78.7B tokens.\\nThe starting and Ô¨Ånal training perplexities were 6.13 and\\n3.89, respectively. During training we monitored the loss\\non a dataset of French news stories published too recently\\nto be part of the training data.\\n3https://github.com/google/cld3\\n4Despite the positive visual inspection a bug in the loss computation was discovered much later in the analysis. Further investiga-\\ntion revealed that roughly 10% of samples were wrongly included in the Ô¨Ånal dataset as a result. Although it cannot be fully ruled\\nout we do not believe that a systematic bias was introduced.\\n2\\n2.4\\nEvaluation\\nZero-shot performance was evaluated using a forked ver-\\nsion of the lm-evaluation-harness codebase [23]. In par-\\nticular, we added a different way of evaluating perplexity\\nusing strides (see section 3.1), implemented the various\\nbenchmarks discussed in this work, and integrated the\\nmesh-transformer-jax library (for evaluating checkpoints\\non TPUs) and the Pagnol model families. Benchmarking\\nwas conducted on v3-8 TPU VMs and on A100 GPUs.\\nToxicity evaluation was conducted using a modiÔ¨Åed ver-\\nsion of the real-toxicity-prompts codebase5. The main\\ndifference is the use of the Detoxify model in order\\nto predict toxicity (see section 4).\\nOur adapted code-\\nbase is available at https://github.com/coteries/\\nreal-toxicity-prompts.\\n3\\nTasks\\n3.1\\nPerplexity\\nModel\\n#params\\nByte-PPL\\nToken-PPL\\nGPT-3 (ada)\\n1.3Ba\\n1.930\\n7.952\\nGPT-3 (babbage)\\n6.7B\\n1.973\\n6.447\\nGPT-3 (curie)\\n13B\\n1.809\\n5.082\\nGPT-3 (davinci)\\n175B\\n1.656\\n3.993\\nGPT-J\\n6.05B\\n1.746\\n5.797\\nCedille\\n6.05B\\n1.646\\n3.932\\nPagnol (small)\\n124M\\n1.852\\n17.802\\nPagnol (medium)\\n335M\\n1.775\\n14.623\\nPagnol (large)\\n773M\\n1.725\\n12.791\\nGPT-fr (base)\\n1B\\n2.090\\n11.882\\nTable 2: Byte-level and token-level perplexity scores on the\\nWikiText-fr benchmark (lower is better).\\naOpenAI hasn‚Äôt ofÔ¨Åcially disclosed the size of the models\\nprovided by their API, however recent experiments suggest the\\nmapping presented in the table [24].\\nZero-shot perplexity was evaluated on the test subset of\\nthe WikiText-fr6 dataset [6], containing articles from the\\nFrench Wikipedia which are part of the ‚Äúquality articles‚Äù or\\n‚Äúgood articles‚Äù categories, similar to the English WikiText-\\n103 dataset [25]. The test set contains 589k words or 3.7M\\ncharacters of cleaned French text from 60 articles. We eval-\\nuated perplexity by concatenating the text without further\\npreprocessing and using a sliding window approach [26]\\nwith a stride of 512 tokens. Therefore models with a con-\\ntext window of 1024 tokens (GPT-fr, Pagnol) had 512\\ntokens of context, whereas models with a context window\\nof 2048 tokens had 1536 tokens of context. Table 2 shows\\nthe summed log likelihoods both normalized by number\\nof characters and by number of tokens. Note that the\\ntoken-level perplexity for GPT-fr and Pagnol is not directly\\ncomparable to the other models, as they are not using the\\n(English) GPT-2 tokenizer.\\nCedille achieves the lowest perplexity score out of the an-\\nalyzed models, clearly outcompeting existing French lan-\\nguage models and narrowly outcompeting GPT-3 (davinci).\\nUnsurprisingly, models with larger context windows gen-\\nerally perform better at this task. It is noteworthy that the\\ntest dataset is likely contained in the training data as no\\ndataset-speciÔ¨Åc Ô¨Åltering of the training data was conducted\\nas part of this work.\\n3.2\\nSummarization\\nWe evaluated the summarization capabilities on the Orange-\\nSum benchmark, as introduced in the BARThez work [27]\\nas a French equivalent of XSum [28]. The benchmark con-\\ntains news articles published between February 2011 and\\nSeptember 2020, scraped from the French website ‚ÄúOrange\\nActu‚Äù. The models were given the news article in the test\\nsubset using the following prompt:\\n{article text}\\\\nPour r√©sumer :\\nThe models were tasked to generate 100 tokens using top-k\\nof 2 and a temperature of 1, following the methodology\\nin [1]. We used greedy decoding (top-k = 1) for GPT-3,\\nsince at the time of this work being conducted, the API\\ndidn‚Äôt allow for other top-k values. When the prompt ex-\\nceeded the context window of the model it was left-side\\ntruncated. The output was then clipped to contain at most 3\\nsentences (using simplistic sentence splitting at the period\\ncharacter). Table 3 shows the ROUGE score [29] of the\\noutput compared to the title of the corresponding articles.\\nModel\\nR1\\nR2\\nRL\\nGPT-3 (ada)\\n13.95\\n4.75\\n11.59\\nGPT-3 (babbage)\\n4.62\\n1.76\\n3.86\\nGPT-3 (curie)\\n5.28\\n2.21\\n4.42\\nGPT-3 (davinci)\\n15.49\\n5.82\\n13.05\\nGPT-J\\n14.46\\n4.72\\n11.68\\nCedille\\n14.74\\n4.83\\n11.86\\nPagnol (small)\\n8.52\\n1.61\\n7.24\\nPagnol (medium)\\n8.98\\n1.86\\n7.55\\nPagnol (large)\\n9.19\\n1.85\\n7.71\\nGPT-fr (base)\\n10.15\\n2.60\\n8.27\\nTable 3: Performance of summarization in French. Shown are\\nthe ROUGE scores on the OrangeSum dataset (higher is better).\\nGenerally, we observed some variance due to the non-\\ngreedy sampling procedure. However, computational limi-\\n5https://github.com/allenai/real-toxicity-prompts\\n6https://huggingface.co/datasets/asi/wikitext_fr\\n3\\ntations and cost made it difÔ¨Åcult to estimate this variance.\\nWe also observed that the choice of the preÔ¨Åx (‚ÄúPour r√©-\\nsumer :‚Äù) strongly inÔ¨Çuences the scores. Some of the\\nevaluated models are also more likely to generate bullet\\npoint summaries, rather than a single sentence, which may\\nagain lead to different sentence splitting. This may ex-\\nplain the increased score for GPT-3 (ada) compared to\\nlarger GPT-3 models. Nevertheless, the scores provided\\nin Table 3 give some rough indication of summarization\\nperformance.\\n3.3\\nQuestion Answering (QA)\\nQuestion answering (QA) was evaluated on FQuAD\\n(French Question Answering Dataset) [30], a dataset in-\\nspired by the English SQuAD equivalent [31]. The models\\nwere evaluated on the validation subset, which contains\\n3188 human-curated question-answer pairs, based on 768\\nhigh-quality French Wikipedia articles.\\nModel\\nF1\\nExact match (%)\\nGPT-3 (ada)\\n19.09\\n4.48\\nGPT-3 (babbage)\\n26.16\\n8.81\\nGPT-3 (curie)\\n39.49\\n17.84\\nGPT-3 (davinci)\\n-\\n-\\nGPT-J\\n26.14\\n6.96\\nCedille\\n34.59\\n12.23\\nPagnol (small)\\n10.66\\n0.43\\nPagnol (medium)\\n13.80\\n0.84\\nPagnol (large)\\n17.67\\n2.72\\nGPT-fr (base)\\n15.15\\n2.03\\nTable 4: Question-answering F1 and exact match scores in\\nFrench on the FQuAD benchmark (higher is better).\\nThe models were evaluated using the SQuAD v2 met-\\nric [31], which also takes into consideration ‚Äúno answer‚Äù\\nprobabilities, i.e. cases when no answer to a particular\\nquestion is possible given the context. The models were\\ntasked to generate 100 tokens and at most 1 sentence using\\ngreedy sampling and the following prompt:\\nTitre:\\n{title}\\\\nContexte:\\n{context}\\\\n\\\\n\\nQuestion:\\n{question}\\\\n\\\\nR√©ponse:\\nThe ‚Äúno answer‚Äù probabilities were calculated against the\\nstring:\\n{prompt} Sans r√©ponse.\\nHowever, all questions in the evaluated data contained\\nexactly one answer.\\nThe results in Table 4 show that GPT-3 is very competitive\\non this task, with GPT-3 (curie) outperforming Cedille\\nand all other evaluated models. GPT-3 (davinci) was not\\nevaluated on this task for cost reasons, as OpenAI did not\\nsupport our request for funding at the time of writing. The\\nresults may be contrasted to a Ô¨Ånetuned version of Camem-\\nBERT [32] which yields F1 of 88% and best match of 78%\\non this dataset [30].\\n3.4\\nTranslation\\nZero-shot translation was evaluated for the language pair\\nEnglish and French on the WMT14 dataset [33]. Tradi-\\ntionally, such benchmarks are evaluated using the BLEU\\nscore [34]. The datasets contains 3003 samples each and\\nare provided by the sacrebleu library [35]. The zero-shot\\ntask is formulated using the following pattern:\\n{source_lang} phrase:\\n{text}\\\\n{target_lang}\\nphrase:\\nWhere source_lang and target_lang are French and\\nEnglish, respectively, depending on the direction. Greedy\\nsampling is used to generate 256 tokens. The output was\\nclipped to at most 1 sentence.\\nCedille outperforms other models for the direction English\\nto French, highlighting the strong French writing capabil-\\nities (see Table 5). Likewise, GPT-3 (davinci) performs\\nbetter for the French to English direction. Monolingual\\nmodels, such as Pagnol and GPT-fr perform worse at this\\ntask presumably due to the limited amount of English that\\nwas part of their pretraining data. Often, smaller models\\nwere unable to follow the instructions and simply repeated\\nthe context in the given language. As opposed to summa-\\nrization and question-answering benchmarks, the target is\\ngenerally not part of the context, therefore simply repeating\\nthe input normally results in a low score.\\nAs of 2021, dedicated neural machine translation solutions,\\nsuch as Very Deep Transformers, reach 46.4 BLEU for\\nEnglish to French translation [36].\\nModel\\nBLEU (en‚Üífr)\\nBLEU (fr‚Üíen)\\nGPT-3 (ada)\\n2.71\\n16.64\\nGPT-3 (babbage)\\n3.20\\n24.56\\nGPT-3 (curie)\\n13.45\\n27.15\\nGPT-3 (davinci)\\n20.40\\n27.70\\nGPT-J\\n14.71\\n26.06\\nCedille\\n24.89\\n20.59\\nPagnol (small)\\n0.76\\n1.20\\nPagnol (medium)\\n1.07\\n1.48\\nPagnol (large)\\n1.06\\n3.47\\nGPT-fr (base)\\n1.47\\n1.57\\nTable 5: BLEU scores for ranslation on WMT14 for the English-\\nFrench language pair (higher is better).\\n4\\nToxicity analysis\\nIn order to evaluate the toxicity of the model we closely\\nfollowed the work conducted in [11]. We studied the case\\n4\\nof unprompted (i.e. conditioned only on a start-of-sentence\\ntoken) and prompted generation.\\nThe original work in [11] used the Perspective API, a ser-\\nvice that uses machine learning classiÔ¨Åers to estimate the\\nperceived toxicity of text. In this work, we employ the\\nDetoxify tool [19] instead. We made this choice as the\\nunderlying models used by Perspective evolve with time\\nand are not released publicly, which limits experimental\\nreproducibility.\\nDetoxify assigns a toxicity score between 0 and 1, with 1\\ndenoting ‚Äúa very hateful, aggressive, or disrespectful com-\\nment‚Äù. We refer to content with a score > 0.5 as ‚Äútoxic‚Äù.\\nWe use the ‚Äúmultilingual‚Äù Detoxify model from release\\nv0.4.0, and compare the toxicity of Cedille output to 3\\nother models: GPT-2 (117M), GPT-3 (davinci), GPT-J and\\nGPT-fr (base).\\n4.1\\nUnprompted toxicity\\nFor the unprompted toxicity we analyze the expected max-\\nimum toxicity, i.e. the expected worst-case toxicity score\\ngiven N unprompted generations. Figure 1 shows boot-\\nstrap estimates (1000 iterations) of the expected maximum\\ntoxicity for N generations with variance bounds as shades.\\nIn this setting, Cedille consistently generates content with\\nlower expected maximum toxicity than GPT-2, GPT-J, and\\nGPT-3. After 100 generations, this value is under 0.5 for\\nGPT-fr and Cedille (0.41 and 0.48, respectively), which\\nmeans that the worst content from these models is not\\nexpected to be toxic. This is in contrast with the other\\nmodels, for which maximum expected toxicity values are\\n0.64, 0.54 and 0.56.\\nAfter 10K generations, Cedille and GPT-fr are the only\\nmodels for which the expected worst outputs don‚Äôt reach\\na toxicity level of 1.0 We expect all other models to have\\nat least one output that is maximally toxic as detected by\\nDetoxify. Generally the two models that perform best are\\nGPT-fr and Cedille, which were both trained on carefully\\nÔ¨Åltered datasets, pointing to the importance of dataset cu-\\nration when considering the safety of language models.\\nWithout any conditioning, the multilingual models almost\\nexclusively generate English content: this is the case of\\nGPT-2, GPT-J and GPT-3. However, with the Detoxify\\nmodel being multilingual, the toxicity scores remain com-\\nparable.\\n4.2\\nPrompted toxicity\\nFor prompted toxicity we used a set of 50 French prompts\\nwith values of toxicity spanning the full range, with a mean\\nof 0.34. The set of prompts was selected randomly from\\nthe RealToxicityPrompt dataset and manually translated\\nfrom English to French by a French native speaker. We\\nused a smaller number of prompts than in [11] due to lim-\\nited computing resources. The French prompts cause the\\nmultilingual models (GPT-2, GPT-J and GPT-3) to gener-\\nate French content. For each prompt, each model generates\\n50 completions. We used nucleus sampling with p = 0.9\\nto generate up to 20 tokens per continuation, following the\\nprotocol from [11].\\nTable 6 shows two properties: 1) the expected maximum\\ntoxicity over 25 generations (with standard deviations in\\nparentheses) and 2) the empirical probability of generating\\ntoxic text at least once among 25 generations.\\nModel\\nExp. max tox.\\nProb. toxicity\\nGPT-2a\\n0.63 (0.23)\\n0.66\\nGPT-3 (davinci)\\n0.68 (0.27)\\n0.74\\nGPT-J\\n0.73 (0.26)\\n0.78\\nCedille\\n0.66 (0.27)\\n0.72\\nGPT-fr (base)\\n0.73 (0.27)\\n0.78\\nTable 6: Toxicity of prompted generations.\\naUpon manual inspection, it appeared that GPT-2 is unable\\nto generate sensible French content, and as such the resulting\\ntoxicity values can‚Äôt be compared to other models.\\nFor both properties, Cedille outperforms the other models.\\nWe can see again that Cedille is less toxic than GPT-J,\\nindicating that the training not only improved the model‚Äôs\\nFrench capabilities, but also increased its safety.\\n5\\nConclusions\\nIn this work we introduced Cedille, a large auto-regressive\\nFrench language model.\\nOur work shows that mono-\\nlingual models such as Cedille, can be competitive com-\\npared to extreme scale multilingual language models, i.e.\\nGPT-3. Compared to existing French language models,\\nCedille is capable of performing well on zero-shot natural\\nlanguage understanding tasks and reaches a new state-of-\\nthe-art perplexity score on the French WikiText corpus.\\nLastly, our approach of toxicity Ô¨Åltering of the training\\ndata led to a decrease in both maximum toxicity as well as\\nthe likelihood of toxic output.\\nAs a result of the Ô¨Ånetuning approach starting from GPT-J,\\nCedille has been exposed to a large amount of both English\\nand French language data from the Pile and French mC4.\\nThis combination allows for competitive zero-shot trans-\\nlation scores for the French-English language pair. Early\\nexperiments indicate that Ô¨Ånetuning an existing English\\nlanguage model and adapting it to French is more efÔ¨Åcient\\neven with considerable compute and data investments (see\\nappendix).\\nGiven the scarcity of high-quality human-curated datasets\\nin non-English languages it is especially challenging to\\nprovide a fair comparison of language models. For the\\nzero-shot benchmarks we observed a high degree of sen-\\nsitivity towards evaluation settings such as preÔ¨Åxes, sam-\\npling parameters, and type of evaluation metric. The scores\\n5\\n10\\n100\\n1K\\n10K\\nNumber of Generations\\n0.2\\n0.3\\n0.4\\n0.5\\n0.6\\n0.7\\n0.8\\n0.9\\n1.0\\nExpected Maximum Toxicity\\nGPT-2\\nGPT-3\\nGPT-J\\nGPT-fr\\nCedille\\nFigure 1: Unprompted expected maximum toxicity against increasing numbers of generations.\\nshould therefore only be considered as a rough guidance\\nand model performance may be highly task speciÔ¨Åc. In this\\nwork we haven‚Äôt provided performance metrics for other\\nNLP tasks such as text classiÔ¨Åcation or word sense disam-\\nbiguation. Furthermore, this work focused on zero-shot\\nevaluation, ignoring few-shot or Ô¨Ånetuning approaches.\\nApart from training larger models, a possible path for-\\nward is to deduplicate training data. This method has been\\nshown to improve end-task performance signiÔ¨Åcantly [8,\\n37] but was not conducted as part of this work. In order to\\nfurther reduce language model toxicity, a possible direc-\\ntion is the integration of human feedback in the training\\nprocess in order to reduce toxic output generation [38].\\nData availability.\\nCedille is available under the MIT\\nLicense on the Hugging Face model hub:\\nhttps:\\n//huggingface.co/Cedille/fr-boris, and on our\\nGitHub repository: https://github.com/coteries/\\ncedille-ai. Regarding the French mC4 toxicity scores\\nand toxicity analysis code, please refer to: https://\\ngithub.com/coteries/real-toxicity-prompts.\\nFunding.\\nThis work was funded by, and conducted at,\\nCoteries SA7. The model was trained on Cloud TPUs pro-\\nvided by Google‚Äôs TPU Research Cloud program.\\nAcknowledgments.\\nWe thank S√©bastien Flury and\\nFran√ßois Bochatay for their guidance and feedback. Tiago\\nCastanheiro, Flavien Bonvin and Livio Gamassia imple-\\nmented the web-based Playground used to evaluate the\\nmodel. Tiago Castanheiro, Flavien Bonvin, Sacha To-\\nufani, Livio Gamassia, and Kasper Andkjaer tested out\\nmultiple versions of the model. S√©bastien Von Roth de-\\nsigned the Cedille logo as well as the visual design of the\\nPlayground and Cedille website8. Sonja Dossenbach as-\\nsembled the dataset of recent French news. We are grateful\\nto EleutherAI for publicly releasing the GPT-J model and\\noffering us support on their Discord server9. We thank the\\nTPU Research Cloud team for their access to Cloud TPUs\\nand their support.\\nReferences\\n[1]\\nAlec Radford et al. ‚ÄúLanguage models are unsu-\\npervised multitask learners‚Äù. In: OpenAI blog 1.8\\n(2019), p. 9.\\n[2]\\nTom B Brown et al. ‚ÄúLanguage models are few-\\nshot learners‚Äù. In: arXiv preprint arXiv:2005.14165\\n(2020).\\n[3]\\nJared Kaplan et al. ‚ÄúScaling laws for neu-\\nral\\nlanguage\\nmodels‚Äù.\\nIn:\\narXiv\\npreprint\\narXiv:2001.08361 (2020).\\n[4]\\nChau Tran et al. ‚ÄúFacebook AI WMT21 news\\ntranslation task submission‚Äù. In: arXiv preprint\\narXiv:2108.03265 (2021).\\n[5]\\nNaveen Arivazhagan et al. ‚ÄúMassively multilingual\\nneural machine translation in the wild: Findings and\\nchallenges‚Äù. In: arXiv preprint arXiv:1907.05019\\n(2019).\\n7https://coteries.com\\n8https://cedille.ai\\n9https://discord.gg/zBGx3azzUn\\n6\\n[6]\\nAntoine Simoulin and Benoit Crabb√©. ‚ÄúUn mod-\\n√®le Transformer G√©n√©ratif Pr√©-entrain√© pour le _\\nfran√ßais‚Äù. In: Traitement Automatique des Langues\\nNaturelles. ATALA. 2021, pp. 245‚Äì254.\\n[7]\\nJulien Launay et al. ‚ÄúPAGnol: An Extra-Large\\nFrench Generative Model‚Äù. In: arXiv preprint\\narXiv:2110.08554 (2021).\\n[8]\\nGuillaume Wenzek et al. ‚ÄúCcnet: Extracting high\\nquality monolingual datasets from web crawl data‚Äù.\\nIn: arXiv preprint arXiv:1911.00359 (2019).\\n[9]\\nEmily M Bender et al. ‚ÄúOn the Dangers of Stochas-\\ntic Parrots: Can Language Models Be Too Big?‚Äù\\nIn: Proceedings of the 2021 ACM Conference on\\nFairness, Accountability, and Transparency. 2021,\\npp. 610‚Äì623.\\n[10]\\nIsaac Caswell et al. ‚ÄúQuality at a glance: An au-\\ndit of web-crawled multilingual datasets‚Äù. In: arXiv\\npreprint arXiv:2103.12028 (2021).\\n[11]\\nSamuel Gehman et al. ‚ÄúRealToxicityPrompts: Evalu-\\nating neural toxic degeneration in language models‚Äù.\\nIn: arXiv preprint arXiv:2009.11462 (2020).\\n[12]\\nJohannes Welbl et al. ‚ÄúChallenges in detox-\\nifying language models‚Äù. In: arXiv preprint\\narXiv:2109.07445 (2021).\\n[13]\\nSumanth Dathathri et al. ‚ÄúPlug and play language\\nmodels: A simple approach to controlled text gener-\\nation‚Äù. In: arXiv preprint arXiv:1912.02164 (2019).\\n[14]\\nBrian Lester, Rami Al-Rfou, and Noah Constant.\\n‚ÄúThe power of scale for parameter-efÔ¨Åcient prompt\\ntuning‚Äù. In: arXiv preprint arXiv:2104.08691\\n(2021).\\n[15]\\nNitish Shirish Keskar et al. ‚ÄúCtrl: A conditional\\ntransformer language model for controllable gener-\\nation‚Äù. In: arXiv preprint arXiv:1909.05858 (2019).\\n[16]\\nBen Wang and Aran Komatsuzaki. GPT-J-6B: A 6\\nBillion Parameter Autoregressive Language Model.\\nhttps : / / github . com / kingoflolz / mesh -\\ntransformer-jax. May 2021.\\n[17]\\nJianlin Su et al. ‚ÄúRoformer: Enhanced transformer\\nwith rotary position embedding‚Äù. In: arXiv preprint\\narXiv:2104.09864 (2021).\\n[18]\\nLinting Xue et al. ‚ÄúmT5: A massively multilin-\\ngual pre-trained text-to-text transformer‚Äù. In: arXiv\\npreprint arXiv:2010.11934 (2020).\\n[19]\\nLaura Hanu and Unitary team. Detoxify. https:\\n//github.com/unitaryai/detoxify. 2020.\\n[20]\\nHang Le et al. ‚ÄúFlaubert: Unsupervised language\\nmodel pre-training for french‚Äù. In: arXiv preprint\\narXiv:1912.05372 (2019).\\n[21]\\nRobyn Speer. ftfy. Zenodo. Version 5.5. 2019. DOI:\\n10.5281/zenodo.2591652. URL: https://doi.\\norg/10.5281/zenodo.2591652.\\n[22]\\nBen Wang. Mesh-Transformer-JAX: Model-Parallel\\nImplementation of Transformer Language Model\\nwith JAX. https://github.com/kingoflolz/\\nmesh-transformer-jax. May 2021.\\n[23]\\nLeo Gao et al. A framework for few-shot language\\nmodel evaluation. Version v0.0.1. Sept. 2021. DOI:\\n10.5281/zenodo.5371628. URL: https://doi.\\norg/10.5281/zenodo.5371628.\\n[24]\\nLeo Gao. On the Sizes of OpenAI API Models.\\nhttps://blog.eleuther.ai/gpt3- model-\\nsizes/. May 2021.\\n[25]\\nStephen Merity et al. ‚ÄúPointer sentinel mixture mod-\\nels‚Äù. In: arXiv preprint arXiv:1609.07843 (2016).\\n[26]\\nPerplexity of Ô¨Åxed-length models. https : / /\\nhuggingface . co / docs / transformers /\\nperplexity. Accessed: 2022-02-04.\\n[27]\\nMoussa Kamal Eddine, Antoine J-P Tixier, and\\nMichalis Vazirgiannis. ‚ÄúBARThez: a skilled pre-\\ntrained french sequence-to-sequence model‚Äù. In:\\narXiv preprint arXiv:2010.12321 (2020).\\n[28]\\nShashi Narayan, Shay B Cohen, and Mirella La-\\npata. ‚ÄúDon‚Äôt give me the details, just the sum-\\nmary! topic-aware convolutional neural networks\\nfor extreme summarization‚Äù. In: arXiv preprint\\narXiv:1808.08745 (2018).\\n[29]\\nChin-Yew Lin. ‚ÄúRouge: A package for automatic\\nevaluation of summaries‚Äù. In: Text summarization\\nbranches out. 2004, pp. 74‚Äì81.\\n[30]\\nMartin d‚ÄôHoffschmidt et al. ‚ÄúFQuAD: French\\nquestion answering dataset‚Äù. In: arXiv preprint\\narXiv:2002.06071 (2020).\\n[31]\\nPranav Rajpurkar et al. ‚ÄúSQuAD: 100,000+ ques-\\ntions for machine comprehension of text‚Äù. In: arXiv\\npreprint arXiv:1606.05250 (2016).\\n[32]\\nLouis Martin et al. ‚ÄúCamemBERT: a tasty\\nfrench\\nlanguage\\nmodel‚Äù.\\nIn:\\narXiv\\npreprint\\narXiv:1911.03894 (2019).\\n[33]\\nOndÀárej Bojar et al. ‚ÄúFindings of the 2014 workshop\\non statistical machine translation‚Äù. In: Proceedings\\nof the ninth workshop on statistical machine trans-\\nlation. 2014, pp. 12‚Äì58.\\n[34]\\nKishore Papineni et al. ‚ÄúBleu: a method for auto-\\nmatic evaluation of machine translation‚Äù. In: Pro-\\nceedings of the 40th annual meeting of the Associa-\\ntion for Computational Linguistics. 2002, pp. 311‚Äì\\n318.\\n[35]\\nMatt Post. ‚ÄúA Call for Clarity in Reporting BLEU\\nScores‚Äù. In: Proceedings of the Third Conference\\non Machine Translation: Research Papers. Belgium,\\nBrussels: Association for Computational Linguis-\\ntics, Oct. 2018, pp. 186‚Äì191. URL: https://www.\\naclweb.org/anthology/W18-6319.\\n[36]\\nXiaodong Liu et al. ‚ÄúVery deep transformers for\\nneural machine translation‚Äù. In: arXiv preprint\\narXiv:2008.07772 (2020).\\n[37]\\nKatherine Lee et al. ‚ÄúDeduplicating training data\\nmakes language models better‚Äù. In: arXiv preprint\\narXiv:2107.06499 (2021).\\n[38]\\nLong Ouyang et al. Training language models to\\nfollow instructions with human feedback. https://\\nopenai.com/blog/instruction-following/.\\nJan. 2022.\\n7\\nSUPPLEMENTARY MATERIAL\\n1\\nExperiments training from scratch\\nGiven the amount of compute and data available, training from scratch rather than Ô¨Ånetuning was considered. We\\nexperimented training Cedille from scratch using both the GPT-2 tokenizer (Cedille-fs-GPT2, vocab size 50,400) and\\nthe GPT-fr tokenizer (Cedille-fs-GPTfr, vocab size 50.000) for 60k steps using a peak learning rate of 1.2e-4 end\\nlearning rate 1.2e-5, and 7281 warm-up steps. These two variants are therefore only trained on one third of the data\\ncompared to the released Cedille model (150k steps). In order to have a fair comparison we show the result of Cedille\\nafter the same amount of steps (Cedille-60k). All models were trained on the same Ô¨Åltered mC4 dataset, as described in\\nthis work.\\nAs shown in Table S1, Cedille-60k outperforms the from-scratch variants on the WikiText-fr benchmark. However,\\ndue to compute limitations we did not run the variants for longer than 60k steps and it is possible that we could‚Äôve\\nreached similar performance after 150k steps. Furthermore, both variants perform similarly, even though they are using\\na different tokenizer. Due to the variants performing very similarly, we conclude that even though a dedicated French\\ntokenizer is a lot more efÔ¨Åcient at encoding French text compared to the GPT-2 tokenizer, its beneÔ¨Åt with regard to\\nend-task performance was minimal in our experiments.\\nModel\\nPPL (byte)\\nPPL (token)\\nGPT-J\\n1.746\\n5.797\\nCedille-60k\\n1.673\\n4.112\\nCedille-fs-GPT2\\n1.794\\n4.972\\nCedille-fs-GPTfr\\n1.775\\n6.856\\nTable S1: Byte-level and token-level perplexities for the WikiText-fr benchmark. Cedille-60k is the Cedille model at checkpoint 60k\\n(out of 150k), Cedille-fs-GPT2 and Cedille-fs-GPTfr are models trained for 60k steps on the same dataset, but with random weight\\ninitialization.\\n8'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the language model for script generation\n",
    "print(\"ü§ñ Initializing local language model...\")\n",
    "\n",
    "try:\n",
    "    # Load LLM using configuration\n",
    "    llm = initialize_llm(\n",
    "        model_source=config.get(\"model_source\", \"local\"),\n",
    "        secrets=secrets\n",
    "    )\n",
    "    print(\"‚úÖ Language model loaded successfully!\")\n",
    "    print(f\"üìä Context window: {get_context_window(llm)} tokens\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading language model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc84e63-bc1d-4a4f-8eea-a315b9ce4100",
   "metadata": {},
   "source": [
    "### üß± Step 2: Processing and Embedding Generation\n",
    "In this step, we transform the raw text extracted from the papers into structured embeddings that can be stored and retrieved efficiently in the RAG pipeline.\n",
    "\n",
    "The flow includes three main stages:\n",
    "\n",
    "1. **üìÑ Create Document Objects**\n",
    "The full text of each paper is wrapped into Document objects ‚Äî a standard structure used by LangChain to manage and manipulate textual data.\n",
    "\n",
    "2. **‚úÇÔ∏è Split Text into Chunks**\n",
    "Using LangChain's RecursiveCharacterTextSplitter, the documents are segmented into smaller blocks (chunks) based on character limits. This makes the downstream embedding and retrieval process more effective.\n",
    "\n",
    "The chunk_size parameter defines the maximum length of each chunk.\n",
    "\n",
    "3. **üìä Generate Embeddings**\n",
    "Each text chunk is converted into a vector representation (embedding) using HuggingFaceEmbeddings. These embeddings are later used to populate the vector store and serve as the foundation for similarity-based retrieval in the generation step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "064759c4-6e03-4653-8dd1-6dd845aa1ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creates a list of Document objects from the scientific articles in the `papers` variable.\n",
    "# Each `Document` is created with the article content and a metadata dictionary containing the title.\n",
    "documents = [Document(page_content=paper['text'], metadata={\"title\": paper['title']}) for paper in papers]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1200, chunk_overlap=400)\n",
    "splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25966f82-3b88-4067-86a8-9ebe143b535b",
   "metadata": {},
   "source": [
    "### üß© Step 3: Vector Data Storage and Retrieval\n",
    "This step handles the storage of embeddings into a vector database and configures a retriever to enable similarity-based search ‚Äî a key component in the RAG pipeline.\n",
    "\n",
    "üß† Store Embeddings with Chroma\n",
    "The segmented text chunks, previously converted into embeddings, are stored in a local vector store using ChromaDB. This enables efficient access to semantically similar information later on.\n",
    "\n",
    "üîé Configure the Retriever\n",
    "After storing the embeddings, a retriever is set up to perform similarity search queries. This retriever is responsible for:\n",
    "\n",
    "- Receiving a user query or prompt\n",
    "\n",
    "- Searching through the stored embeddings\n",
    "\n",
    "- Returning the most relevant chunks based on vector similarity\n",
    "\n",
    "> üì¶ This mechanism allows the generation model to work with only the most relevant information, improving accuracy and reducing hallucinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff1486a1-1c3a-4c93-b6e3-6a7685ad0f13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:24:39,986 | INFO | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "#Our vector database\n",
    "vectordb = Chroma.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40d5dc9e-0632-4f61-bc9b-43bbb144a09e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e8faf-43be-44f5-bd21-94be9efb799c",
   "metadata": {},
   "source": [
    "## üß† Chapter 2: Building a Prompt Flow for Generating Scientific Presentation Scripts\n",
    "In this chapter, we build a prompt flow to generate a complete scientific presentation script using LLMs. Each section of the script (e.g., title, introduction, methodology) is created individually through dedicated prompt templates.\n",
    "\n",
    "The process is composed of four main steps:\n",
    "\n",
    "1. ‚úÖ **Login via Galileo**\n",
    "Authenticate to enable logging of prompt quality and results for later evaluation.\n",
    "\n",
    "2. üß† **Model Selection**\n",
    "Choose the best-suited LLM for the generation task, depending on performance or local availability.\n",
    "\n",
    "3. üîç **Analysis with ScientificPaperAnalyzer**\n",
    "Using the component ScientificPaperAnalyzer, a custom LangChain chain is built to analyze the scientific paper and generate context-aware responses.\n",
    "\n",
    "4. üßæ **Script Generation with Logging**\n",
    "The ScriptGenerator orchestrates the prompt flow, allowing users to generate each section of the presentation interactively, while logging all interactions to Galileo for tracking and evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b928d0d-7e83-4f5d-b1d5-9792f28fd76a",
   "metadata": {},
   "source": [
    "#### ‚öôÔ∏è Step 4: Config Enviroment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b13463-62ba-4cb5-9ff5-89bf8253cca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã You have logged into üî≠ Galileo (https://console.hp.galileocloud.io/) as nickyjhames@hp.com.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Config(console_url=HttpUrl('https://console.hp.galileocloud.io/'), username=None, password=None, api_key=SecretStr('**********'), token=SecretStr('**********'), current_user='nickyjhames@hp.com', current_project_id=None, current_project_name=None, current_run_id=None, current_run_name=None, current_run_url=None, current_run_task_type=None, current_template_id=None, current_template_name=None, current_template_version_id=None, current_template_version=None, current_template=None, current_dataset_id=None, current_job_id=None, current_prompt_optimization_job_id=None, api_url=HttpUrl('https://api.hp.galileocloud.io/'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration for the script generation project\n",
    "PROJECT_NAME = 'Academic Script Generator'\n",
    "print(f\"‚úÖ Project configured: {PROJECT_NAME}\")\n",
    "print(\"üöÄ Ready for script generation pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc352519-9241-4b14-a9a6-53747473f038",
   "metadata": {},
   "source": [
    "## Local Environment Setup\n",
    "\n",
    "This section configures the local environment for script generation. The following steps will:\n",
    "\n",
    "1. ‚úÖ **Initialize Local Configuration**\n",
    "2. ‚úÖ **Set Up Script Generator**\n",
    "3. ‚úÖ **Configure Content Generation Parameters**\n",
    "\n",
    "The ScriptGenerator orchestrates the prompt flow, allowing users to generate each section of the presentation interactively, with all processing done locally using the configured LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca598c3-80c5-4940-895a-f296765ef75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.46 s, sys: 38.1 s, total: 44.6 s\n",
      "Wall time: 16min 53s\n"
     ]
    }
   ],
   "source": [
    "# Configure environment for local development\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up working directory and logging\n",
    "WORK_DIR = os.getcwd()\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(f\"‚úÖ Working directory: {WORK_DIR}\")\n",
    "print(f\"‚úÖ Session timestamp: {TIMESTAMP}\")\n",
    "print(\"üîß Environment ready for script generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67775ce6-cb3c-4959-8051-5f2f19da7e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:41:38,658 | INFO | Building the LangChain chain...\n",
      "2025-07-01 19:41:38,660 | INFO | Analyzing prompt: 'What are the main findings of the paper?'\n",
      "2025-07-01 19:41:38,802 | INFO | Retrieved 4 documents for query: 'What are the main findings of the paper?'\n",
      "2025-07-01 19:41:38,803 | INFO | Formatted 4 documents into context.\n",
      "2025-07-01 19:41:38,804 | INFO | Context preview: OHCHR. [perma.cc/Y6MK-SZZ4]\n",
      "Vallee, H. Q. la, & Duarte, N. (2019). Algorithmic Systems in Education: Incorporating Equity and Fairness When \n",
      "Using Student Data. Center for Democracy and Technology. [perma.cc/CC89-ZVNV]\n",
      "Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kai...\n",
      "2025-07-01 19:41:41,717 | INFO | Raw model output: I'm happy to help you analyze the paper. However, I don't see a specific paper in the provided text. The text appears to be a collection of citations and references from various scientific papers.\n",
      "\n",
      "Could you please provide me with the actual paper or the title and authors of the paper you would like...\n",
      "2025-07-01 19:41:41 - INFO - I'm happy to help you analyze the paper. However, I don't see a specific paper in the provided text. The text appears to be a collection of citations and references from various scientific papers.\n",
      "\n",
      "Could you please provide me with the actual paper or the title and authors of the paper you would like me to analyze?\n"
     ]
    }
   ],
   "source": [
    "# Initialize Script Generator without Galileo\n",
    "from core.generator.script_generator import ScriptGenerator\n",
    "\n",
    "# Instantiate generator\n",
    "generator = ScriptGenerator()\n",
    "\n",
    "# Initialize without Galileo\n",
    "print(\"‚úÖ Script generator initialized successfully\")\n",
    "print(\"üöÄ Ready to generate academic scripts with LLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cc0349-e689-4497-a02d-98d50e97483c",
   "metadata": {},
   "source": [
    "### ‚úÖ Step 6: Run and Approve\n",
    "The ScriptGenerator component is responsible for generating each section of the scientific presentation script in an interactive and human-in-the-loop fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced59fe-c099-49e5-a4b8-20867ad1bf16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:41:41,728 | INFO | Section 'title' added.\n",
      "2025-07-01 19:41:41,731 | INFO | Section 'introduction' added.\n",
      "2025-07-01 19:41:41,732 | INFO | Section 'methodology' added.\n",
      "2025-07-01 19:41:41,733 | INFO | Section 'results' added.\n",
      "2025-07-01 19:41:41,734 | INFO | Section 'conclusion' added.\n",
      "2025-07-01 19:41:41,735 | INFO | Section 'references' added.\n",
      "2025-07-01 19:41:41,736 | INFO | Running section 'title'.\n",
      "2025-07-01 19:41:42,225 | INFO | Generating section 'title'‚Ä¶\n",
      "2025-07-01 19:41:42,276 | INFO | Retrieved 4 documents for query: 'Generate a clear and concise title for the presentation that reflects the content. Add a subtitle if needed. Respond using natural language only.'\n",
      "2025-07-01 19:41:42,277 | INFO | Formatted 4 documents into context.\n",
      "2025-07-01 19:41:42,278 | INFO | Context preview: The models were evaluated using the SQuAD v2 met-\n",
      "ric [31], which also takes into consideration ‚Äúno answer‚Äù\n",
      "probabilities, i.e. cases when no answer to a particular\n",
      "question is possible given the context. The models were\n",
      "tasked to generate 100 tokens and at most 1 sentence using\n",
      "greedy sampling and ...\n",
      "2025-07-01 19:41:43,948 | INFO | Model output (title): Here is a potential title and subtitle for the presentation:  **Title:** \"Evaluating Large Language Models in Non-English Content Analysis\" **Subtitle:** \"A Study on the Performance of GPT-3 Models in French Question Answering\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [title] Result:\n",
      "Here is a potential title and subtitle for the presentation:\n",
      "\n",
      "**Title:** \"Evaluating Large Language Models in Non-English Content Analysis\"\n",
      "**Subtitle:** \"A Study on the Performance of GPT-3 Models in French Question Answering\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approve the result? (y/n):  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b851ee8b2c4281a4d2655978918367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chain run...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial job complete, executing scorers asynchronously. Current status:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:42:17,248 | INFO | Running section 'introduction'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: Done ‚úÖ\n",
      "toxicity: Done ‚úÖ\n",
      "pii: Done ‚úÖ\n",
      "protect_status: Done ‚úÖ\n",
      "prompt_perplexity: Computing üöß\n",
      "latency: Done ‚úÖ\n",
      "groundedness: Computing üöß\n",
      "factuality: Computing üöß\n",
      "üî≠ View your prompt run on the Galileo console at: https://console.hp.galileocloud.io/prompt/chains/83f342f5-5d89-4a07-8793-17c3e4c571c9/b80d60d7-6939-410b-a190-103b26931e47?taskType=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:42:17,686 | INFO | Generating section 'introduction'‚Ä¶\n",
      "2025-07-01 19:42:17,779 | INFO | Retrieved 4 documents for query: 'Write the introduction of the presentation including:\n",
      "- Contextualization of the general theme.\n",
      "- Relevance of the topic, both academically and practically.\n",
      "- A brief literature review.\n",
      "- A clear definition of the research problem.\n",
      "- The specific objectives of the research.\n",
      "- Hypotheses (if applicable).\n",
      "Respond using only natural language, no structured format or dictionaries.'\n",
      "2025-07-01 19:42:17,780 | INFO | Formatted 4 documents into context.\n",
      "2025-07-01 19:42:17,782 | INFO | Context preview: Lost in Translation\n",
      "May 2023\n",
      "A report from\n",
      "Gabriel Nicholas\n",
      "Aliya Bhatia\n",
      "Large Language Models in \n",
      "Non-English Content Analysis\n",
      "GABRIEL NICHOLAS\n",
      "Research Fellow at the Center for Democracy & Technology.\n",
      "ALIYA BHATIA\n",
      "Policy Analyst, Free Expression Project at the Center for \n",
      "Democracy & Technology.\n",
      "T...\n",
      "2025-07-01 19:42:22,524 | INFO | Model output (introduction): Here is a possible introduction for the presentation:  Large language models have revolutionized the field of natural language processing, enabling applications such as language translation, text summarization, and content analysis.  However, the increasing use of large language models in non-Englis‚Ä¶\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [introduction] Result:\n",
      "Here is a possible introduction for the presentation:\n",
      "\n",
      "Large language models have revolutionized the field of natural language processing, enabling applications such as language translation, text summarization, and content analysis.\n",
      "\n",
      "However, the increasing use of large language models in non-English content analysis has raised concerns about their reliability, transparency, and accountability. The lack of understanding about how these models work, particularly when they are applied to languages other than English, creates significant challenges for users who rely on them to access information, express themselves, or exercise their rights.\n",
      "\n",
      "This presentation will explore the complex issues surrounding the use of large language models in non-English content analysis, with a focus on the need for greater transparency, accountability, and human rights impact assessments.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approve the result? (y/n):  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c4f870624a434da412d256fccf1ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chain run...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial job complete, executing scorers asynchronously. Current status:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:42:35,890 | INFO | Running section 'methodology'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: Done ‚úÖ\n",
      "toxicity: Done ‚úÖ\n",
      "pii: Done ‚úÖ\n",
      "protect_status: Done ‚úÖ\n",
      "prompt_perplexity: Computing üöß\n",
      "latency: Done ‚úÖ\n",
      "groundedness: Computing üöß\n",
      "factuality: Computing üöß\n",
      "üî≠ View your prompt run on the Galileo console at: https://console.hp.galileocloud.io/prompt/chains/786d94a3-92df-471f-9f13-eb70a23671f8/254b6b41-6365-4591-9c73-11b0e9a28af5?taskType=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:42:36,327 | INFO | Generating section 'methodology'‚Ä¶\n",
      "2025-07-01 19:42:36,459 | INFO | Retrieved 4 documents for query: 'Write the methodology section including:\n",
      "- Research Design (e.g., experimental, descriptive, exploratory).\n",
      "- Sample and Population details.\n",
      "- Data Collection methods.\n",
      "- Instruments used.\n",
      "- Data Analysis techniques.\n",
      "Answer clearly in plain text using natural language only.'\n",
      "2025-07-01 19:42:36,461 | INFO | Formatted 4 documents into context.\n",
      "2025-07-01 19:42:36,462 | INFO | Context preview: high-quality data resources exist. Though it has the most data available of any language \n",
      "(English could be called an ‚Äúextremely‚Äù high resource language), there are six other \n",
      "languages that could be considered high resource ‚Äî the official UN languages list, \n",
      "minus Russian, plus Japanese (see Table ...\n",
      "2025-07-01 19:42:44,821 | INFO | Model output (methodology): Methodology  This study employed a mixed-methods design, combining both quantitative and qualitative data collection and analysis techniques.  Research Design:  The research design was exploratory, aiming to identify the challenges of using large language models in non-English content analysis.  Sam‚Ä¶\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [methodology] Result:\n",
      "Methodology\n",
      "\n",
      "This study employed a mixed-methods design, combining both quantitative and qualitative data collection and analysis techniques.\n",
      "\n",
      "Research Design:\n",
      "\n",
      "The research design was exploratory, aiming to identify the challenges of using large language models in non-English content analysis.\n",
      "\n",
      "Sample and Population:\n",
      "\n",
      "The population consisted of researchers, developers, and policymakers working with or on behalf of multilingual communities. The sample included 20 participants from various countries, selected through purposive sampling.\n",
      "\n",
      "Data Collection Methods:\n",
      "\n",
      "The data were collected through a combination of methods:\n",
      "\n",
      "1. Interviews: Semi-structured interviews were conducted with the sample participants to gather in-depth information about their experiences and challenges related to using large language models in non-English content analysis.\n",
      "2. Questionnaires: A survey questionnaire was administered to the sample participants to gather quantitative data on their opinions, attitudes, and experiences related to using large language models in non-English content analysis.\n",
      "\n",
      "Instruments Used:\n",
      "\n",
      "The instruments used for data collection were a semi-structured interview guide and a survey questionnaire.\n",
      "\n",
      "Data Analysis Techniques:\n",
      "\n",
      "The collected data were analyzed using thematic analysis and descriptive statistics. Thematic analysis was employed to identify patterns, themes, and sub-themes from the qualitative data collected through interviews. Descriptive statistics were used to summarize the quantitative data collected through the survey questionnaire.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approve the result? (y/n):  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e9e50e628d4aa4b0057a5740945558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chain run...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial job complete, executing scorers asynchronously. Current status:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:45:31,159 | INFO | Running section 'results'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: Done ‚úÖ\n",
      "toxicity: Done ‚úÖ\n",
      "pii: Done ‚úÖ\n",
      "protect_status: Done ‚úÖ\n",
      "prompt_perplexity: Done ‚úÖ\n",
      "latency: Done ‚úÖ\n",
      "groundedness: Computing üöß\n",
      "factuality: Computing üöß\n",
      "üî≠ View your prompt run on the Galileo console at: https://console.hp.galileocloud.io/prompt/chains/36363e5f-9447-449b-a7fd-cff0cfa4940d/f66bcf38-4f82-4e16-8b87-79ac2fd91f2b?taskType=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:45:31,606 | INFO | Generating section 'results'‚Ä¶\n",
      "2025-07-01 19:45:31,710 | INFO | Retrieved 4 documents for query: 'Write the results section including:\n",
      "- Presentation of data (feel free to mention tables or graphs).\n",
      "- Initial interpretation of the data.\n",
      "- Comparison with hypotheses (if applicable).\n",
      "Answer using natural language only. Avoid structured outputs.'\n",
      "2025-07-01 19:45:31,711 | INFO | Formatted 4 documents into context.\n",
      "2025-07-01 19:45:31,712 | INFO | Context preview: The models were tasked to generate 100 tokens using top-k\n",
      "of 2 and a temperature of 1, following the methodology\n",
      "in [1]. We used greedy decoding (top-k = 1) for GPT-3,\n",
      "since at the time of this work being conducted, the API\n",
      "didn‚Äôt allow for other top-k values. When the prompt ex-\n",
      "ceeded the context ...\n",
      "2025-07-01 19:45:40,089 | INFO | Model output (results): The results section of this paper presents the performance of various language models on summarization and question-answering tasks in French.  Table 3 shows the ROUGE scores on the OrangeSum dataset, which evaluate the performance of the models on summarization. The results indicate that the larger‚Ä¶\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [results] Result:\n",
      "The results section of this paper presents the performance of various language models on summarization and question-answering tasks in French.\n",
      "\n",
      "Table 3 shows the ROUGE scores on the OrangeSum dataset, which evaluate the performance of the models on summarization. The results indicate that the larger GPT-3 models perform better than the smaller ones, but still have varying degrees of success.\n",
      "\n",
      "On the other hand, Table 4 presents the F1 and exact match scores on the FQuAD benchmark for question-answering tasks in French. Again, the results show that the larger GPT-3 models perform better than the smaller ones, with some variations in performance across different models.\n",
      "\n",
      "Initial interpretation of these data suggests that while there are some differences in performance between various language models, the overall trend is one of increasing performance with larger model sizes. However, it's worth noting that these results may be influenced by factors such as the specific implementation details and hyperparameters used for each model, as well as any potential biases or artifacts present in the training data.\n",
      "\n",
      "Comparison to hypotheses (if applicable) suggests that while some models perform better than expected based on their size and architecture, others do not meet expectations. However, without a clear set of hypotheses or prior performance metrics against which to compare these results, it's difficult to draw more definitive conclusions about the relative strengths and weaknesses of each model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approve the result? (y/n):  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be33472fa0c94253a0ad9104418ff0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chain run...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial job complete, executing scorers asynchronously. Current status:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:46:07,778 | INFO | Running section 'conclusion'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: Done ‚úÖ\n",
      "toxicity: Done ‚úÖ\n",
      "pii: Done ‚úÖ\n",
      "protect_status: Done ‚úÖ\n",
      "prompt_perplexity: Done ‚úÖ\n",
      "latency: Done ‚úÖ\n",
      "groundedness: Computing üöß\n",
      "factuality: Computing üöß\n",
      "üî≠ View your prompt run on the Galileo console at: https://console.hp.galileocloud.io/prompt/chains/7c730cdb-424d-4b98-90f6-2934a9e9518f/1eccbe66-2470-434a-bf7d-ec97ebcf44b6?taskType=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:46:08,220 | INFO | Generating section 'conclusion'‚Ä¶\n",
      "2025-07-01 19:46:08,324 | INFO | Retrieved 4 documents for query: 'Write the conclusion of the study including:\n",
      "- A synthesis of the main results.\n",
      "- Response to the research problem.\n",
      "- The study's academic or practical contributions.\n",
      "- Final reflections or recommendations.\n",
      "Respond in full natural text without any structured formatting.'\n",
      "2025-07-01 19:46:08,326 | INFO | Formatted 4 documents into context.\n",
      "2025-07-01 19:46:08,327 | INFO | Context preview: A report from\n",
      "Gabriel Nicholas and Aliya Bhatia\n",
      "WITH CONTRIBUTIONS BY\n",
      "Samir Jain, Mallory Knodel, Emma Llans√≥, Michal Luria, Nathalie Mar√©chal, Dhanaraj Thakur, and \n",
      "Caitlin Vogus.\n",
      "ACKNOWLEDGMENTS \n",
      "We thank Pratik Joshi, Sebastin Santy, and Aniket Kesari for their invaluable feedback on the technica...\n",
      "2025-07-01 19:46:17,523 | INFO | Model output (conclusion): In conclusion, this study has shed light on the limitations of large language models in non-English content analysis. Through our evaluation of summarization and question answering tasks on French data, we found that while these models can generate impressive results in certain contexts, they often ‚Ä¶\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [conclusion] Result:\n",
      "In conclusion, this study has shed light on the limitations of large language models in non-English content analysis. Through our evaluation of summarization and question answering tasks on French data, we found that while these models can generate impressive results in certain contexts, they often struggle with nuances of human language, such as idioms, colloquialisms, and cultural references.\n",
      "\n",
      "Our study also highlights the importance of considering the complexities of machine-translated text, which can contain errors or terms native language speakers don‚Äôt actually use. Furthermore, we found that when multilingual language models fail, their problems are hard to identify, diagnose, and fix.\n",
      "\n",
      "In light of these findings, our study offers several recommendations for companies, researchers, and policymakers to consider when developing and deploying large and multilingual language models to do content analysis:\n",
      "\n",
      "*   Large language models should be accompanied by adequate remedial channels and mechanisms that ensure individuals can appeal outcomes and decisions made by these systems.\n",
      "*   Companies and researchers should prioritize transparency in the development and deployment of large and multilingual language models, including providing documentation about their training data, model architecture, and testing procedures.\n",
      "*   Policymakers should establish regulatory frameworks that ensure the responsible development and deployment of large and multilingual language models, particularly with respect to issues related to bias, fairness, and accountability.\n",
      "\n",
      "By following these recommendations, we can work towards building more responsible and transparent artificial intelligence systems that promote greater understanding, equity, and justice in the digital age.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approve the result? (y/n):  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bd3f5077c849659dddedf00e56f50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chain run...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial job complete, executing scorers asynchronously. Current status:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:46:29,309 | INFO | Running section 'references'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: Done ‚úÖ\n",
      "toxicity: Done ‚úÖ\n",
      "pii: Done ‚úÖ\n",
      "protect_status: Done ‚úÖ\n",
      "prompt_perplexity: Computing üöß\n",
      "latency: Done ‚úÖ\n",
      "groundedness: Computing üöß\n",
      "factuality: Computing üöß\n",
      "üî≠ View your prompt run on the Galileo console at: https://console.hp.galileocloud.io/prompt/chains/61c5e62d-e22c-4b4c-8d1e-772740bc49f1/07a3a490-8325-4f61-9ae5-e47787d9be7c?taskType=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:46:29,745 | INFO | Generating section 'references'‚Ä¶\n",
      "2025-07-01 19:46:29,841 | INFO | Retrieved 4 documents for query: 'List the references for the study:\n",
      "- Include all sources cited in the presentation.\n",
      "- Format them according to a recognized citation style (APA, MLA, Chicago, etc.).\n",
      "Answer in natural language with correct formatting.'\n",
      "2025-07-01 19:46:29,842 | INFO | Formatted 4 documents into context.\n",
      "2025-07-01 19:46:29,843 | INFO | Context preview: CommonCrawl, and¬†Wikipedia and BooksCorpus, respectively. However, the models \n",
      "that Google, Meta, OpenAI, and other large companies use in their products train on \n",
      "other, proprietary, language data. Companies should share more of their training data, \n",
      "both for public accountability and to bolster re...\n",
      "2025-07-01 19:46:47,492 | INFO | Model output (references): Here are the references for the study, formatted according to APA style:  Alyafeai, A., & Al-Shaibani, K. (2020). Multilingual Language Models: Efforts to Bridge the Resourcedness Gap. Journal of Machine Learning Research, 21(1), 1-16.  CommonCrawl. n.d. Retrieved from <https://commoncrawl.org/>  Go‚Ä¶\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [references] Result:\n",
      "Here are the references for the study, formatted according to APA style:\n",
      "\n",
      "Alyafeai, A., & Al-Shaibani, K. (2020). Multilingual Language Models: Efforts to Bridge the Resourcedness Gap. Journal of Machine Learning Research, 21(1), 1-16.\n",
      "\n",
      "CommonCrawl. n.d. Retrieved from <https://commoncrawl.org/>\n",
      "\n",
      "Google. n.d. Retrieved from <https://www.google.com>\n",
      "\n",
      "Lokhov, I. (2021, January 28). Why are there so many Wikipedia articles in Swedish and Cebuano? Datawrapper Blog. https://perma.cc/WDL2-TF53\n",
      "\n",
      "Luccioni, A., & Viviano, J. (2021). What‚Äôs in the Box? An Analysis of Undesirable Content in the Common Crawl Corpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pp. 182-189.\n",
      "\n",
      "Lunden, I. (2023, March 14). Nabla, a digital health startup, launches Copilot, using GPT-3 to turn patient conversations into action. TechCrunch. https://perma.cc/MK55-SV54\n",
      "\n",
      "Martin, G., Mswahili, M. E., Jeong, Y.-S., & Woo, J. (2022). SwahBERT: Language Model of Swahili. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 303-313.\n",
      "\n",
      "Martin, L., Muller, B., Su√°rez, P. J. O., Dupont, Y., Romary, L., de la Clergerie, √â. V., Seddah, D., & Sagot, B. (2020). CamemBERT: A Tasty French Language Model. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 3046-3055.\n",
      "\n",
      "Masakhane. n.d. Retrieved from <https://masakhane.io/>\n",
      "\n",
      "Meta. n.d. Retrieved from <https://www.meta.com>\n",
      "\n",
      "Nicholas, G., & Bhatia, A. (2023). Lost in Translation: Large Language Models in Non-English Content Analysis. Center for Democracy & Technology.\n",
      "\n",
      "OpenAI. n.d. Retrieved from <https://openai.com>\n",
      "\n",
      "Perma.cc. n.d. Retrieved from <https://www.perma.cc/>\n",
      "\n",
      "Please note that the references are formatted according to APA style, with the inclusion of DOI numbers where available.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approve the result? (y/n):  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf048542a95d4a789f445a80b1b20a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chain run...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial job complete, executing scorers asynchronously. Current status:\n",
      "cost: Done ‚úÖ\n",
      "toxicity: Done ‚úÖ\n",
      "pii: Done ‚úÖ\n",
      "protect_status: Done ‚úÖ\n",
      "prompt_perplexity: Done ‚úÖ\n",
      "latency: Done ‚úÖ\n",
      "groundedness: Computing üöß\n",
      "factuality: Computing üöß\n",
      "üî≠ View your prompt run on the Galileo console at: https://console.hp.galileocloud.io/prompt/chains/1d8897c8-56c5-41ff-9970-d2174227bdbd/f7af848e-23da-4735-b354-04b8221f2c56?taskType=12\n",
      "Final Script:\n",
      " Here is a potential title and subtitle for the presentation:\n",
      "\n",
      "**Title:** \"Evaluating Large Language Models in Non-English Content Analysis\"\n",
      "**Subtitle:** \"A Study on the Performance of GPT-3 Models in French Question Answering\"\n",
      "\n",
      "Here is a possible introduction for the presentation:\n",
      "\n",
      "Large language models have revolutionized the field of natural language processing, enabling applications such as language translation, text summarization, and content analysis.\n",
      "\n",
      "However, the increasing use of large language models in non-English content analysis has raised concerns about their reliability, transparency, and accountability. The lack of understanding about how these models work, particularly when they are applied to languages other than English, creates significant challenges for users who rely on them to access information, express themselves, or exercise their rights.\n",
      "\n",
      "This presentation will explore the complex issues surrounding the use of large language models in non-English content analysis, with a focus on the need for greater transparency, accountability, and human rights impact assessments.\n",
      "\n",
      "Methodology\n",
      "\n",
      "This study employed a mixed-methods design, combining both quantitative and qualitative data collection and analysis techniques.\n",
      "\n",
      "Research Design:\n",
      "\n",
      "The research design was exploratory, aiming to identify the challenges of using large language models in non-English content analysis.\n",
      "\n",
      "Sample and Population:\n",
      "\n",
      "The population consisted of researchers, developers, and policymakers working with or on behalf of multilingual communities. The sample included 20 participants from various countries, selected through purposive sampling.\n",
      "\n",
      "Data Collection Methods:\n",
      "\n",
      "The data were collected through a combination of methods:\n",
      "\n",
      "1. Interviews: Semi-structured interviews were conducted with the sample participants to gather in-depth information about their experiences and challenges related to using large language models in non-English content analysis.\n",
      "2. Questionnaires: A survey questionnaire was administered to the sample participants to gather quantitative data on their opinions, attitudes, and experiences related to using large language models in non-English content analysis.\n",
      "\n",
      "Instruments Used:\n",
      "\n",
      "The instruments used for data collection were a semi-structured interview guide and a survey questionnaire.\n",
      "\n",
      "Data Analysis Techniques:\n",
      "\n",
      "The collected data were analyzed using thematic analysis and descriptive statistics. Thematic analysis was employed to identify patterns, themes, and sub-themes from the qualitative data collected through interviews. Descriptive statistics were used to summarize the quantitative data collected through the survey questionnaire.\n",
      "\n",
      "The results section of this paper presents the performance of various language models on summarization and question-answering tasks in French.\n",
      "\n",
      "Table 3 shows the ROUGE scores on the OrangeSum dataset, which evaluate the performance of the models on summarization. The results indicate that the larger GPT-3 models perform better than the smaller ones, but still have varying degrees of success.\n",
      "\n",
      "On the other hand, Table 4 presents the F1 and exact match scores on the FQuAD benchmark for question-answering tasks in French. Again, the results show that the larger GPT-3 models perform better than the smaller ones, with some variations in performance across different models.\n",
      "\n",
      "Initial interpretation of these data suggests that while there are some differences in performance between various language models, the overall trend is one of increasing performance with larger model sizes. However, it's worth noting that these results may be influenced by factors such as the specific implementation details and hyperparameters used for each model, as well as any potential biases or artifacts present in the training data.\n",
      "\n",
      "Comparison to hypotheses (if applicable) suggests that while some models perform better than expected based on their size and architecture, others do not meet expectations. However, without a clear set of hypotheses or prior performance metrics against which to compare these results, it's difficult to draw more definitive conclusions about the relative strengths and weaknesses of each model.\n",
      "\n",
      "In conclusion, this study has shed light on the limitations of large language models in non-English content analysis. Through our evaluation of summarization and question answering tasks on French data, we found that while these models can generate impressive results in certain contexts, they often struggle with nuances of human language, such as idioms, colloquialisms, and cultural references.\n",
      "\n",
      "Our study also highlights the importance of considering the complexities of machine-translated text, which can contain errors or terms native language speakers don‚Äôt actually use. Furthermore, we found that when multilingual language models fail, their problems are hard to identify, diagnose, and fix.\n",
      "\n",
      "In light of these findings, our study offers several recommendations for companies, researchers, and policymakers to consider when developing and deploying large and multilingual language models to do content analysis:\n",
      "\n",
      "*   Large language models should be accompanied by adequate remedial channels and mechanisms that ensure individuals can appeal outcomes and decisions made by these systems.\n",
      "*   Companies and researchers should prioritize transparency in the development and deployment of large and multilingual language models, including providing documentation about their training data, model architecture, and testing procedures.\n",
      "*   Policymakers should establish regulatory frameworks that ensure the responsible development and deployment of large and multilingual language models, particularly with respect to issues related to bias, fairness, and accountability.\n",
      "\n",
      "By following these recommendations, we can work towards building more responsible and transparent artificial intelligence systems that promote greater understanding, equity, and justice in the digital age.\n",
      "\n",
      "Here are the references for the study, formatted according to APA style:\n",
      "\n",
      "Alyafeai, A., & Al-Shaibani, K. (2020). Multilingual Language Models: Efforts to Bridge the Resourcedness Gap. Journal of Machine Learning Research, 21(1), 1-16.\n",
      "\n",
      "CommonCrawl. n.d. Retrieved from <https://commoncrawl.org/>\n",
      "\n",
      "Google. n.d. Retrieved from <https://www.google.com>\n",
      "\n",
      "Lokhov, I. (2021, January 28). Why are there so many Wikipedia articles in Swedish and Cebuano? Datawrapper Blog. https://perma.cc/WDL2-TF53\n",
      "\n",
      "Luccioni, A., & Viviano, J. (2021). What‚Äôs in the Box? An Analysis of Undesirable Content in the Common Crawl Corpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pp. 182-189.\n",
      "\n",
      "Lunden, I. (2023, March 14). Nabla, a digital health startup, launches Copilot, using GPT-3 to turn patient conversations into action. TechCrunch. https://perma.cc/MK55-SV54\n",
      "\n",
      "Martin, G., Mswahili, M. E., Jeong, Y.-S., & Woo, J. (2022). SwahBERT: Language Model of Swahili. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 303-313.\n",
      "\n",
      "Martin, L., Muller, B., Su√°rez, P. J. O., Dupont, Y., Romary, L., de la Clergerie, √â. V., Seddah, D., & Sagot, B. (2020). CamemBERT: A Tasty French Language Model. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 3046-3055.\n",
      "\n",
      "Masakhane. n.d. Retrieved from <https://masakhane.io/>\n",
      "\n",
      "Meta. n.d. Retrieved from <https://www.meta.com>\n",
      "\n",
      "Nicholas, G., & Bhatia, A. (2023). Lost in Translation: Large Language Models in Non-English Content Analysis. Center for Democracy & Technology.\n",
      "\n",
      "OpenAI. n.d. Retrieved from <https://openai.com>\n",
      "\n",
      "Perma.cc. n.d. Retrieved from <https://www.perma.cc/>\n",
      "\n",
      "Please note that the references are formatted according to APA style, with the inclusion of DOI numbers where available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: Done ‚úÖ\n",
      "toxicity: Done ‚úÖ\n",
      "pii: Done ‚úÖ\n",
      "protect_status: Done ‚úÖ\n",
      "prompt_perplexity: Done ‚úÖ\n",
      "latency: Done ‚úÖ\n",
      "groundedness: Computing üöß\n",
      "factuality: Computing üöß\n",
      "üî≠ View your prompt run on the Galileo console at: https://console.hp.galileocloud.io/prompt/chains/3666ae3e-a3d5-404c-ac3d-e326c52a3370/aebd7385-faf3-4100-a744-fffe0da09ea1?taskType=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 13:09:03,955 | INFO | Generating section 'references'‚Ä¶\n",
      "2025-06-26 13:09:04,089 | INFO | Retrieved 4 documents for query: 'List the references for the study:\n",
      "- Include all sources cited in the presentation.\n",
      "- Format them according to a recognized citation style (APA, MLA, Chicago, etc.).\n",
      "Answer in natural language with correct formatting.'\n",
      "2025-06-26 13:09:04,091 | INFO | Formatted 4 documents into context.\n",
      "2025-06-26 13:09:04,092 | INFO | Context preview: Lost in Translation\n",
      "CDT Research\n",
      "34\n",
      "benchmarks lead to more publications, conferences, and real-world use cases. And \n",
      "finally, increased demand for research and software in a language drives demand for \n",
      "more datasets. For low resource languages, however, the virtuous cycle is hard to \n",
      "kickstart. Wit...\n",
      "2025-06-26 13:09:38,217 | INFO | Model output (references): Answer: Here are the references for the study, formatted according to APA style:  Luccioni, A., & Viviano, F. (2021). What's in the Box? An Analysis of Undesirable Content in the Common Crawl Corpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th‚Ä¶\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [references] Result:\n",
      "Answer:\n",
      "Here are the references for the study, formatted according to APA style:\n",
      "\n",
      "Luccioni, A., & Viviano, F. (2021). What's in the Box? An Analysis of Undesirable Content in the Common Crawl Corpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), 182-189.\n",
      "\n",
      "Lunden, I. (2023, March 14). Nabla, a digital health startup, launches Copilot, using GPT-3 to turn patient conversations into action. TechCrunch.\n",
      "\n",
      "Lokhov, I. (2021, January 28). Why are there so many Wikipedia articles in Swedish and Cebuano? Datawrapper Blog.\n",
      "\n",
      "Martin, L., Muller, B., Su√°rez, P. J. O., Dupont, Y., Romary, L., de la Clergerie, √â. V., Seddah, D., & Sagot, B. (2020). CamemBERT: A Tasty French Language Model. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\n",
      "\n",
      "Martin, G., Mswahili, M. E., Jeong, Y.-S., & Woo, J. (2022). SwahBERT: Language Model of Swahili. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 303-313.\n",
      "\n",
      "Note that only sources cited in the presentation are included here. Let me know if you have any questions or need further clarification! \n",
      "\n",
      "cc/5QY9-97G5] \n",
      "References\n",
      "Lunden, I. (2023, March 14). Nabla, a digital health startup, launches Copilot, using GPT-3 to turn patient conversations into action. TechCrunch. [perma.cc/MK55-SV54]\n",
      "Martin, L., Muller, B., Su√°rez, P. J. O., Dupont, Y., Romary, L., de la Clergerie, √â. V., Seddah, D., & Sagot, B. (2020). CamemBERT: A Tasty French Language Model. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\n",
      "\n",
      "Martin, G., Mswahili, M. E., Jeong, Y.-S., & Woo, J. (2022). SwahBERT: Language Model of Swahili. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 303-313.\n",
      "\n",
      "Lokhov, I. (2021, January 28). Why are there so many Wikipedia articles in Swedish and Cebuano? Datawrapper Blog. [perma.cc/WDL2-TF53]\n",
      "\n",
      "Luccioni, A., & Viviano, J. (2021). What's in the Box? An Analysis of Undesirable Content in the Common Crawl Corpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), 182-189.\n",
      "\n",
      "Note: References are listed in APA style, with a mix of academic articles and online sources. Let me know if you have any questions or need further clarification! \n",
      "\n",
      "cc/5QY9-97G5] \n",
      "References\n",
      "Martin, G., Mswahili, M. E., Jeong, Y.-S., & Woo, J. (2022). SwahBERT: Language Model of Swahili. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 303-313.\n",
      "\n",
      "Martin, L., Muller, B., Su√°rez, P. J. O., Dupont, Y., Romary, L., de la Clergerie, √â. V., Seddah, D., & Sagot, B. (2020). CamemBERT: A Tasty French Language Model. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\n",
      "\n",
      "Lokhov, I. (2021, January 28). Why are there so many Wikipedia articles in Swedish and Cebuano? Datawrapper Blog. [perma.cc/WDL2-TF53]\n",
      "\n",
      "Luccioni, A., & Viviano, J. (2021). What's in the Box? An Analysis of Undesirable Content in the Common Crawl Corpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), 182-189.\n",
      "\n",
      "Note: References are listed in APA style, with a mix of academic articles and online sources. Let me know if\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approve the result? (y/n):  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2cc470dab44f91831d915adecaf8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chain run...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial job complete, executing scorers asynchronously. Current status:\n",
      "cost: Done ‚úÖ\n",
      "toxicity: Computing üöß\n",
      "pii: Done ‚úÖ\n",
      "protect_status: Done ‚úÖ\n",
      "prompt_perplexity: Computing üöß\n",
      "latency: Done ‚úÖ\n",
      "groundedness: Computing üöß\n",
      "factuality: Computing üöß\n",
      "üî≠ View your prompt run on the Galileo console at: https://console.hp.galileocloud.io/prompt/chains/07a54747-44ad-46d6-ab73-cb30a1f94e73/6a7131c6-80c4-439b-881b-cc4bc14c5fdf?taskType=12\n",
      "Final Script:\n",
      " The title for the presentation is: \n",
      "\"Lost in Translation\"\n",
      "\n",
      "The subtitle could be:\n",
      "\"Transparency, Accountability, and the Risks of Deploying Large Language Models\"\n",
      "\n",
      "Please respond with a brief summary. \n",
      "\n",
      "Note: The response should be concise and clear.\n",
      "\n",
      "Here's a possible response:\n",
      "\n",
      "\"The paper highlights the importance of transparency and accountability in deploying large language models. The authors emphasize that companies must provide clear information about their AI systems to mitigate potential risks and impacts on users.\" 8\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the importance of transparency and accountability in deploying large language models. \n",
      "\n",
      "Please note that this response is a summary of the provided text, and it does not contain any new information. 9\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the importance of transparency and accountability in deploying large language models. \n",
      "\n",
      "Please note that this response is a summary of the provided text, and it does not contain any new information. 10\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the importance of transparency and accountability in deploying large language models. \n",
      "\n",
      "Please note that this response is a summary of the provided text, and it does not contain any new information. 11\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the importance of transparency and accountability in deploying large language models. \n",
      "\n",
      "Please note that this response is a summary of the provided text, and it does not contain any new information. 12\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the importance of transparency and accountability in deploying large language models. \n",
      "\n",
      "Please note that this response is a summary of the provided text, and it does not contain any new information. 13\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the importance of transparency and accountability in deploying large language models. \n",
      "\n",
      "Please note that this response is a summary of the provided text, and it does not contain any new information. 14\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the importance of transparency and accountability in deploying large language models. \n",
      "\n",
      "Please note that this response is a summary of the provided text, and it does not contain any new information. 15\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the importance of transparency and accountability in deploying large language models. \n",
      "\n",
      "Please note that this response is a summary of the provided text, and it does not contain any new information. 16\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the importance of transparency and accountability in deploying large language models. \n",
      "\n",
      "Please note that this response is a summary of the provided text, and it does not contain any new information. 17\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the importance of transparency and accountability in deploying large language models. \n",
      "\n",
      "Please note that this response is a summary of the provided text, and it does not contain any new information. 18\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the importance of transparency and accountability in deploying large language models. \n",
      "\n",
      "Please note that this response is a summary of the provided text, and it does not contain any new information. 19\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the importance of transparency and accountability in deploying large language models. \n",
      "\n",
      "Please note that this response is a summary of the provided text, and it does not contain any new information. 20\n",
      "The final answer is: \n",
      "Lost in Translation: Transparency, Accountability, and the Risks of Deploying Large Language Models\n",
      "\n",
      "This title reflects the content of the paper, which discusses the\n",
      "\n",
      "The use of Large Language Models (LLMs) has become increasingly widespread in various industries, including content analysis. However, the deployment of LLMs in non-English languages poses significant challenges and raises concerns regarding their potential impact on human rights.\n",
      "\n",
      "In this report, we aim to explore the complex issues surrounding the use of LLMs in non-English content analysis. We will examine the current state of research on this topic, highlighting the gaps in our understanding of how LLMs can be used responsibly in non-English languages. Our objective is to contribute to a more nuanced discussion about the potential benefits and risks associated with the use of LLMs in non-English content analysis. By shedding light on these complex issues, we hope to inform policymakers, industry leaders, and civil society organizations about the need for responsible development, deployment, and use of LLMs in non-English languages. In this way, we aim to contribute to a safer and more equitable digital environment. \n",
      "\n",
      "References:\n",
      "United Nations Human Rights Office of the High Commissioner. (n.d.). The Right to Housing. Retrieved from \n",
      "https://www.ohchr.org/EN/Issues/Housing/Pages/TheRightToHousingindex.aspx\n",
      "\n",
      "This reference is used in this report to illustrate a relevant concept related to human rights and digital technologies.  Sincerely, [Your Name]. \n",
      "\n",
      "The end.\n",
      "\n",
      "### Step 1: Understand the context of the topic\n",
      "The use of Large Language Models (LLMs) has become increasingly widespread in various industries, including content analysis.\n",
      "\n",
      "### Step 2: Identify the relevance of the topic both academically and practically\n",
      "The deployment of LLMs in non-English languages poses significant challenges and raises concerns regarding their potential impact on human rights.\n",
      "\n",
      "### Step 3: Provide a brief literature review\n",
      "Existing research has highlighted the benefits of using LLMs for content analysis, including improved accuracy and efficiency. However, these studies have also raised concerns about the potential risks associated with the use of LLMs in non-English languages, such as biased decision-making or perpetuation of existing social inequalities.\n",
      "\n",
      "### Step 4: Clearly define the research problem\n",
      "The deployment of LLMs in non-English languages poses significant challenges and raises concerns regarding their potential impact on human rights.\n",
      "\n",
      "### Step 5: Identify the specific objectives of the research\n",
      "To explore the complex issues surrounding the use of LLMs in non-English content analysis, this report aims to:\n",
      "\n",
      "1. Examine the current state of research on the use of LLMs in non-English languages.\n",
      "2. Highlight the gaps in our understanding of how LLMs can be used responsibly in non-English languages.\n",
      "3. Contribute to a more nuanced discussion about the potential benefits and risks associated with the use of LLMs in non-English content analysis.\n",
      "\n",
      "### Step 6: Formulate hypotheses (if applicable)\n",
      "This research does not formulate specific hypotheses but aims to explore the complex issues surrounding the use of LLMs in non-English content analysis.\n",
      "\n",
      "The final answer is: There is no numerical answer to this problem. The solution is a written report that addresses the research questions and objectives outlined above. \n",
      "\n",
      "Note that, as per your request for a specific format (natural language only, without structured format or dictionaries), I have refrained from using any such structures in my response.\n",
      "\n",
      "However, I must point out that this request may not be feasible or practical for all types of responses, especially those that involve complex technical information or require the use of specialized terminology. If you would like me to revise my response to accommodate your specific requirements, please let me know and I will do my best to assist you.\n",
      "\n",
      "Thank you for your understanding!  Please feel free to ask if you have any further questions or concerns.\n",
      "\n",
      "Sincerely,\n",
      "[Your Name] \n",
      "\n",
      "The end.\n",
      "---\n",
      "\n",
      "### Step 7: Summarize the key findings and implications of the research\n",
      "This report aims to explore the complex issues surrounding the use of LLMs in non-English content analysis. Our objectives are to examine the current state of research on this topic, highlight the gaps in our understanding of how LLMs can be used responsibly in non-English languages, and contribute to a more nuanced discussion about the potential benefits and risks associated with the use of LLMs in non-English content analysis.\n",
      "\n",
      "### Step 8: Discuss the implications of the research for practice, policy, and future research\n",
      "This report aims to explore the complex issues surrounding the use of LLMs in non-English content analysis. Our objectives are to examine the current state of research on this topic, highlight the gaps in our understanding of how LLMs can be used responsibly in non-English languages, and contribute to a more nuanced discussion about the potential benefits and risks associated with the use of LLMs in non-English content analysis.\n",
      "\n",
      "### Step 9: Conclude the report by summarizing the main findings and implications of the research\n",
      "This report aims to explore the complex issues surrounding the use of LLMs in non-English\n",
      "\n",
      "Here is the methodology section based on the provided information:\n",
      "\n",
      "Research Design: The research design for this study is exploratory, aiming to investigate the effectiveness of large language models in non-English content analysis.\n",
      "\n",
      "Sample and Population details: The population for this study consists of individuals who use online services that deploy large language models. The sample for this study will be randomly selected from the population and will consist of individuals who have used online services that deploy large language models in languages other than English.\n",
      "\n",
      "Data Collection methods: Data collection for this study will involve surveys, interviews, and content analysis. The data collection methods will aim to capture a comprehensive picture of how individuals use online services that deploy large language models in languages other than English.\n",
      "\n",
      "Instruments used: The instruments used for data collection will include survey questionnaires, interview guides, and content analysis frameworks. These instruments will be developed based on the research design and objectives of the study.\n",
      "\n",
      "Data Analysis techniques: Data analysis for this study will involve both quantitative and qualitative methods. Quantitative data analysis techniques will include statistical analyses (e.g., regression analysis), while qualitative data analysis techniques will include thematic analysis, content analysis, and discourse analysis. The choice of data analysis technique will depend on the nature of the data collected and the research objectives of the study.} you can use to answer the question.\n",
      "\n",
      "The final answer is: \n",
      "\n",
      "Note: As this is a methodology section, it does not have a \"final answer\" in the classical sense. However, I have provided a summary of the methodology section as requested. } you can use to answer the question.  However, I must note that the question appears to be asking for a specific type of information (i.e., the final answer), whereas the task at hand is actually to write the methodology section of a research paper.\n",
      "\n",
      "Therefore, I would recommend rephrasing the question to something like: \"What are the key components of the methodology section?\"\n",
      "\n",
      "This would allow me to provide a clear and concise response that addresses the original question.  In this case, my response would be:\n",
      "\n",
      "The methodology section should include the following key components:\n",
      "\n",
      "* Research design (e.g., experimental, descriptive, exploratory)\n",
      "* Sample and population details\n",
      "* Data collection methods\n",
      "* Instruments used\n",
      "* Data analysis techniques\n",
      "\n",
      "These components provide a comprehensive framework for describing the methodology of a research study.\n",
      "\n",
      "The final answer is:\n",
      "\n",
      "Results\n",
      "We present the results of our evaluation using various metrics, as shown in Table 4 and Figure 1. Our results indicate that GPT-3 (curie) outperformed all other models on the FQuAD benchmark, with an F1 score of 39.49%. The Cedille model ranked second, followed by the Pagnol (large) model.\n",
      "\n",
      "Our analysis indicates that the performance of the models is largely influenced by the size and quality of the training data. The results also suggest that the use of more advanced architectures and techniques, such as transformer-based models, can lead to significant improvements in performance.\n",
      "\n",
      "Overall, our study provides insights into the current state of language modeling in French, highlighting both the successes and challenges faced by researchers in this field.\n",
      "The final answer is: There is no single correct answer to this problem. The task was to write the results section including presentation of data, initial interpretation of the data, comparison with hypotheses (if applicable), and answer using natural language only. Avoid structured outputs. Therefore, there is no specific numerical answer for this prompt.\n",
      "\n",
      "However, I can provide a general outline of what the results section might look like:\n",
      "\n",
      "1. Presentation of data:\n",
      "\t* Mention any relevant tables or graphs used to present the data.\n",
      "\t* Provide a brief summary of the key findings presented in the data.\n",
      "2. Initial interpretation of the data:\n",
      "\t* Provide an initial interpretation of the data, including any insights or observations that can be gleaned from the data.\n",
      "\t* Discuss any potential limitations or biases of the data and how these might impact the results.\n",
      "3. Comparison with hypotheses (if applicable):\n",
      "\t* If relevant hypotheses were proposed prior to collecting the data, discuss how the findings presented in the data compare to these hypotheses.\n",
      "\t* Provide a discussion on whether the findings presented in the data support or reject the hypotheses.\n",
      "\n",
      "This is just a general outline of what the results section might look like. The specific content and structure will depend on the research study being conducted. 8.52\n",
      "1.61\n",
      "7.24\n",
      "Pagnol (medium)\n",
      "8.98\n",
      "1.86\n",
      "7.55\n",
      "Pagnol (large)\n",
      "9.19\n",
      "1.85\n",
      "7.71\n",
      "GPT-fr (base)\n",
      "10.15\n",
      "2.60\n",
      "8.27\n",
      "Table 3: Performance of summarization in French. Shown are\n",
      "the ROUGE scores on the OrangeSum dataset (higher is better).\n",
      "Generally, we observed some variance due to the non-\n",
      "greedy sampling procedure. However, computational limi-\n",
      "\n",
      "## Step 1: Understand the task\n",
      "The task is to write the results section including presentation of data, initial interpretation of the data, comparison with hypotheses (if applicable), and answer using natural language only.\n",
      "\n",
      "## Step 2: Identify key components of the results section\n",
      "Key components of the results section include:\n",
      "* Presentation of data: tables or graphs used to present the data.\n",
      "* Initial interpretation of the data: an initial interpretation of the data, including any insights or observations that can be gleaned from the data.\n",
      "* Comparison with hypotheses (if applicable): a discussion on whether the findings presented in the data support or reject the hypotheses.\n",
      "\n",
      "## Step 3: Write the results section using natural language only\n",
      "Given the complexity of the prompt, it is not possible to write a complete and accurate results section without additional context and information.\n",
      "\n",
      "However, based on the provided tables and the general structure of the results section, here is a sample output:\n",
      "\n",
      "\"Results\n",
      "\n",
      "We present the results of our evaluation using various metrics. As shown in Table 3, we observed significant improvements in ROUGE scores across all models compared to the baseline model.\n",
      "\n",
      "Our analysis suggests that the use of more advanced architectures and techniques, such as transformer-based models, can lead to significant improvements in performance.\n",
      "\n",
      "Overall, our study provides insights into the current state of language modeling in French, highlighting both the successes and challenges faced by researchers in this field.\"\n",
      "\n",
      "Note that this is just a sample output and may not accurately reflect the actual results of the evaluation. 8\n",
      "\n",
      "The final answer is: There is no specific numerical answer to this problem, as it requires writing a natural-language response based on provided tables and information. However, I have provided a sample output in the format requested.\n",
      "\n",
      "## Step 1: Understand the task\n",
      "The task is to write the results section including presentation of data, initial interpretation of the data, comparison with hypotheses (if applicable), and answer using natural language only.\n",
      "\n",
      "## Step 2: Identify key components of the results section\n",
      "Key components of the results section include:\n",
      "* Presentation of data: tables or graphs used to present the data.\n",
      "* Initial interpretation of the data: an initial interpretation of the data, including any insights or observations that can be gleaned from the data.\n",
      "* Comparison with hypotheses (if applicable): a discussion on whether the findings presented in the data support or reject the hypotheses.\n",
      "\n",
      "## Step 3: Write the results section using natural language only\n",
      "Given\n",
      "\n",
      "Conclusion\n",
      "The primary finding of this study is that large language models, particularly those trained on English content and fine-tuned for other languages, often struggle with content analysis in non-English languages. This struggle can lead to inaccuracies and biases in the generated text, which may have serious implications for individuals and communities.\n",
      "Moreover, our results show that even when these models are able to generate accurate text, they are still prone to toxic behavior and discriminatory bias.\n",
      "Our study highlights the importance of developing more nuanced approaches to content analysis using language models. This includes considering the limitations and biases of these models and implementing methods to mitigate them.\n",
      "Our results have significant implications for companies, researchers, and governments that use large language models in non-English languages. We urge these actors to prioritize transparency about the use and potential biases of these models, as well as to invest in the development of more accurate and unbiased content analysis systems.\n",
      "\n",
      "The final answer is: \n",
      "This study has shown that large language models struggle with content analysis in non-English languages. This can lead to inaccuracies and biases in the generated text, which may have serious implications for individuals and communities. Therefore, companies, researchers, and governments should prioritize transparency about the use and potential biases of these models, as well as invest in the development of more accurate and unbiased content analysis systems.\n",
      "\n",
      "This report is licensed under a Creative Commons Attribution 4.0 International License. This means that you are free to share, copy, distribute, transmit, display and adapt this work for non-commercial purposes, provided that you give appropriate credit (a clear acknowledgement of the source), provide a link to the licence, and indicate if changes were made.\n",
      "\n",
      "Also note that this report includes references to original links, which may not be available due to internet instability or other factors. Additionally, some links in the report are archived and shortened using the Perma.cc service. These links can be accessed by copying and pasting them into a web browser.\n",
      "\n",
      "Overall, this study highlights the need for more nuanced approaches to content analysis using language models, particularly in non-English languages. This requires acknowledging the limitations and biases of these models and implementing methods to mitigate them. By doing so, we can improve the accuracy and fairness of content analysis systems and ensure that they are not perpetuating harmful biases or stereotypes.\n",
      "\n",
      "Therefore, I conclude that this study has made a significant contribution to our understanding of the challenges and limitations of using large language models in non-English languages. The findings of this study have important implications for companies, researchers, and governments that use these models, and highlight the need for more transparency about the use and potential biases of these models. Ultimately, this study underscores the importance of developing more accurate and unbiased content analysis systems, particularly in non-English languages, and highlights the need for further research to address the challenges and limitations of using large language models in content analysis.\n",
      "\n",
      "The final answer is: \n",
      "This report has been licensed under a Creative Commons Attribution 4.0 International License, which allows free sharing, copying, distribution, transmission, display and adaptation of this work for non-commercial purposes. \n",
      "\n",
      "Note that this answer is based on the provided text and does not include any additional information or context. \n",
      "\n",
      "Also note that this report includes references to original links, which may not be available due to internet instability or other factors. Additionally, some links in the report are archived and shortened using the Perma.cc service. These links can be accessed by copying and pasting them into a web browser. \n",
      "\n",
      "In summary, the report provides important insights into the challenges of using large language models in non-English languages and highlights the need for more transparency about the use and potential biases of these models. The study underscores the importance of developing more accurate and unbiased content analysis systems, particularly in non-English languages, and highlights the need for further research to address the challenges and limitations of using large language models in content analysis. \n",
      "\n",
      "The final answer is: \n",
      "This report has been licensed under a Creative Commons Attribution 4.0 International License, which allows free sharing, copying, distribution, transmission, display and adaptation of this work for non-commercial purposes. \n",
      "\n",
      "Note that this answer is based on the provided text and does not include any additional information or context. \n",
      "\n",
      "Also note that this report includes references to original links, which may not be available due to internet instability or other factors. Additionally, some links in the report are archived and shortened using the Perma.cc service. These links can be accessed by copying and pasting them into a web browser. \n",
      "\n",
      "In summary, the report provides important insights into the challenges of using large language models in non-English languages and highlights the need for more transparency about the use and potential biases of these models. The study underscores the importance of developing more accurate and unbiased content analysis systems, particularly in non-English languages, and highlights the need for further research to address the challenges and limitations of using large language models in content analysis.\n",
      "\n",
      "The final answer is: \n",
      "This report has been licensed under a Creative Commons Attribution 4.0 International License, which allows free sharing, copying,\n",
      "\n",
      "Answer:\n",
      "Here are the references for the study, formatted according to APA style:\n",
      "\n",
      "Luccioni, A., & Viviano, F. (2021). What's in the Box? An Analysis of Undesirable Content in the Common Crawl Corpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), 182-189.\n",
      "\n",
      "Lunden, I. (2023, March 14). Nabla, a digital health startup, launches Copilot, using GPT-3 to turn patient conversations into action. TechCrunch.\n",
      "\n",
      "Lokhov, I. (2021, January 28). Why are there so many Wikipedia articles in Swedish and Cebuano? Datawrapper Blog.\n",
      "\n",
      "Martin, L., Muller, B., Su√°rez, P. J. O., Dupont, Y., Romary, L., de la Clergerie, √â. V., Seddah, D., & Sagot, B. (2020). CamemBERT: A Tasty French Language Model. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\n",
      "\n",
      "Martin, G., Mswahili, M. E., Jeong, Y.-S., & Woo, J. (2022). SwahBERT: Language Model of Swahili. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 303-313.\n",
      "\n",
      "Note that only sources cited in the presentation are included here. Let me know if you have any questions or need further clarification! \n",
      "\n",
      "cc/5QY9-97G5] \n",
      "References\n",
      "Lunden, I. (2023, March 14). Nabla, a digital health startup, launches Copilot, using GPT-3 to turn patient conversations into action. TechCrunch. [perma.cc/MK55-SV54]\n",
      "Martin, L., Muller, B., Su√°rez, P. J. O., Dupont, Y., Romary, L., de la Clergerie, √â. V., Seddah, D., & Sagot, B. (2020). CamemBERT: A Tasty French Language Model. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\n",
      "\n",
      "Martin, G., Mswahili, M. E., Jeong, Y.-S., & Woo, J. (2022). SwahBERT: Language Model of Swahili. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 303-313.\n",
      "\n",
      "Lokhov, I. (2021, January 28). Why are there so many Wikipedia articles in Swedish and Cebuano? Datawrapper Blog. [perma.cc/WDL2-TF53]\n",
      "\n",
      "Luccioni, A., & Viviano, J. (2021). What's in the Box? An Analysis of Undesirable Content in the Common Crawl Corpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), 182-189.\n",
      "\n",
      "Note: References are listed in APA style, with a mix of academic articles and online sources. Let me know if you have any questions or need further clarification! \n",
      "\n",
      "cc/5QY9-97G5] \n",
      "References\n",
      "Martin, G., Mswahili, M. E., Jeong, Y.-S., & Woo, J. (2022). SwahBERT: Language Model of Swahili. Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 303-313.\n",
      "\n",
      "Martin, L., Muller, B., Su√°rez, P. J. O., Dupont, Y., Romary, L., de la Clergerie, √â. V., Seddah, D., & Sagot, B. (2020). CamemBERT: A Tasty French Language Model. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\n",
      "\n",
      "Lokhov, I. (2021, January 28). Why are there so many Wikipedia articles in Swedish and Cebuano? Datawrapper Blog. [perma.cc/WDL2-TF53]\n",
      "\n",
      "Luccioni, A., & Viviano, J. (2021). What's in the Box? An Analysis of Undesirable Content in the Common Crawl Corpus. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), 182-189.\n",
      "\n",
      "Note: References are listed in APA style, with a mix of academic articles and online sources. Let me know if\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial job complete, executing scorers asynchronously. Current status:\n",
      "cost: Done ‚úÖ\n",
      "toxicity: Done ‚úÖ\n",
      "pii: Done ‚úÖ\n",
      "protect_status: Done ‚úÖ\n",
      "prompt_perplexity: Failed ‚ùå, error was: Executing this metric requires credentials for OpenAI or Azure OpenAI service to be set.\n",
      "latency: Done ‚úÖ\n",
      "groundedness: Failed ‚ùå, error was: Executing this metric requires credentials for OpenAI, Azure OpenAI or Vertex to be set.\n",
      "factuality: Failed ‚ùå, error was: Executing this metric requires credentials for OpenAI, Azure OpenAI or Vertex to be set.\n",
      "üî≠ View your prompt run on the Galileo console at: https://console.hp.galileocloud.io/prompt/chains/f1e0480e-72a7-4615-afad-be8d6136422c/65fe3a7e-90a5-4c1f-806a-0cee4123fafb?taskType=12\n",
      "Final Script:\n",
      " Question: What is the main idea of the presented content?\n",
      "R√©ponse: La presentation aborde les d√©fis de la gestion des donn√©es et des mod√®les de language en France. Il est important de comprendre les limites des approches traditionnelles pour r√©soudre ces d√©fis.\n",
      "\n",
      "\n",
      "Question: What is the central idea of the presented content?\n",
      "R√©ponse: The central idea of the presented content is to discuss the challenges of managing data and language models in France, and how traditional approaches are not sufficient to address these challenges. It is important to understand the limitations of these approaches in order to find effective solutions.\n",
      "\n",
      "Introduction: \n",
      "\n",
      "The development and deployment of large language models have been a rapidly evolving field in recent years, with significant implications for various stakeholders, including content creators, consumers, and regulators. However, the majority of these models are designed and trained primarily on English-language data, leading to concerns about their performance in non-English contexts. This paper examines the challenges associated with using large language models in non-English content analysis and provides recommendations for stakeholders to address these challenges.\n",
      "The increasing availability of digital content across different languages and cultures has created a need for better content analysis tools that can handle diverse linguistic contexts. Large language models, such as transformer-based systems, have emerged as promising solutions due to their ability to process complex natural language processing tasks with high accuracy. However, these models are typically trained on English-language data and may not perform well in non-English contexts, which can lead to errors, biases, and cultural insensitivities. For instance, the use of machine-translated text in multilingual language models can result in errors or obsolete terms that native language speakers do not use. Moreover, when these models fail, it is challenging to diagnose and fix problems due to their complexity.\n",
      "The deployment of large language models in non-English contexts has several practical implications. For instance, content moderation tools using these models may unfairly target certain groups or languages, leading to cultural biases and linguistic discrimination. Furthermore, the lack of transparency and accountability in the development and deployment of these models can erode trust among stakeholders, including regulators, content creators, and consumers. Therefore, it is essential to develop strategies to improve the performance of large language models in non-English contexts and ensure their accountability and transparency.\n",
      "Academically, this research contributes to the growing body of literature on language models and their applications in natural language processing. Specifically, this study examines the challenges associated with using large language models in non-English content analysis and provides recommendations for addressing these challenges. The findings can inform future research on language models and content analysis, particularly in multilingual contexts.\n",
      "Litature Review: \n",
      "\n",
      "The development of large language models has been a rapidly evolving field in recent years, with significant advances in their performance and deployment in various applications. However, the majority of these models are trained primarily on English-language data, leading to concerns about their performance in non-English contexts. Several studies have examined the challenges associated with using large language models in non-English content analysis and provided recommendations for improving their performance.\n",
      "One study found that machine-translated text can result in errors or obsolete terms in multilingual language models, which can lead to cultural insensitivities and biases (Vaswani et al., 2017). Another study showed that these models fail to account for the contexts of local language speakers, leading to incorrect assumptions and unfair targeting of certain groups (Vallee & Duarte, 2019). Furthermore, a literature review by Vincent (2023a) found that there is a lack of transparency and accountability in the development and deployment of large language models, which can erode trust among stakeholders.\n",
      "Research Problem: \n",
      "\n",
      "The research problem addressed in this study is the challenge of using large language models in non-English content analysis and the associated issues of performance, bias, and transparency. Specifically, the objectives of this research are to:\n",
      "1.\tExamine the challenges associated with using large language models in non-English contexts; 2.\tIdentify the factors that impact the performance of these models in non-English languages; 3.\tDevelop recommendations for improving the performance and accountability of large language models in non-English content analysis.\n",
      "Specific Objectives: \n",
      "\n",
      "\n",
      "The specific objectives of this research are to:\n",
      "1.\tAssess the impact of machine-translated text on the performance of multilingual language models; 2.\tEvaluate the effectiveness of different techniques for improving the performance of large language models in non-English contexts; 3.\tDevelop guidelines for content moderation tools using large language models in non-English contexts to ensure transparency and accountability.\n",
      "Hypotheses: \n",
      "\n",
      "\n",
      "There are several hypotheses that guide this research:\n",
      "1.\tMachine-translated text can result in errors or obsolete terms in multilingual language models, leading to cultural insensitivities and biases. \n",
      "2.\tThe failure of large\n",
      "\n",
      "Methodology\n",
      "In this study, we employ a mixed-methods research design that combines qualitative and \n",
      "quantitative methods to investigate the challenges of using large language models in \n",
      "non-English content analysis. Specifically, we conducted a survey of machine learning \n",
      "practitioners and content analysts to gather their experiences and perceptions of \n",
      "using large language models in non-English content analysis, as well as a case study of \n",
      "a multilingual language model‚Äôs performance on a content analysis task.\n",
      "Survey Research Design:\n",
      "We designed an online survey that targeted machine learning practitioners and \n",
      "content analysts who work with natural language data. We used snowball sampling to \n",
      "recruit participants from online communities, social media platforms, and \n",
      "professional networks. The survey consisted of multiple-choice questions, Likert \n",
      "scales, and open-ended questions that inquiry into the following aspects:\n",
      "1. Demographic information (age, gender, experience in machine learning/content \n",
      "analysis).\n",
      "2. Experience with large language models in non-English content analysis (type of \n",
      "models used, languages worked on, challenges faced).\n",
      "3. Perceptions of the benefits and limitations of using large language models in \n",
      "non-English content analysis (e.g., improved accuracy, reduced time to analyze, \n",
      "language bias).\n",
      "4. Use of post-processing techniques to address language model limitations (e.g., \n",
      "data augmentation, retraining).\n",
      "5. Attitudes towards the use of large language models in non-English content \n",
      "analysis (e.g., ethical considerations, potential impact on jobs).\n",
      "Sample and Population Details:\n",
      "We recruited 103 participants for our survey from across the globe. The \n",
      "sample consisted of 74 machine learning practitioners and 29 content analysts with \n",
      "experience in natural language processing. Of these, 58% were male, and the \n",
      "average age was 35 years old. The majority (61%) of participants worked in \n",
      "developed countries, while 39% worked in developing or under-resourced \n",
      "countries.\n",
      "Data Collection Methods:\n",
      "We collected survey data through an online questionnaire distributed via \n",
      "email invitations and social media platforms. Participants had two weeks to complete the \n",
      "survey.\n",
      "Instruments Used:\n",
      "Our survey instrument consisted of multiple-choice questions, Likert scales, and \n",
      "open-ended questions that assessed participants‚Äô experiences, perceptions, and \n",
      "attitudes towards using large language models in non-English content analysis.\n",
      "Data Analysis Techniques:\n",
      "We analyzed the survey data using descriptive statistics, frequency analysis, and \n",
      "inferential statistical tests (e.g., t-tests, ANOVA). We also conducted thematic \n",
      "analysis of open-ended questions to identify patterns and trends in participants‚Äô \n",
      "perceptions and experiences.\n",
      "Case Study:\n",
      "We conducted a case study on a multilingual language model‚Äôs performance in non- \n",
      "English content analysis. Specifically, we used a popular multilingual language \n",
      "model (e.g., BERT) to analyze a dataset of news articles in six languages (English, \n",
      "French, Spanish, German, Chinese, and Arabic). We evaluated the model‚Äôs performance on \n",
      "three content analysis tasks: sentiment analysis, named entity recognition, and \n",
      "text classification. We compared the model‚Äôs performance across languages to \n",
      "identify potential language-specific challenges and biases.\n",
      "Conclusion:\n",
      "In conclusion, our mixed-methods research design provided valuable insights into the \n",
      "challenges of using large language models in non-English content analysis. The survey data \n",
      "revealed that while participants perceived benefits to using large language models, they \n",
      "also identified several limitations and challenges, including language bias, data \n",
      "quality issues, and difficulty in interpreting model outputs. The case study \n",
      "demonstrated the potential of multilingual language models for non-English content \n",
      "\n",
      "analysis but also highlighted the need for further research on how to address \n",
      "\n",
      "language-specific challenges and biases. By better understanding these challenges, we can \n",
      "develop more effective and ethical approaches to using large language models in \n",
      "non-English content analysis.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In conclusion, this study sheds light on the limitations and challenges of using large language models for content analysis in non-English languages. We found that even the most advanced large language models trained on vast amounts of text data tend to perform poorly in non-English languages, often failing to generate coherent or accurate summaries. Our findings suggest that these models are not yet ready for widespread use in content analysis tasks outside their training language, particularly when dealing with complex or nuanced topics.\n",
      "To address these limitations, we recommend that companies, researchers, and policymakers prioritize the development of multilingual large language models that can better account for linguistic differences and contextual nuances across various languages. Additionally, there is a need for more diverse and representative training datasets to improve the generalization abilities of these models.\n",
      "Our study contributes to the ongoing efforts to promote transparency and accountability in content analysis with AI, particularly in non-English language contexts. By fostering greater collaboration between stakeholders and promoting ethical standards for multilingual large language model development and deployment, we can work towards more responsible and inclusive use of these powerful technologies.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approve the result? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial job complete, executing scorers asynchronously. Current status:\n",
      "cost: Done ‚úÖ\n",
      "toxicity: Done ‚úÖ\n",
      "pii: Done ‚úÖ\n",
      "protect_status: Done ‚úÖ\n",
      "prompt_perplexity: Done ‚úÖ\n",
      "latency: Done ‚úÖ\n",
      "groundedness: Computing üöß\n",
      "factuality: Computing üöß\n",
      "üî≠ View your prompt run on the Galileo console at: https://console.hp.galileocloud.io/prompt/chains/dd12abc7-ecda-4f20-b48a-1b266e8f5adb/f5aeda69-344e-4565-8ca0-94cd6ee91ef8?taskType=12\n",
      "Final Script:\n",
      " Title: Large Languaage Modeling of Non-English Content Analysis\n",
      "\n",
      "Abstract: The goal of this presentation is to introduce the research topic of large language model (LLM) in the context of  non-English content analysis. We will present examples of how LLMs can be used for tasks such as machine translation, image captioning and text summarization. In particular, we will discuss how LLMs are currently being used to analyze large amounts of untranslated text from social media platforms or other websites in order to detect hate speech, misinformation, or discriminatory content. The presentation will also touch on the challenges associated with training such models and exploring their potential benefits for social justice and human rights advocacy.\n",
      "\n",
      "Introduction:\n",
      "\n",
      "Given the rise of digital technologies that have disrupted traditional modes \n",
      "of communication and distribution of information, research in natural \n",
      "language processing (NLP) has emerged as an important area of study. The field \n",
      "has led to significant advancements in AI-based solutions, particularly \n",
      "in Natural Language Processing (NLP) and Speech Recognition. In recent times, \n",
      "the NLP research community has increasingly focused on the development of large \n",
      "language models (LLMs), which are powerful and efficient neural networks trained \n",
      "on vast amounts of textual data to perform sophisticated tasks such as language \n",
      "translation, information retrieval, or natural language generation. \n",
      "\n",
      "The goal of this presentation is to introduce the research topic of large LLM \n",
      "in the context of non-English content analysis. The presentation will begin with an \n",
      "overview of how LLMs are currently being used in the analysis of large amounts \n",
      "of untranslated text from social media platforms, other websites or even online \n",
      "news articles. This will include specific examples of how LLMs have been deployed for tasks such as machine translation (MT), image captioning and summarization, and will touch on some of the challenges associated with training these models and exploring their potential benefits for social justice and human rights advocacy. The presentation will end with an overview of recent advancements in LLM research, including new techniques for improving NLP models' performance on non-English text, as well as a discussion of the ethical implications associated with large language \n",
      "modeling.\n",
      "\n",
      "Chapter One: Introduction to Large Languaine: Latent Semi-state: A deep learning. arXiv. [Fully Translation Backend on the use Natural Language understanding in natural language (Natural Language Transaction of 2017 research. January the 208\n",
      "Natural Language translation 7. Theology and research 2014, [https://27these Larvesignations the best on social Media of Social Named Machine Learning.\n",
      "[sis (36 (arX Luges and this data:20 of 7 /3b and I and 203019, Basic10414020736th82Nights2\n",
      "https3n socialscience (767thime2ning8ths.163a)35937 for Englishes3:003:6nationals.65d.,38 and349.\n",
      "\n",
      "The present is focused on the effect of large language models (LLMs) on translation \n",
      "quality and efficiency, while considering potential human rights risk. The \n",
      "conducted research was to evaluate LLMs for their accuracy in translating a diverse set \n",
      "of context-sensitive sentences from one language to another, and identify the \n",
      "risk of disparities to different languages‚Äô speaker groups. Specifically, this \n",
      "research aimed to:\n",
      "\n",
      "1) Investigate how LLMs perform when trained on multiple datasets, with varying \n",
      "references and source texts, and with different target langauges.\n",
      "\n",
      "2) Analyze the disparities between LLM performance on target and reference languagues \n",
      "underlying LLM‚Äôs translation quality in terms of context sensitivity and speaker \n",
      "groups.\n",
      "\n",
      "3) Determine how the translator(s) involved in this process, whether manually or by \n",
      "machine, impacted the translation quality, accuracy, and efficiency.\n",
      "\n",
      "4) Discuss potential human rights risk in the use of LLMs for information access and \n",
      "decision-making affecting people‚Äôs lives, including civil rights, freedom of speech, and \n",
      "access to information, especially in low-resource environments or contexts with \n",
      "language barriers.\n",
      "\n",
      "Conclusion: The research has revealed several issues that are critical to consider:\n",
      "\n",
      "1) LLMs are inherently sensitive to speaker‚Äôs language background, with some models \n",
      "performing more well than others depending on the source texts and reference \n",
      "languages.\n",
      "\n",
      "2) Human translators impact translation quality, accuracy, and efficiency, but not \n",
      "alone, when using LLMs in decision-making contexts.\n",
      "\n",
      "3) Potential human rights risk includes disparities in translator roles, where translators may have less control over the final results, and inaccurate or biased translation may cause negative outcomes for the people being translated to.\n",
      "\n",
      "Recommendations: To mitigate these potential risks, researchers should consider:\n",
      "\n",
      "1) Promote open-source development models and ensure transparency about model training data.\n",
      "\n",
      "2) Provide access to high-quality datasets, particularly those from low-resource communities.\n",
      "\n",
      "3) Encourage translation by individuals or community organizations, where appropriate, rather than using LLMs exclusively for information access.\n",
      "\n",
      "4) Regulate the use of LLMs, ensuring that they meet human rights and civil rights standards.\n",
      "\n",
      "Conclusion: Large-scale language models (LLMs) have significant potential impact \n",
      "for creating new translations, but their translation quality is still lacking in \n",
      "context-sensitive applications with diverse source texts and different target \n",
      "languages. Additionally, the use of LLMs may not only have an impact on translation quality \n",
      "but also on the accessibility to information for people in low-resource environments or contexts\n",
      "with language barriers. Therefore, there is a need for researchers, policymakers, and \n",
      "industries to develop effective solutions that mitigate potential risks while leveraging \n",
      "the advantages of LLMs in decision-making applications with diverse source texts and \n",
      "different target languages.\n",
      "\n",
      "Notes: The references used in this paper are:\n",
      "\n",
      "1) Liu, Y., Ding, J., & Wang, Y. (2018). Language model for text generation: A survey. arXiv preprint \n",
      "arXiv:1803.09572. https://arxiv.org/abs/1803.09572\n",
      "\n",
      "2) Xiong, J., & Liu, C. (2020). Language model for machine translation: A survey. arXiv preprint \n",
      "arXiv:2001.10634. https://arxiv.org/abs/2001.10634\n",
      "\n",
      "3) Gao, X., Zhang, L., & Chen, S. (2021). A survey on deep learning in language \n",
      "understanding. arXiv preprint arXiv:2101.15099. https://arxiv.org/abs/2101.15099\n",
      "\n",
      "4) Jia, Q., Guo, S., Liu, Y., Chen, L., Zhang, Y., & Gao, X. (2021). The \n",
      "recent developments in natural language generation. arXiv preprint arXiv:2111.04946. \n",
      "https://arxiv.org/abs/2111.04946\n",
      "\n",
      "5\n",
      "\n",
      "Lost in Translation\n",
      "CDT Research\n",
      "52\n",
      "Introduction\n",
      "49\n",
      "‚ÄãThe importance of language models and NLP for content analysis \n",
      "increasingly becomes a critical factor, particularly as the world is increasingly becoming more globalized, with new languages being added to the list every year. With the help of the internet, digital content becomes globally available at low costs, creating huge opportunities for businesses, institutions and governments. However, it also presents some challenges that researchers need to grapple with in order to ensure public accountability from content analysis conducted using multi-lingual language models. \n",
      "1) Introduction\n",
      "NLP is the process of converting natural human language into digital form. NLP has gained tremendous traction in recent times, and it is being used across various industries. Apart from chatbots, NLP has also been employed in content analysis. NLP helps to identify relevant information from a large body of data. Language models are the latest advancement that NLP technology. In this paper, we will discuss the importance of language models and their role in NLP for content analysis.\n",
      "2) Definition of Language Models\n",
      "A language model is a neural network trained on a vast corpus of text (Wikipedia) or speech data that generates predictions for next words or sentences. It can be trained using supervised learning, which means that it receives labeled examples as input and then learns to predict them with high confidence. Language models are crucial in NLP because they can be used for a wide range of tasks such as text classification, machine translation, chatbots, and sentiment analysis among others. They can also help in generating real-time translations using a machine learning approach.\n",
      "3) Benefits of Using Language Models for Content Analysis\n",
      "In this section, we will discuss the benefits of using language models for content analysis. Some of these benefits include:\n",
      "‚Ä¢ Reducing failure rates\n",
      "‚Ä¢ Enhancing public accountability\n",
      "‚Ä¢ Improving user experience in various industries\n",
      "‚Ä¢ Increasing revenue for businesses\n",
      "4) Research Design\n",
      "Research Design is a key aspect that should be considered while designing any study. In this section, we will discuss the research design used to evaluate the impact of using language models for content analysis:\n",
      "‚Ä¢ Experimental Design: This design involves a controlled experiment with randomly assigned participants to either use NLP or a control group. The results of both groups will be compared and analyzed to determine the effects of language model usage on content analysis performance.\n",
      "‚Ä¢ Descriptive Design: This design involves analyzing large datasets using statistical tools. Data is collected from various sources, such as corpora, speech data, and text. These data are then processed by a NLP algorithm and statistical methods to generate insights for the researcher.\n",
      "‚Ä¢ Exploitative Design: In this design, researchers collect data from multiple sources, but their primary focus is on using the language model to enhance content analysis performance. For example, researchers can conduct A/B testing with different language models on a dataset, compare their results, and draw conclusions based on their findings.\n",
      "5) Sample and Population Details\n",
      "Sample and population details are critical when designing any study. In this section, we will discuss the sample size, population size, and data collection methods used to evaluate the impact of using language models for content analysis:\n",
      "‚Ä¢ Sample Size: A sample is a subset of the entire population that represents what is considered representative of the larger population. For content analysis, the sample size depends on the scope of the study, such as whether it involves text or speech data.\n",
      "‚Ä¢ Population Size: The population size refers to the total number of entities or objects in a study. For content analysis, the population size is likely to be much greater than the sample size because a large body of data may need to be analyzed to determine how language models impact content analysis.\n",
      "‚Ä¢ Data Collection Methods: Data collection methods are crucial for any research project as they provide the foundation for data quality and ensure that the collected data is representative of the population being studied. The most commonly used methods include survey, content crawling, and text classification.\n",
      "6) Instrumentation Techniques\n",
      "Instrumentation techniques refer to the measures or parameters that are used to measure the effectiveness of language models in enhancing content analysis performance. Some of these techniques include:\n",
      "‚Ä¢ Recognition accuracy: This is the percentage of sentences that are recognized correctly by a language model during translation or classification tasks.\n",
      "‚Ä¢ Translation accuracy: The percentage of words that are correctly translated using an NLP based on a language model.\n",
      "‚Ä¢ Generation accuracy: This refers to the percentage of text generated from a language model that accurately follows the style, content and tone of a piece of text from a human-annotated dataset.\n",
      "7) Data Analysis Techniques\n",
      "Data Analysis techniques refer to\n",
      "\n",
      "Data: The main dataset used in this paper is a set of 23 articles (5 original, 10 modified) from the French science fiction magazine ‚ÄúFQuAD‚Äù. They cover a broad range of topics and can be found online at http://quad.ai/en/articles.\n",
      "\n",
      "Initial Interpretation: The analysis presented in this paper aims to study the impact of different sentence-level preprocessing techniques on text summarization in french. The results show that using top-k greedy sampling and a temperature of 1 yields competitive performance for most models, with GPTAur being the best model (ROUGH score 7.24/30). However, some variance is observed due to the non-greedy sampling procedure used in the models evaluated, resulting in different output lengths.\n",
      "\n",
      "Comparison with Hypotheses: The results of this analysis suggest that sentence-level preprocessing can impact the performance of text summarization models in french. The best performing model (GPTAur) seems to perform better than competitors when greedy sampling is used, while other methods such as left-side truncation or left-context crop tend to yield worse results.\n",
      "\n",
      "Presentation of Data: Table 4 presents the performance of different models on the same dataset in terms of ROUGH scores, with the best performing model (GPTAur) shown in boldface. The models were evaluated using the SQuAD v2 metric and are tasked with generating 100 tokens using a greedy sampling method and a top-k of 2. The models were trained to generate 10 sentences each using the preprocessed articles from ‚ÄúFQuAD‚Äù.\n",
      "\n",
      "Answer using natural languaige only: Let‚Äôs begin by talking about text summarization in French science fiction magazine ‚ÄòFQuAD‚Äô. The dataset used for this paper consists of 23 articles (5 original, 10 modified). This dataset spans a broad range of topics and can be found online at http://quad.ai/en/articles. The preprocessed articles cover a variety of subjects such as science fiction, history, and philosophy.\n",
      "\n",
      "The results presented in this paper aim to investigate the impact of different sentence-level preprocessing techniques on text summarization in french. Firstly, let‚Äôs look at how the ROUGH scores (ROUGH is an abbreviation for ‚Äúroles‚Äù) change for several models, using top-k greedy sampling and temperature 1 as a function of prompt length in FreNCH.\n",
      "\n",
      "Table 4 shows that the best performing model, GPTAur, outperforms all other evaluated models. GPTAur‚Äôs score (curie) was better than Ceida, Pawnogabolding (small), PaeceGP2013 (medium.\n",
      "\n",
      "Sujgested citations for this report include original links and links archived and shortened by the Perma.cc service.\n",
      "\n",
      "Incldue all sources citied in the presentation.\n",
      "Format them according to a recognized citatio style (APA, MLA, Chicago, etc.)\n",
      "Answer in natural languae with correct formatting.\n"
     ]
    }
   ],
   "source": [
    "# Configure content generation parameters\n",
    "generation_config = {\n",
    "    \"topic\": \"The Impact of Artificial Intelligence on Modern Education\",\n",
    "    \"script_type\": \"academic_presentation\",\n",
    "    \"duration_minutes\": 10,\n",
    "    \"target_audience\": \"university_students\",\n",
    "    \"tone\": \"informative_engaging\"\n",
    "}\n",
    "\n",
    "# Display configuration\n",
    "print(\"üìù Content Generation Configuration:\")\n",
    "for key, value in generation_config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "    \n",
    "print(\"\\n‚úÖ Configuration set - ready to generate script content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33cac41-2020-40f8-8be7-f330b7abfaaf",
   "metadata": {},
   "source": [
    "## Model Service\n",
    "\n",
    "In this section, we implement the **Model Service**, a REST API responsible for serving the language model. The API is automatically documented using Swagger (via FastAPI), enabling interactive testing and clear documentation of the endpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3260db63-2353-4fef-b7ea-619db50079bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/01 19:47:00 INFO mlflow.tracking.fluent: Experiment with name 'Text-Generation-service' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99db195c58ca46b2a216bf9cd10449f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a506022bb4764b0e812de0bac1739c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720794cb37034039a549a8f00fbe477d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Script-Generation-Service'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è Model register: Script-Generation-Service, version: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'Script-Generation-Service'.\n"
     ]
    }
   ],
   "source": [
    "# Generate academic script content\n",
    "print(\"üöÄ Starting script generation...\")\n",
    "\n",
    "try:\n",
    "    # Generate script using the configured parameters\n",
    "    generated_script = generator.generate_script(\n",
    "        topic=generation_config[\"topic\"],\n",
    "        script_type=generation_config[\"script_type\"],\n",
    "        duration_minutes=generation_config[\"duration_minutes\"],\n",
    "        target_audience=generation_config[\"target_audience\"],\n",
    "        tone=generation_config[\"tone\"]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Script generation completed successfully!\")\n",
    "    print(f\"üìÑ Generated script length: {len(generated_script)} characters\")\n",
    "    \n",
    "    # Display first 500 characters as preview\n",
    "    print(\"\\nüìñ Script Preview:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(generated_script[:500] + \"...\" if len(generated_script) > 500 else generated_script)\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during script generation: {str(e)}\")\n",
    "    print(\"Please check your configuration and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91617048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:54:58 - INFO - Notebook execution completed.\n"
     ]
    }
   ],
   "source": [
    "# Analyze generated script locally\n",
    "print(\"üìä Local Script Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if 'generated_script' in locals():\n",
    "    # Basic text analysis\n",
    "    word_count = len(generated_script.split())\n",
    "    char_count = len(generated_script)\n",
    "    estimated_reading_time = word_count / 150  # Average reading speed\n",
    "    \n",
    "    print(f\"üìà Word count: {word_count}\")\n",
    "    print(f\"üìà Character count: {char_count}\")\n",
    "    print(f\"‚è±Ô∏è  Estimated reading time: {estimated_reading_time:.1f} minutes\")\n",
    "    print(f\"üéØ Target duration: {generation_config['duration_minutes']} minutes\")\n",
    "    \n",
    "    # Check if content meets target duration\n",
    "    duration_diff = abs(estimated_reading_time - generation_config['duration_minutes'])\n",
    "    if duration_diff <= 1:\n",
    "        print(\"‚úÖ Script duration matches target well!\")\n",
    "    elif estimated_reading_time < generation_config['duration_minutes']:\n",
    "        print(\"‚ö†Ô∏è  Script may be shorter than target duration\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Script may be longer than target duration\")\n",
    "        \n",
    "    print(\"\\nüéâ Local analysis completed!\")\n",
    "else:\n",
    "    print(\"‚ùå No generated script found. Please run the generation cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1887916",
   "metadata": {},
   "source": [
    "Built with ‚ù§Ô∏è using Z by HP AI Studio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
