{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ad548a",
   "metadata": {},
   "source": [
    "# Register Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4670f0ae",
   "metadata": {},
   "source": [
    "## Notebook Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6192b4f3",
   "metadata": {},
   "source": [
    "- Start Execution\n",
    "- Install and Import Libraries\n",
    "- Configure Settings\n",
    "- Model Service Registration to MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a27170",
   "metadata": {},
   "source": [
    "# Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e3a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "# Configure logger\n",
    "logger: logging.Logger = logging.getLogger(\"register_model_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent duplicate logs from parent loggers\n",
    "\n",
    "# Set formatter\n",
    "formatter: logging.Formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Configure and attach stream handler\n",
    "stream_handler: logging.StreamHandler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c40cd27a-a4a7-4c09-89c0-5be4217717c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 12:50:16 - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  \n",
    "\n",
    "logger.info(\"Notebook execution started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a18876b",
   "metadata": {},
   "source": [
    "# Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23a663a-22ec-4f40-ab6b-5bd5659d5e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CPU times: user 49 ms, sys: 18.2 ms, total: 67.2 ms\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066d4e2f-063f-4b5e-afc8-456e136a1c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:137: FutureWarning: Model's `predict` method contains invalid parameters: {'_', 'df'}. Only the following parameter names are allowed: context, model_input, and params. Note that invalid parameters will no longer be permitted in future versions.\n",
      "  param_names = _check_func_signature(func, \"predict\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Standard Library Imports ===\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the relative path to the 'src' directory (two levels up from current working directory)\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add 'src' directory to system path for module imports (e.g., utils)\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# === Third-Party Imports ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from typing import List\n",
    "\n",
    "# Import transformers from huggingface\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "#Import components of notebook\n",
    "from core.extract_text.arxiv_search import ArxivSearcher\n",
    "from core.generator.script_generator import ScriptGenerator\n",
    "from core.analyzer.scientific_paper_analyzer import ScientificPaperAnalyzer\n",
    "from core.deploy.text_generation_service import TextGenerationService\n",
    "\n",
    "#import langchain libraries\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEndpoint\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "# === Project-Specific Imports (from src.utils) ===\n",
    "from src.utils import (\n",
    "    load_config,\n",
    "    load_secrets,\n",
    "    load_secrets_to_env,\n",
    "    configure_proxy,\n",
    "    initialize_llm,\n",
    "    configure_hf_cache\n",
    ")\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# Import the TextGenerationService class\n",
    "from core.deploy.text_generation_service import TextGenerationService"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10857aca",
   "metadata": {},
   "source": [
    "# Configure Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "423e7ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Suppress Verbose Logs ------------------------\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ec59b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you just want to run this cell without the rest of the notebook \n",
    "# (you still need to install the requirements and run the import block), run the following block:\n",
    "CONFIG_PATH = \"../configs/config.yaml\"\n",
    "SECRETS_PATH = \"../configs/secrets.yaml\"\n",
    "MODEL_PATH = \"/home/jovyan/datafabric/meta-llama3.1-8b-Q8/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\"\n",
    "\n",
    "# Define demo folder path\n",
    "DEMO_FOLDER = \"../demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4460bae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 2 secrets into environment variables.\n",
      "✅ Configuration loaded successfully\n",
      "✅ Secrets loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load secrets from secrets.yaml file (if it exists) into environment\n",
    "if Path(SECRETS_PATH).exists():\n",
    "    load_secrets_to_env(SECRETS_PATH)\n",
    "else:\n",
    "    print(f\"No secrets file found at {SECRETS_PATH}; relying on preexisting environment\")\n",
    "\n",
    "# Retrieve secrets from environment\n",
    "try:\n",
    "    secrets = load_secrets()\n",
    "except ValueError:\n",
    "    secrets = {}\n",
    "\n",
    "# Load configuration and secrets\n",
    "config = load_config(CONFIG_PATH)\n",
    "\n",
    "print(\"✅ Configuration loaded successfully\")\n",
    "print(\"✅ Secrets loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c1df6-e894-4423-bfa4-0a9c2ccbd471",
   "metadata": {},
   "source": [
    "# Model Service Registration to MLFlow\n",
    "\n",
    "In this section, we implement the **Model Service**, a REST API responsible for serving the language model. The API is automatically documented using Swagger (via FastAPI), enabling interactive testing and clear documentation of the endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf09222f-67ed-465a-90b4-585925d6d0f8",
   "metadata": {},
   "source": [
    "## Text Generation Service\n",
    "\n",
    "This section demonstrates how to use our TextGenerationService from the src/service directory. This approach improves code organization by separating the service implementation from the notebook, making it easier to maintain and update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b67f548-6765-4d42-8730-fab796acd64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 12:50:27,494 | INFO | Secrets artifact written to temporary file /tmp/tmphhrqz9vq.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c34fcc3f90e460990f647de0dbf7581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1b9b2654b64c1fab3326a8c5012c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42216f52e68e4d01b3ef6422b96a5ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613f2f468c0748ddadb9e37b26f5ea7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered successfully with run ID: acc64804ca1c4482a2b88bdf23b4bc4a\n",
      "CPU times: user 1.32 s, sys: 16.6 s, total: 17.9 s\n",
      "Wall time: 18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Script-Generation-Service' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'Script-Generation-Service'.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlflow.set_tracking_uri('/phoenix/mlflow')\n",
    "# Set up the MLflow experiment\n",
    "mlflow.set_experiment(\"Text-Generation-service\")\n",
    "\n",
    "# Check if the model file exists\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"Warning: Model file not found at {MODEL_PATH}. You may need to update the path.\")\n",
    "\n",
    "#Only logs the model path in the case where it is local\n",
    "if config[\"model_source\"] == \"local\":\n",
    "    model_path = MODEL_PATH\n",
    "else:\n",
    "    model_path = None\n",
    "\n",
    "\n",
    "# Use the TextGenerationService's log_model method to register the model in MLflow\n",
    "with mlflow.start_run(run_name=\"Script-Generation\") as run:\n",
    "    # Log and register the model using the service's classmethod\n",
    "    TextGenerationService.log_model(\n",
    "        llm_artifact = MODEL_PATH,\n",
    "        config_path = CONFIG_PATH,\n",
    "        secrets_dict = secrets if secrets else None,\n",
    "        demo_folder = DEMO_FOLDER\n",
    "    )\n",
    "    \n",
    "    # Register the model in MLflow Model Registry\n",
    "    model_uri = f\"runs:/{run.info.run_id}/script_generation_model\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=\"Script-Generation-Service\")\n",
    "    print(f\"Model registered successfully with run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "354a7c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 12:50:45 - INFO - ⏱️ Total execution time: 0m 29.25s\n",
      "2025-08-19 12:50:45 - INFO - ✅ Notebook execution completed successfully.\n"
     ]
    }
   ],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"⏱️ Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"✅ Notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46e5db7-5e01-4186-a958-1b5585b71a7a",
   "metadata": {},
   "source": [
    "Built with ❤️ using [**HP AI Studio**](https://hp.com/ai-studio)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
