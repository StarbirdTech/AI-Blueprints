{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fdb4bbf",
   "metadata": {},
   "source": [
    "# English Correction with Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149608e8",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115eb488",
   "metadata": {},
   "source": [
    "## Step 0: Configuring the Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6591e9f3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "%pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97410cf1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "os.environ['LLAMA_CPP_LOG_LEVEL'] = '0'\n",
    "import sys\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "# Add src directory to system path\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# Internal Modules\n",
    "from github_extractor import GitHubMarkdownProcessor\n",
    "from utils import load_config_and_secrets\n",
    "from utils import (\n",
    "    load_config_and_secrets,\n",
    "    initialize_llm,\n",
    ")\n",
    "from parser import parse_md_for_grammar_correction, restore_placeholders\n",
    "from chunker import chunk_markdown\n",
    "from core.prompt_templates import get_markdown_correction_prompt\n",
    "from core.markdown_correction_service import MarkdownCorrectionService\n",
    "\n",
    "# Other modules\n",
    "import mlflow\n",
    "from mlflow.models import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d56403",
   "metadata": {},
   "source": [
    "### Define Constants and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21ae9c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"../configs/configs.yaml\"\n",
    "SECRETS_PATH = \"../configs/secrets.yaml\"\n",
    "LOCAL_MODEL_PATH = \"/home/jovyan/datafabric/llama3.1-8b-instruct/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\" #\"/home/jovyan/datafabric/llama2-7b/ggml-model-f16-Q5_K_M.gguf\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de48c5",
   "metadata": {},
   "source": [
    "### Configuration and Secrets Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca78569",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "config, secrets = load_config_and_secrets(CONFIG_PATH, SECRETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d617b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create Logger\n",
    "logger = logging.getLogger(\"english-correction-notebook\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", \n",
    "                             datefmt=\"%Y-%m-%d %H:%M:%S\") \n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9594ff16",
   "metadata": {},
   "source": [
    "## Step 1: Extracting and Parsing Markdown Files From GitHub Repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1634fe",
   "metadata": {},
   "source": [
    "### Extract Markdown Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012bfaf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Repo URL and token\n",
    "repo_url = \"https://github.com/hp-david/test\"\n",
    "access_token = secrets.get(\"GITHUB_ACCESS_TOKEN\")\n",
    "\n",
    "# Create processor instance\n",
    "processor = GitHubMarkdownProcessor(repo_url=repo_url, access_token=access_token)\n",
    "\n",
    "# Run preprocessing workflow\n",
    "markdowns = processor.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc969753",
   "metadata": {},
   "source": [
    "### Parse Markdown Files with Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6c5a8c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "parsed_markdowns = {}\n",
    "placeholder_maps = {}\n",
    "\n",
    "for filename, content in markdowns.items():\n",
    "    # Parse the content and get placeholder map\n",
    "    placeholder_map, processed_content = parse_md_for_grammar_correction(content)\n",
    "    \n",
    "    # Store the processed content (maintains dictionary structure for chunker)\n",
    "    parsed_markdowns[filename] = processed_content\n",
    "    \n",
    "    # Store the placeholder map for later restoration\n",
    "    placeholder_maps[filename] = placeholder_map\n",
    "\n",
    "logger.info(f\"Parsed {len(parsed_markdowns)} files successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342a312",
   "metadata": {},
   "source": [
    "### Chunk Markdown Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c7a75",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "all_chunks = {}  \n",
    "\n",
    "for file_name, content in parsed_markdowns.items():\n",
    "    chunks = chunk_markdown(content, max_tokens=100)\n",
    "    all_chunks[file_name] = chunks\n",
    "\n",
    "# Print chunks during testing\n",
    "\n",
    "for file_name, chunks in all_chunks.items():\n",
    "    logger.info(f\"\\n===== {file_name} =====\\n\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        logger.info(f\"\\n--- Chunk {i+1} ---\\n\")\n",
    "        logger.info(chunk)\n",
    "        logger.info(\"\\n\" + \"-\" * 40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cfa1f8",
   "metadata": {},
   "source": [
    "## Step 2: Correct Markdown Files with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5b195",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get markdown correction prompt from prompt_templates module\n",
    "correction_prompt = get_markdown_correction_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65823c9d",
   "metadata": {},
   "source": [
    "### Initialize Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6470bbf6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#from core.prompt_templates import get_response_from_llm, MARKDOWN_CORRECTION_SYSTEM_PROMPT, MARKDOWN_CORRECTION_USER_PROMPT\n",
    "\n",
    "if \"model_source\" in config:\n",
    "    model_source = config[\"model_source\"]\n",
    "\n",
    "# Initialize llm \n",
    "llm = initialize_llm(model_source, secrets, LOCAL_MODEL_PATH)\n",
    "\n",
    "# Create the LLM chain with the correction prompt\n",
    "llm_chain = correction_prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b3fb3",
   "metadata": {},
   "source": [
    "### Invoke Model on Each Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6cc26",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "count = 0\n",
    "\n",
    "for file_name, chunks in all_chunks.items():  \n",
    "    for chunk in chunks:\n",
    "        response = llm_chain.invoke({\"markdown\": chunk})\n",
    "        results.append({\n",
    "            \"file\": file_name,\n",
    "            \"original\": chunk,\n",
    "            \"corrected\": response\n",
    "        })\n",
    "        print(f\"chunk {count} done\")\n",
    "        count += 1\n",
    "'''\n",
    "results = []\n",
    "count = 0\n",
    "\n",
    "for file_name, chunks in all_chunks.items():\n",
    "    for chunk in chunks:\n",
    "        # Use the general function directly with formatted user prompt\n",
    "        user_prompt = MARKDOWN_CORRECTION_USER_PROMPT.format(markdown_text=chunk)\n",
    "        response = get_response_from_llm(llm, MARKDOWN_CORRECTION_SYSTEM_PROMPT, user_prompt)\n",
    "        \n",
    "        results.append({\n",
    "            \"file\": file_name,\n",
    "            \"original\": chunk,\n",
    "            \"corrected\": response.content\n",
    "        })\n",
    "        \n",
    "        print(f\"chunk {count} done\")\n",
    "        count += 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4223c3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Print results during testing\n",
    "for result in results:\n",
    "    original_text = result[\"original\"]\n",
    "    corrected_text = result[\"corrected\"]\n",
    "    \n",
    "    original_tokens = len(llm.client.tokenize(original_text.encode(\"utf-8\")))\n",
    "    corrected_tokens = len(llm.client.tokenize(corrected_text.encode(\"utf-8\")))\n",
    "\n",
    "    print(f\"\\n===== {result['file']} =====\\n\")\n",
    "    print(f\"--- Original ({original_tokens} tokens) ---\\n\")\n",
    "    print(original_text)\n",
    "    print(f\"\\n--- Corrected ({corrected_tokens} tokens) ---\\n\")\n",
    "    print(corrected_text)\n",
    "    print(\"\\n\" + \"=\" * 60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f2da8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Helper: Safe chunk joiner\n",
    "def safe_join_chunks(chunks):\n",
    "    joined = \"\"\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if i == 0:\n",
    "            joined += chunk\n",
    "        else:\n",
    "            prev = chunks[i - 1].rstrip()\n",
    "            curr = chunk\n",
    "\n",
    "            # Heuristic: Add space only between sentences if needed\n",
    "            if prev.endswith('.') and re.match(r'^[A-Z\\\"]', curr.lstrip()):\n",
    "                joined += ' ' + curr.lstrip()\n",
    "            else:\n",
    "                joined += curr  # Don't strip indentation!\n",
    "    return joined\n",
    "\n",
    "\n",
    "# Group corrected chunks by file\n",
    "corrected_chunks_by_file = defaultdict(list)\n",
    "\n",
    "for result in results:\n",
    "    corrected_chunks_by_file[result[\"file\"]].append(result[\"corrected\"])\n",
    "\n",
    "# Rebuild each file from its corrected chunks with smart joining\n",
    "rebuilt_corrected_files = {\n",
    "    file_name: safe_join_chunks(chunks)\n",
    "    for file_name, chunks in corrected_chunks_by_file.items()\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"corrected\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Restore placeholders and write final output\n",
    "for file_name, corrected_content in rebuilt_corrected_files.items():\n",
    "    placeholder_map = placeholder_maps.get(file_name, {})\n",
    "    restored_content = restore_placeholders(corrected_content, placeholder_map)\n",
    "\n",
    "    # Create subdirectories as needed under 'corrected/'\n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(restored_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d272f2d0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "diff_output_dir = \"corrected_diffs\"\n",
    "os.makedirs(diff_output_dir, exist_ok=True)\n",
    "\n",
    "for file_name, corrected_content in rebuilt_corrected_files.items():\n",
    "    placeholder_map = placeholder_maps.get(file_name, {})\n",
    "    restored_content = restore_placeholders(corrected_content, placeholder_map)\n",
    "\n",
    "    # Get original content from markdowns dict\n",
    "    original_content = markdowns.get(file_name)\n",
    "    if original_content is None:\n",
    "        print(f\"Warning: No original content for file {file_name}\")\n",
    "        continue\n",
    "\n",
    "    # Create unified diff view (HTML side-by-side)\n",
    "    differ = difflib.HtmlDiff(tabsize=4, wrapcolumn=80)\n",
    "    diff_html = differ.make_file(\n",
    "        original_content.splitlines(),\n",
    "        restored_content.splitlines(),\n",
    "        fromdesc=f\"Original: {file_name}\",\n",
    "        todesc=f\"Corrected: {file_name}\",\n",
    "        context=True,\n",
    "        numlines=3\n",
    "    )\n",
    "\n",
    "    # Write diff HTML file\n",
    "    diff_path = os.path.join(diff_output_dir, file_name + \".html\")\n",
    "    os.makedirs(os.path.dirname(diff_path), exist_ok=True)\n",
    "    with open(diff_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(diff_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932307d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e81dfb",
   "metadata": {},
   "source": [
    "## ML Flow Logging and Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b12acae",
   "metadata": {},
   "source": [
    "### Register the Model with ML Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343330f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "mlflow.set_experiment(\"markdown-correction-experiment\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"markdown-correction-run\") as run:\n",
    "    MarkdownCorrectionService.log_model(\n",
    "        llm_artifact=LOCAL_MODEL_PATH,\n",
    "        config_yaml=CONFIG_PATH,\n",
    "        secrets_yaml=SECRETS_PATH,\n",
    "    )\n",
    "\n",
    "    model_uri = f\"runs:/{run.info.run_id}/markdown_corrector\"\n",
    "    mlflow.register_model(model_uri, \"MarkdownCorrector\")\n",
    "\n",
    "    logger.info(f\"Model registered: MarkdownCorrector\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015cc5a9",
   "metadata": {},
   "source": [
    "### ML Flow LLM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21d336",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "from mlflow.metrics import (\n",
    "    ari_grade_level,\n",
    "    flesch_kincaid_grade_level,\n",
    "    exact_match,\n",
    "    rouge1,\n",
    "    rougeL\n",
    ")\n",
    "from core.llm_metrics import (\n",
    "    semantic_similarity_metric,\n",
    "    grammar_error_count_metric,\n",
    "    grammar_error_rate_metric,\n",
    "    grammar_improvement_metric,\n",
    "    grammar_score_metric,\n",
    "    readability_improvement_metric,\n",
    "    llm_judge_metric,\n",
    "    llm_judge_metric_local,\n",
    "    generate_gpt_gold_standards\n",
    ")\n",
    "\n",
    "# Generate GPT gold standards\n",
    "print(\"Generating GPT gold standards...\")\n",
    "original_texts = [item[\"original\"] for item in results]\n",
    "\n",
    "# Pass API key to the function\n",
    "api_key = secrets.get(\"OPEN_AI_API_KEY\") if secrets else None\n",
    "gpt_gold_standards = generate_gpt_gold_standards(original_texts, api_key)\n",
    "\n",
    "# Create evaluation DataFrame\n",
    "eval_df = pd.DataFrame([\n",
    "    {\n",
    "        \"markdown\": original,\n",
    "        \"gpt_corrected\": gpt_gold  # GPT's correction as gold standard\n",
    "    }\n",
    "    for original, gpt_gold in zip(original_texts, gpt_gold_standards)\n",
    "])\n",
    "\n",
    "# Run evaluation\n",
    "results = mlflow.evaluate(\n",
    "    model=model_uri,\n",
    "    data=eval_df,\n",
    "    targets=\"gpt_corrected\",\n",
    "    feature_names=[\"markdown\"],\n",
    "    extra_metrics=[\n",
    "        ari_grade_level(),\n",
    "        flesch_kincaid_grade_level(),\n",
    "        exact_match(),\n",
    "        rouge1(),\n",
    "        rougeL(),\n",
    "        semantic_similarity_metric,\n",
    "        grammar_error_count_metric,\n",
    "        grammar_error_rate_metric,\n",
    "        grammar_improvement_metric,\n",
    "        grammar_score_metric,\n",
    "        readability_improvement_metric,\n",
    "        llm_judge_metric,\n",
    "        llm_judge_metric_local\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger.info(\"Evaluation results:\")\n",
    "logger.info(results.metrics)\n",
    "mlflow.log_metrics(results.metrics)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
