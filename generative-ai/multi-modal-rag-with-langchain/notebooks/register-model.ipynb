{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff193981-f701-4595-9d5f-a08779c65508",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-size: 50px;\"> ü§ñ MLFlow Registration for Multimodal RAG</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2607392-6bd0-4950-8ac8-84026da9df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt --quiet "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e7b230-e638-458a-8104-0a30727b2466",
   "metadata": {},
   "source": [
    "# MLFlow Model Service \n",
    "\n",
    "In this section, we demonstrate how to deploy a RAG-based chatbot service. This service provides a REST API endpoint that allows users to query the knowledge base with natural language questions, upload new documents to the knowledge base, and manage conversation history, all with built-in safeguards against sensitive information and toxicity. This service encapsulates all the functionality we developed in this notebook, including the document retrieval system, RAG-based question answering capabilities, and Galileo integration for protection, observation and evaluation. It demonstrates how to use our ChatbotService from the src/service directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13315d2-4b6d-4ffe-a59b-7f7c79873f60",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd304d2-4129-45d5-8c4e-796c4daa809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_evaluate_setup(\n",
    "    secrets,\n",
    "    mlflow_tracking_uri=\"/phoenix/mlflow\"\n",
    ")\n",
    "\n",
    "# === Set MLflow experiment context ===\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "# === Validate local model file path ===\n",
    "if not os.path.exists(LOCAL_MODEL_PATH):\n",
    "    logger.info(f\"‚ö†Ô∏è Warning: Model file not found at {LOCAL_MODEL_PATH}. Please verify the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7644c096-6092-4242-8645-625aa9e5180b",
   "metadata": {},
   "source": [
    "## Log and Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c3b77-997a-4872-be17-c922ae80f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Log and register model to MLflow ===\n",
    "with mlflow.start_run(run_name=MLFLOW_RUN_NAME) as run:\n",
    "    \n",
    "    # Log model artifacts using custom ChatbotService\n",
    "    ChatbotService.log_model(\n",
    "        artifact_path=MLFLOW_MODEL_NAME,\n",
    "        config_path=CONFIG_PATH,\n",
    "        secrets_path=SECRETS_PATH,\n",
    "        docs_path=DATA_PATH,\n",
    "        model_path=LOCAL_MODEL_PATH,\n",
    "        demo_folder=DEMO_FOLDER\n",
    "    )\n",
    "\n",
    "    # Construct the URI for the logged model\n",
    "    model_uri = f\"runs:/{run.info.run_id}/{MLFLOW_MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0156a-bc2f-4ba8-81d2-104f24b097de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model into MLflow Model Registry\n",
    "mlflow.register_model(\n",
    "    model_uri=model_uri,\n",
    "    name=MLFLOW_MODEL_NAME\n",
    ")\n",
    "\n",
    "logger.info(f\"‚úÖ Model registered successfully with run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83806df-79a8-4273-ab62-96c4bf1c2ded",
   "metadata": {},
   "source": [
    "# Evaluate Hallucinations & Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afd929-1a1c-40df-ad6f-2140059ebe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_source = config[\"model_source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65785be-a49d-447d-855d-7a359ead6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "llm = initialize_llm(model_source, secrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a04d0f-2827-4f3d-9b2e-88f09f5aeeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model(batch_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    preds, contexts = [], []\n",
    "    for q in batch_df[\"questions\"]:\n",
    "        answer = mm_chain.invoke(q)\n",
    "        preds.append(answer)\n",
    "\n",
    "        docs = retriever.get_relevant_documents(q)\n",
    "        contexts.append(\" \".join(d.page_content for d in docs))\n",
    "\n",
    "    # keep the incoming index so every batch‚Äôs rows stay unique\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"result\": preds,\n",
    "            \"source_documents\": contexts,\n",
    "        },\n",
    "        index=batch_df.index,      #  ‚Üê key line\n",
    "    )\n",
    "\n",
    "# --- 3)  Evaluation dataset\n",
    "eval_df = pd.DataFrame({\"questions\": [\n",
    "    \"What naming convention should I use for a new blueprint project folder?\",\n",
    "    \"What is the first step in the standard blueprint testing workflow?\",\n",
    "    \"How do I fetch logs from a running Kubernetes pod?\",\n",
    "]})\n",
    "\n",
    "judge = LocalGenAIJudge(\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "faithfulness_metric = judge.to_mlflow_metric(\"faithfulness\")\n",
    "relevance_metric = judge.to_mlflow_metric(\"relevance\")\n",
    "\n",
    "results = mlflow.evaluate(\n",
    "    model,\n",
    "    eval_df,\n",
    "    predictions=\"result\",\n",
    "    evaluators=\"default\",\n",
    "    extra_metrics=[faithfulness_metric, relevance_metric],\n",
    "    evaluator_config={\n",
    "        \"col_mapping\": {\n",
    "            \"inputs\": \"questions\",\n",
    "            \"context\": \"source_documents\"\n",
    "        }\n",
    "    },\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
