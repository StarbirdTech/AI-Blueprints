# English Correction with LangChain

<div align="center">

![Python](https://img.shields.io/badge/Python-3.13+-blue.svg?logo=python)
![Jupyter](https://img.shields.io/badge/Jupyter-supported-orange.svg?logo=jupyter)
![LangChain](https://img.shields.io/badge/LangChain-used-4b8bbe.svg?logo=langchain)
![MLflow](https://img.shields.io/badge/MLflow-used-015cab.svg?logo=mlflow)
![Streamlit](https://img.shields.io/badge/User%20Interface-Streamlit-ff4b4b.svg?logo=streamlit)

</div>

## üìö Contents

- [üß† Overview](#overview)
- [üóÇ Project Structure](#project-structure)
- [‚öôÔ∏è Setup](#setup)
- [üöÄ Usage](#usage)
- [üìû Contact and Support](#contact-and-support)

---

# Overview

This project demonstrates how to perform English grammar correction in GitHub Markdown fules using a local LLaMA language model and LangChain. The system uses placeholder substitution and reconstruction techniques to ensure Markdown structure is preserved during correction, making it ideal for grammar refinement in documentation and technical repositories. 

---

# Project Structure

```
‚îú‚îÄ‚îÄ configs
‚îÇ   ‚îî‚îÄ‚îÄ configs.yaml                                                  # General settings
‚îú‚îÄ‚îÄ demo
‚îÇ   ‚îî‚îÄ‚îÄ streamlit-webapp
‚îÇ      ‚îî‚îÄ‚îÄ README.md                                                  # Streamlit Documentation
‚îÇ      ‚îî‚îÄ‚îÄ main.py                                                    # Streamlit UI
‚îú‚îÄ‚îÄ docs
‚îÇ   ‚îî‚îÄ‚îÄ eval_metrics.pdf                                              # Evaluation metrics explanations
‚îú‚îÄ‚îÄ notebooks
‚îÇ   ‚îî‚îÄ‚îÄ run-workflow.ipynb                                            # Main notebook for the project
‚îÇ   ‚îî‚îÄ‚îÄ register-model.ipynb                                          # MLflow registration and evaluation notebook 
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py                                                   # Marks directory as a package
‚îÇ   ‚îî‚îÄ‚îÄ chunker.py                                                    # Markdown chunker 
‚îÇ   ‚îî‚îÄ‚îÄ github_extractor.py                                           # GitHub markdown file extractor
‚îÇ   ‚îî‚îÄ‚îÄ llm_metrics.py                                                # Custom MLflow evaluation metrics
‚îÇ   ‚îî‚îÄ‚îÄ markdown_correction_service.py                                # Custom MLflow model class
‚îÇ   ‚îî‚îÄ‚îÄ parser.py                                                     # Markdown parser to insert placeholders
‚îÇ   ‚îî‚îÄ‚îÄ prompt_templates.py                                           # Model prompts
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                                                      # Reusable helper functions
‚îú‚îÄ‚îÄ README.md                                                         # Project documentation
‚îú‚îÄ‚îÄ requirements.txt                                                  # Required dependancies

```

# Setup

### Step 0 ‚ñ™ Minimum Hardware Requirements

Ensure your environment meets the minimum compute requirements for smooth image classification performance:

- **RAM**: 32 GB  
- **VRAM**: 12 GB  
- **GPU**: NVIDIA GPU

### Step 1 ‚ñ™ Create an AI Studio Project

1.  Create a **New Project** in [Z by HP AI Studio](https://zdocs.datascience.hp.com/docs/aistudio/overview).
2. (Optional) Add a description and relevant tags.

### Step 2 ‚ñ™ Set Up a Workspace

1. Choose **Local Gen AI** as the base image.
2. Upload the requirements.txt fule and install dependancies.

### Step 3: Verify Project Files

1. Clone the GitHub repository:  
   ```
   git clone https://github.com/HPInc/AI-Blueprints.git
   ```  
2. Make sure the folder `generative-ai/english-correction-with-langchain` is present inside your workspace.

#### Step 4: Use a Custom Kernel for Notebooks
1. In Jupyter notebooks, select the **aistudio kernel** to ensure compatibility.

---

# Usage

### Step 1 ‚ñ™ Run the Main Notebook

Execute the notebook inside the `notebooks` folder:

```bash
notebooks/run-workflow.ipynb
```

This will:

- Extract GitHub markdown files from the given repository.
- Parse the markdown files with placeholders.
- Chunk the placeheld markdown files.
- Initialize a LLaMa model and pass all markdown chunks through it.
- Output results into a directory.
  
### Step 2 ‚ñ™ Run the Registration and Evaluation Notebook

```bash
notebooks/register-model.ipynb
```

This will:

- Emulate processing workflow from run-workflow.ipynb
- Register the model with MLflow.
- Run custom evaluation metrics on the model. 

### Step 3 ‚ñ™ Deploy the Model

1. Go to **Deployments > New Service** in AI Studio.
2. Name the service and select the registered model.
3. Choose a model version and select **With GPU** for **GPU Configuration**.
4. Choose the workspace.
5. Start the deployment.
6. Once deployed, open the Service URL to access the Swagger API page.


### Step 4 ‚ñ™ Launch the Streamlit UI

1. Follow the instructions in the README file located in the `demo\streamlit-webapp` folder.
2. Navigate to the shown URL, upload markdown files or enter a GitHub repo URL, preview the corrected files, and download the corrected markdown files. 

---

# Contact and Support  

- Issues: Open a new issue in our [**AI-Blueprints GitHub repo**](https://github.com/HPInc/AI-Blueprints).

- Docs: Refer to the **[AI Studio Documentation](https://zdocs.datascience.hp.com/docs/aistudio/overview)** for detailed guidance and troubleshooting. 

- Community: Join the [**HP AI Creator Community**](https://community.datascience.hp.com/) for questions and help.

---

> Built with ‚ù§Ô∏è using [**HP AI Studio**](https://www.hp.com/us-en/workstations/ai-studio.html).

