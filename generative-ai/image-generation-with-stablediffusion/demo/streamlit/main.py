import streamlit as st
import os
import base64
import requests
from io import BytesIO
from PIL import Image
from pathlib import Path

# Environment configuration
os.environ.setdefault("NO_PROXY", "localhost,127.0.0.1")

# --- Page Configuration ---
st.set_page_config(
    page_title="Image Generation with StableDifussion",
    page_icon="ğŸ“·",
    layout="centered"
)

# --- Custom Style ---
st.markdown("""
Â Â Â  <style>
Â Â Â Â Â Â Â  .block-container {
Â Â Â Â Â Â Â Â Â Â Â  padding-top: 0 !important;
Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â  body {
Â Â Â Â Â Â Â Â Â Â Â  font-family: 'Arial', sans-serif;
Â Â Â Â Â Â Â Â Â Â Â  background-color: #f4f4f4;
Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â  .stButton>button {
Â Â Â Â Â Â Â Â Â Â Â  background-color: #4CAF50 !important;
Â Â Â Â Â Â Â Â Â Â Â  color: white !important;
Â Â Â Â Â Â Â Â Â Â Â  font-size: 18px !important;
Â Â Â Â Â Â Â Â Â Â Â  border-radius: 8px !important;
Â Â Â Â Â Â Â Â Â Â Â  padding: 10px 24px !important;
Â Â Â Â Â Â Â Â Â Â Â  border: none !important;
Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â  .stTextInput>div>div>input {
Â Â Â Â Â Â Â Â Â Â Â  font-size: 16px !important;
Â Â Â Â Â Â Â Â Â Â Â  padding: 10px !important;
Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â  .stMarkdown {
Â Â Â Â Â Â Â Â Â Â Â  background-color: #ffffff;
Â Â Â Â Â Â Â Â Â Â Â  padding: 15px;
Â Â Â Â Â Â Â Â Â Â Â  border-radius: 10px;
Â Â Â Â Â Â Â Â Â Â Â  box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
Â Â Â Â Â Â Â Â Â Â Â  margin: 10px 0px;
Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â  hr, .stHorizontalRule {
Â Â Â Â Â Â Â Â Â Â Â  border-color: rgba(0,77,204,0.20);
Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â  img[alt="HP Logo"],
Â Â Â Â Â Â Â  img[alt="AI Studio Logo"],
Â Â Â Â Â Â Â  img[alt="Z by HP Logo"] {
Â Â Â  width: 50px !important;
Â Â Â  height: auto !important;
}

Â Â Â  </style>
""", unsafe_allow_html=True)

# --- Logo ---

def uri_from(path: Path) -> str:
    return f"data:image/{path.suffix[1:].lower()};base64," + base64.b64encode(path.read_bytes()).decode()

assets = Path("assets")
hp_uri = uri_from(assets / "HP-Logo.png")
ais_uri = uri_from(assets / "AI-Studio.png")
zhp_uri = uri_from(assets / "Z-HP-logo.png")

st.markdown(f"""
Â Â Â  <div style="display:flex;justify-content:space-between;
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  align-items:center;margin-bottom:1.5rem">
Â Â Â Â Â Â Â  <img src="{hp_uri}"Â  alt="HP Logo" style="width:90px;height:auto;">
Â Â Â Â Â Â Â  <img src="{ais_uri}" alt="AI Studio Logo" style="width:90px;height:auto;">
Â Â Â Â Â Â Â  <img src="{zhp_uri}" alt="Z by HP Logo" style="width:90px;height:auto;">
Â Â Â  </div>
""", unsafe_allow_html=True)

# --- Header ---
st.markdown("<h1 style='text-align: center; color: #2C3E50;'>ğŸ–¼ï¸ Image Generation with StableDifussion </h1>", unsafe_allow_html=True)

# --- MLflow API Configuration ---
# Standardized MLflow endpoint for containerized deployment
MLFLOW_ENDPOINT = "http://localhost:5002/invocations"
api_url = MLFLOW_ENDPOINT

# --- data inputs ---

prompt = st.text_input("Prompt (image description):")
use_finetuning = st.checkbox("Use fine-tuning")
height = st.number_input("Image height (px):", min_value=1, value=512)
width = st.number_input("Image width (px):", min_value=1, value=512)
num_images = st.number_input("Number of images:", min_value=1, max_value=10, value=1)
num_inference_steps = st.number_input("Number of inference steps:", min_value=1, value=50)


# --- Button to Call the Model ---
if st.button("Get result"):
    if not all([prompt, height, width, num_images, num_inference_steps]):
        st.warning("âš ï¸ Please fill all fields!")
    else:
        payload = {
            "inputs": {
                "prompt": [prompt],
                "use_finetuning":[use_finetuning],
                "height":[height],
                "width":[width],
                "num_images": [num_images],
                "num_inference_steps": [num_inference_steps]   
                       },
        }

        with st.spinner("Generating image..."):
            try:
                response = requests.post(api_url, json=payload, verify=False)
                response.raise_for_status()
                data = response.json()
                
                predictions = data.get("predictions", [])

                if predictions:
                    for i, pred in enumerate(predictions):
                        base64_image = pred.get("output_images", "")
                        if base64_image and isinstance(base64_image, str):
                            try:

                                image_bytes = base64.b64decode(base64_image)
                                image = Image.open(BytesIO(image_bytes))
                                st.image(image, caption=f"Image {i+1}", use_container_width=True)

                                # Download button for each image
                                buffer = BytesIO()
                                image.save(buffer, format="PNG")
                                buffer.seek(0)

                                st.download_button(
                                    label=f"ğŸ“¥ Download Image {i+1}",
                                    data=buffer,
                                    file_name=f"image_{i+1}.png",
                                    mime="image/png"
                                )
                            except Exception as e:
                                st.error(f"âŒ Error displaying image {i+1}: {str(e)}")
                        else:
                            st.warning(f"âš ï¸ No image data found for prediction {i+1}.")
                else:
                    st.error("âŒ No predictions returned from the model.")

            except requests.exceptions.RequestException as e:
                st.error("âŒ Error fetching prediction.")
                st.error(str(e))

# --- Footer ---
st.markdown(
    """
    > Built with â¤ï¸ using HP AI Studio.
    """,
    unsafe_allow_html=True,
)