{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a9cfb23-42af-4fed-a375-54d310c8e285",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-size: 50px;\">DreamBooth on Stable Diffusion 2.1</h1>\n",
    "\n",
    "DreamBooth is a powerful technique for personalizing latent diffusion models, such as Stable Diffusion, allowing the model to be fine-tuned to generate specific images based on a limited set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd00e9d",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "- Imports\n",
    "- Configurations\n",
    "- Verify Assets\n",
    "- Download model local\n",
    "- Load the Model\n",
    "- DreamBooth Training\n",
    "- Inference Local Model\n",
    "- Galileo Evaluate Custom metrics\n",
    "- Model Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab16e0-eec7-4cc8-aee9-305cc190e597",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "This command installs the \"diffusers\" library directly from the Hugging Face GitHub repository.The diffusers library is used to work with latent diffusion models, such as Stable Diffusion, and provides tools for image generation, fine-tuning, and other functionalities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64567c2e-085f-4db3-bd89-f7ab3090ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1914541-0648-454e-9ed5-0f51eee56427",
   "metadata": {},
   "source": [
    "### Configuration and Secrets Loading\n",
    "In this section, we load configuration parameters and API keys from separate YAML files. This separation helps maintain security by keeping sensitive information (API keys) separate from configuration settings.\n",
    "\n",
    "- **config.yaml**: Contains non-sensitive configuration parameters like model sources and URLs\n",
    "- **secrets.yaml**: Contains sensitive API keys for services like Galileo and HuggingFace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab66135",
   "metadata": {},
   "source": [
    "> ⚠️ **Warning**: If your GPU uses an older architecture (e.g., **pre-Pascal**, such as **Maxwell or earlier**), please uncomment the following line to avoid CUDA timeout issues:\n",
    "```python\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6c798-cdf9-461b-a3a0-cb766773fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from src.utils import (\n",
    "    load_config_and_secrets,\n",
    "    configure_proxy,\n",
    "    setup_galileo_environment,\n",
    "    get_project_root,\n",
    "    get_config_dir,\n",
    "    get_output_dir,\n",
    "    get_default_model_path,\n",
    "    get_model_cache_dir\n",
    ")\n",
    "\n",
    "\n",
    "# Add the core directory to the path to import utils\n",
    "core_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if core_path not in sys.path:\n",
    "    sys.path.append(core_path)\n",
    "\n",
    "from core.custom_metrics.image_metrics_scorers import entropy_scorer, complexity_scorer, set_custom_image_path\n",
    "from core.deploy.deploy_image_generation import deploy_model\n",
    "from core.local_inference.inference import StableDiffusionPipelineOutput, load_config, run_inference\n",
    "from core.dreambooth_inference.inference_dreambooth import StableDiffusionPipelineOutput, load_config_dreambooth, run_inference_dreambooth\n",
    "\n",
    "\n",
    "# === Third-Party Imports ===\n",
    "from huggingface_hub import snapshot_download\n",
    "import promptquality as pq\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "\n",
    "# === Standard Library Imports ===\n",
    "import logging\n",
    "import warnings\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f3a72",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc9419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa2b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create logger ===\n",
    "logger = logging.getLogger(\"image-generation-notebook\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter(\n",
    "    \"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Constants ===\n",
    "# Model and experiment configuration\n",
    "project_root = get_project_root()\n",
    "CONFIG_PATH = str(project_root / \"configs\" / \"config.yaml\")\n",
    "SECRETS_PATH = str(project_root / \"configs\" / \"secrets.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df84716",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Notebook execution started.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f389894e",
   "metadata": {},
   "source": [
    "### Configuration and Secrets Loading\n",
    "In this section, we load configuration parameters and API keys from separate YAML files. This separation helps maintain security by keeping sensitive information (API keys) separate from configuration settings.\n",
    "\n",
    "- **config.yaml**: Contains non-sensitive configuration parameters like model sources and URLs\n",
    "- **secrets.yaml**: Contains sensitive API keys for services like Galileo and HuggingFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a2bb3-7843-4ca1-95d0-d252fbee51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, secrets = load_config_and_secrets(CONFIG_PATH, SECRETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc604e8-5487-4518-9d91-8542074be0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_proxy(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b5b9dc",
   "metadata": {},
   "source": [
    "## Verify Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ef9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_asset_status(asset_path: str, asset_name: str, success_message: str, failure_message: str) -> None:\n",
    "    \"\"\"\n",
    "    Logs the status of a given asset based on its existence.\n",
    "\n",
    "    Parameters:\n",
    "        asset_path (str): File or directory path to check.\n",
    "        asset_name (str): Name of the asset for logging context.\n",
    "        success_message (str): Message to log if asset exists.\n",
    "        failure_message (str): Message to log if asset does not exist.\n",
    "    \"\"\"\n",
    "    if Path(asset_path).exists():\n",
    "        logger.info(f\"{asset_name} is properly configured. {success_message}\")\n",
    "    else:\n",
    "        logger.info(f\"{asset_name} is not properly configured. {failure_message}\")\n",
    "\n",
    "\n",
    "log_asset_status(\n",
    "    asset_path=CONFIG_PATH,\n",
    "    asset_name=\"Config\",\n",
    "    success_message=\"\",\n",
    "    failure_message=\"Please check if the configs.yaml was propely connfigured in your project on AI Studio.\"\n",
    ")\n",
    "\n",
    "log_asset_status(\n",
    "    asset_path=SECRETS_PATH,\n",
    "    asset_name=\"Secrets\",\n",
    "    success_message=\"\",\n",
    "    failure_message=\"Please check if the secrets.yaml was propely connfigured in your project on AI Studio.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea33851-2215-4fab-b02d-b78aab3f3c08",
   "metadata": {},
   "source": [
    "## Download model local\n",
    "\n",
    "This code imports the snapshot_download function from the huggingface_hub library to download the latest version of the \"stabilityai/stable-diffusion-2-1\" model. It sets a local directory for saving the model (local_model_path), and the download is configured to be resumable in case it is interrupted, with an etag timeout set to 60 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1ae0b-fcb1-46f6-9275-30746011c7ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download the snapshot directly to the project's models directory\n",
    "local_model_path = str(get_project_root() / \"models\" / \"stable-diffusion-2-1\")\n",
    "\n",
    "# Downloading the latest revision of the \"stabilityai/stable-diffusion-2-1\" model\n",
    "snapshot_download(\n",
    "    repo_id=\"stabilityai/stable-diffusion-2-1\", \n",
    "    local_dir=local_model_path,\n",
    "    resume_download=True,\n",
    "    etag_timeout=60  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841fcc24-ed5d-46d3-b9ce-3f48451a5e01",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "We load the pre-trained Stable Diffusion 2.1 model from Hugging Face and move it to the GPU for efficient execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4d448-a095-4db9-84e8-207c00b52cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "\n",
    "run_inference(\n",
    "    prompt=\"A beautiful landscape\",\n",
    "    height=768,\n",
    "    width=768,\n",
    "    num_images=1,\n",
    "    num_inference_steps=60,\n",
    "    output=True  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b07ea-7694-4c3d-8959-82533d6021ed",
   "metadata": {},
   "source": [
    "## DreamBooth Training\n",
    "\n",
    "This Bash script uses PyTorch to detect the number of available GPUs, automatically selects either the multi-GPU or single-GPU configuration file, and then launches the DreamBooth training process on Stable Diffusion via `accelerate launch` with your specified parameters. It also captures the start and end timestamps to calculate the total training duration.\n",
    "\n",
    "> **Tip:** To enable full, verbose logging, add the `--log_level=DEBUG` flag to your command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03076937-b726-419b-b59f-5180ccd85bec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s \"${{str(project_root)}}\"\n",
    "# Use the project_root variable from Python converted to string\n",
    "PROJECT_ROOT=\"$1\"\n",
    "\n",
    "CONFIG_DIR=\"$PROJECT_ROOT/config\"\n",
    "OUTPUT_DIR=\"$PROJECT_ROOT/output\"\n",
    "DATA_DIR=\"$PROJECT_ROOT/data\"\n",
    "\n",
    "# Ensure directories exist\n",
    "mkdir -p \"$OUTPUT_DIR\"\n",
    "mkdir -p \"$DATA_DIR\"\n",
    "\n",
    "NUM_GPUS=$(python3 -c \"import torch; print(torch.cuda.device_count())\")\n",
    "\n",
    "if [ \"$NUM_GPUS\" -ge 2 ]; then\n",
    "  CONFIG_FILE=\"$CONFIG_DIR/default_config_multi-gpu.yaml\"\n",
    "  echo \"Detected $NUM_GPUS GPUs, using $CONFIG_FILE\"\n",
    "else\n",
    "  CONFIG_FILE=\"$CONFIG_DIR/default_config_one-gpu.yaml\"\n",
    "  echo \"Detected $NUM_GPUS GPU, using $CONFIG_FILE\"\n",
    "fi\n",
    "\n",
    "# Verify config file exists\n",
    "if [ ! -f \"$CONFIG_FILE\" ]; then\n",
    "  echo \"Error: Config file $CONFIG_FILE not found!\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "START=$(date +%s)\n",
    "\n",
    "accelerate launch --config_file \"$CONFIG_FILE\" ../core/train/train_dreambooth_aistudio.py \\\n",
    "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-2-1\"  \\\n",
    "  --log_level=ERROR \\\n",
    "  --instance_data_dir=\"$DATA_DIR/img\" \\\n",
    "  --output_dir=\"$OUTPUT_DIR/dreambooth/\" \\\n",
    "  --instance_prompt=\"A modern laptop on a sandy beach with the ocean in the background, sunlight reflecting off the screen\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=5e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=400 \\\n",
    "  --logging_dir=\"/phoenix/tensorboard/tensorlogs\" \\\n",
    "  --report_to=\"tensorboard\" \\\n",
    "  --validation_prompt=\"A photo of an HP laptop on the sand with a sunset over the ocean in the background.\" \\\n",
    "  --num_validation_images=1 \\\n",
    "  --validation_steps=100\n",
    "\n",
    "END=$(date +%s)\n",
    "DIFF=$(( $END - $START ))\n",
    "\n",
    "echo \"Training completed in $DIFF seconds\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623c9bbd-dcf8-41f6-9815-4c7a29f9ce9b",
   "metadata": {},
   "source": [
    "## Inference Local Model\n",
    "\n",
    "This code imports functions from the inference_dreambooth module, loads a configuration, and then runs inference to generate images. It uses a prompt to create three images with a resolution of 768x768 pixels, executing 100 inference steps per image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0ab869-830d-45a8-81f9-239856d1cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config_dreambooth()\n",
    "\n",
    "run_inference_dreambooth(\n",
    "    prompt=\"A high-quality photo of an HP laptop placed on the sand at the beach, with a sunset over the ocean in the background.\", \n",
    "    height=768, \n",
    "    width=768, \n",
    "    num_images=3, \n",
    "    num_inference_steps=100,\n",
    "    output=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2051d-f562-4d8b-b5e3-cd292e39241d",
   "metadata": {},
   "source": [
    "## Galileo Evaluate Custom metrics\n",
    "Galileo GenAI Studio supports Custom Metrics (programmatic or GPT-based) for all your Evaluate and Observe projects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340fae2-64e8-44ed-b491-36a744bc7f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# In order to connect to Galileo, create a secrets.yaml file in the configs folder.\n",
    "# This file should be an entry called GALILEO_API_KEY, with your personal Galileo API Key\n",
    "# Galileo API keys can be created on https://console.hp.galileocloud.io/settings/api-keys\n",
    "#########################################\n",
    "\n",
    "setup_galileo_environment(secrets)\n",
    "pq.login(os.environ['GALILEO_CONSOLE_URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6ed1a2-cd33-4b42-ba5d-795199180d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_generated_image(directory: str = None, prefix: str = \"dreambooth_result_\", ext: str = \".png\") -> str:\n",
    "    \"\"\"\n",
    "    Returns the path of the most recent image that matches the specified pattern.\n",
    "    Uses the project's output directory by default.\n",
    "    \"\"\"\n",
    "    if directory is None:\n",
    "        directory = str(get_output_dir())\n",
    "    \n",
    "    files = glob.glob(os.path.join(directory, f\"{prefix}*{ext}\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No generated images found in {directory}.\")\n",
    "    latest_file = max(files, key=os.path.getmtime)\n",
    "    return latest_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb69f4-dd2f-4cb4-b25f-25429169c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config_dreambooth()\n",
    "\n",
    "prompt_text = (\"A high-quality photo of an HP laptop placed on the sand at the beach, \"\n",
    "               \"with a sunset over the ocean in the background.\")\n",
    "\n",
    "run_inference_dreambooth(\n",
    "    prompt=prompt_text, \n",
    "    height=768, \n",
    "    width=768, \n",
    "    num_images=1, \n",
    "    num_inference_steps=100,\n",
    "    output=True\n",
    ")\n",
    "\n",
    "generated_image_path = get_latest_generated_image()\n",
    "\n",
    "set_custom_image_path(generated_image_path)\n",
    "\n",
    "template = prompt_text\n",
    "\n",
    "result_custom = pq.run(template=template, scorers=[entropy_scorer, complexity_scorer])\n",
    "print(\"Result:\", result_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f737c7-b9ff-45c1-a7c2-df5e2ab479a8",
   "metadata": {},
   "source": [
    "## Model Service\n",
    "\n",
    "Using MLflow, we will save and load the model in an integrated manner, enabling the traceability and reproducibility of experiments. MLflow will facilitate model versioning, monitoring, and deployment, ensuring a robust pipeline for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920eec1-6c4a-4141-9956-a0d8f1c688d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deploy_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f30745",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Notebook execution completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3882050d",
   "metadata": {},
   "source": [
    "Built with ❤️ using Z by HP AI Studio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
