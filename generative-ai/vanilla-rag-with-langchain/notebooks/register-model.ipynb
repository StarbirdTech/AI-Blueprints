{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375d7bc0",
   "metadata": {},
   "source": [
    "# Register Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc414b2",
   "metadata": {},
   "source": [
    "## Notebook Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c822baa",
   "metadata": {},
   "source": [
    "- Start Execution\n",
    "- Install and Import Libraries\n",
    "- Configure Settings\n",
    "- Register and Log the Model to MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a68e29",
   "metadata": {},
   "source": [
    "# Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c73243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "# Configure logger\n",
    "logger: logging.Logger = logging.getLogger(\"run_workflow_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent duplicate logs from parent loggers\n",
    "\n",
    "# Set formatter\n",
    "formatter: logging.Formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Configure and attach stream handler\n",
    "stream_handler: logging.StreamHandler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193f6710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 14:16:48 - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  \n",
    "\n",
    "logger.info(\"Notebook execution started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5438cb",
   "metadata": {},
   "source": [
    "# Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc376d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CPU times: user 42.8 ms, sys: 19.7 ms, total: 62.5 ms\n",
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%pip install -r ../requirements.txt --quiet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e5259bf-a938-4ca6-99c0-8eca066f758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:168: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n",
      "/opt/conda/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:168: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import uuid\n",
    "import base64\n",
    "import sys\n",
    "from typing import Dict, Any, List\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import mlflow\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline, HuggingFaceEndpoint\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda, RunnableMap\n",
    "from langchain.schema.document import Document\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# Define the relative path to the 'src' directory (one level up from current working directory)\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from core.chatbot_service.chatbot_service import ChatbotService\n",
    "from src.utils import (\n",
    "    get_context_window, \n",
    "    dynamic_retriever, \n",
    "    format_docs_with_adaptive_context,\n",
    "    login_huggingface,\n",
    "    load_config,\n",
    "    load_secrets,\n",
    "    load_secrets_to_env,\n",
    "    clean_code\n",
    ")\n",
    "from src.prompt_templates import format_rag_chatbot_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99283dd2",
   "metadata": {},
   "source": [
    "# Configure Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7059e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Suppress Verbose Logs ------------------------\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c4b8ef6-4669-4b11-acc6-56ea640fa046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters for the RAG chatbot\n",
    "MODEL_SOURCE = \"local\"  # Can be: \"local\", \"hugging-face-local\", \"hugging-face-cloud\"\n",
    "CHATBOT_SERVICE_NAME = \"VanillaRAGChatbot\"\n",
    "\n",
    "# Configuration paths\n",
    "CONFIG_PATH = \"../configs/config.yaml\"\n",
    "SECRETS_PATH = \"../configs/secrets.yaml\"\n",
    "DATA_PATH = \"../data\"\n",
    "MLFLOW_EXPERIMENT_NAME = \"AIStudio-Chatbot-Experiment\"\n",
    "MLFLOW_RUN_NAME = \"AIStudio-Chatbot-Run\"\n",
    "LOCAL_MODEL_PATH = \"/home/jovyan/datafabric/meta-llama3.1-8b-Q8/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\"\n",
    "DEMO_FOLDER = \"../demo\"\n",
    "MLFLOW_MODEL_NAME = \"AIStudio-Chatbot-Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc5a22a-5c19-4218-a7bf-93b5defeb048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 2 secrets into environment variables.\n",
      "✅ Configuration loaded successfully\n",
      "✅ Secrets loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load secrets from secrets.yaml file (if it exists) into environment\n",
    "if Path(SECRETS_PATH).exists():\n",
    "    load_secrets_to_env(SECRETS_PATH)\n",
    "else:\n",
    "    print(f\"No secrets file found at {SECRETS_PATH}; relying on preexisting environment\")\n",
    "\n",
    "# Retrieve secrets from environment\n",
    "try:\n",
    "    secrets = load_secrets()\n",
    "except ValueError:\n",
    "    secrets = {}\n",
    "\n",
    "# Load configuration and secrets\n",
    "config = load_config(CONFIG_PATH)\n",
    "\n",
    "print(\"✅ Configuration loaded successfully\")\n",
    "print(\"✅ Secrets loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a47787-e57b-42fa-8009-7b0c296ba7d4",
   "metadata": {},
   "source": [
    "# Register and Log the Model to MLFlow \n",
    "\n",
    "In this section, we demonstrate how to deploy a RAG-based chatbot service with integrated Galileo Protect and Observe capabilities. This service provides a REST API endpoint that allows users to query the knowledge base with natural language questions, upload new documents to the knowledge base, and manage conversation history, all with built-in safeguards against sensitive information and toxicity. This service encapsulates all the functionality we developed in this notebook, including the document retrieval system and the RAG-based question answering capabilities. It demonstrates how to use our ChatbotService from the src/service directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a93da99-a714-4ee2-8b22-b3af42c04075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 14:16:58 INFO mlflow.tracking.fluent: Experiment with name 'AIStudio-Chatbot-Experiment' does not exist. Creating a new experiment.\n",
      "2025-08-19 14:16:58 - INFO - Starting the experiment: AIStudio-Chatbot-Experiment\n",
      "2025-08-19 14:16:58 - INFO - Using MLflow tracking URI: /phoenix/mlflow\n",
      "2025-08-19 14:16:58,227 - INFO - Run's Artifact URI: /phoenix/mlflow/300005248811937461/0509c8656e024bdeb0c7074f6b406e1b/artifacts\n",
      "2025-08-19 14:16:58,229 - INFO - Secrets artifact written to temporary file /tmp/tmptd2t1zn3.yaml\n",
      "2025-08-19 14:16:58,312 - INFO - PyTorch version 2.7.1 available.\n",
      "2025-08-19 14:16:58,618 - INFO - Use pytorch device_name: cuda\n",
      "2025-08-19 14:16:58,620 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ed39fecd814c8f84e58b5569b23a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67065b9cf8584d7ea1def73371126293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7644360e22d34ab8bc1c9f7ee93238c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143e0eb953d640a7b117ef7359727559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cecc736cd184fd0abe051e075f301e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "2025-08-19 14:16:59,771 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdf5c2295974414835bfa7017a79675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c5e7844ead47f9a22fb0c87422cfce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7c0cf66e60436c9c8c44449f1c0737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0770f2273dc54166913eb09a0ba69f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd004e294ec4f5d96f0b66bba883fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b37f27088cd4dff8f9f1128d61262a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef64c9ae55744d8ae9596e29caa881b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a8b8058acf4173af2d9d6529eefdc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc976b089ba14a8d9372419bf2a03496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6d2b74df484e00b45a10d4ac0aa631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70846cd6e2e49d785b8a5241fb5ab2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 14:17:26,583 - INFO - Model and artifacts successfully registered in MLflow.\n",
      "Successfully registered model 'AIStudio-Chatbot-Model'.\n",
      "Created version '1' of model 'AIStudio-Chatbot-Model'.\n",
      "2025-08-19 14:17:26 - INFO - ✅ Model registered successfully with run ID: 0509c8656e024bdeb0c7074f6b406e1b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.7 s, sys: 17.8 s, total: 20.5 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\", '/phoenix/mlflow'))\n",
    "# === Set MLflow experiment context ===\n",
    "mlflow.set_experiment(experiment_name=MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "# === Validate local model file path ===\n",
    "if not os.path.exists(LOCAL_MODEL_PATH):\n",
    "    logger.info(f\"⚠️ Warning: Model file not found at {LOCAL_MODEL_PATH}. Please verify the path.\")\n",
    "\n",
    "logger.info(f'Starting the experiment: {MLFLOW_EXPERIMENT_NAME}')\n",
    "logger.info(f\"Using MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# === Log and register model to MLflow ===\n",
    "with mlflow.start_run(run_name=MLFLOW_RUN_NAME) as run:\n",
    "    # Print the artifact URI for reference\n",
    "    logging.info(f\"Run's Artifact URI: {run.info.artifact_uri}\")\n",
    "    \n",
    "    # Log model artifacts using custom ChatbotService\n",
    "    ChatbotService.log_model(\n",
    "        artifact_path=MLFLOW_MODEL_NAME,\n",
    "        config_path=CONFIG_PATH,\n",
    "        docs_path=DATA_PATH,\n",
    "        secrets_dict=secrets if secrets else None,\n",
    "        model_path=LOCAL_MODEL_PATH,\n",
    "        demo_folder=DEMO_FOLDER\n",
    "    )\n",
    "\n",
    "    # Construct the URI for the logged model\n",
    "    model_uri = f\"runs:/{run.info.run_id}/{MLFLOW_MODEL_NAME}\"\n",
    "\n",
    "    # Register the model into MLflow Model Registry\n",
    "    mlflow.register_model(\n",
    "        model_uri=model_uri,\n",
    "        name=MLFLOW_MODEL_NAME\n",
    "    )\n",
    "\n",
    "logger.info(f\"✅ Model registered successfully with run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cb33b25-e9bf-443a-9636-d1fd0385ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 14:17:26 - INFO - ⏱️ Total execution time: 0m 38.04s\n",
      "2025-08-19 14:17:26 - INFO - ✅ Notebook execution completed successfully.\n"
     ]
    }
   ],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"⏱️ Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"✅ Notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184e2983-bd61-4a8d-b76c-6ea5dcf3df72",
   "metadata": {},
   "source": [
    "Built with ❤️ using [**HP AI Studio**](https://hp.com/ai-studio)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
