{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd537ec-23d3-4b4e-979b-171f586afcb6",
   "metadata": {},
   "source": [
    "<h1 style=\\\"text-align: center; font-size: 50px;\\\">üò∑ Register Model for COVID Movement Patterns with VAR (Vector Autoregression)</h1>\n",
    "This notebook shows an visual data analysis of the effects of COVID-19 in two different cities: New York and London"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291d1d72",
   "metadata": {},
   "source": [
    "## Notebook Overview\n",
    "- Imports\n",
    "- Configurations\n",
    "- Preparing the Data\n",
    "- Logging Model to MLflow\n",
    "- Fetching the Latest Model Version from MLflow\n",
    "- Loading the Model and Running Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbe7ff0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091ed3c2",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 2.82276,
     "end_time": "2022-07-21T20:12:57.131891",
     "exception": false,
     "start_time": "2022-07-21T20:12:54.309131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------ Data Manipulation ------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------ System Utilities ------------------------\n",
    "import warnings\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "from typing import Any, Optional, Dict\n",
    "\n",
    "# ------------------------ MLflow for Experiment Tracking and Model Management ------------------------\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec, TensorSpec, ParamSchema, ParamSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727b12e",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c492213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Python warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92575391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logger\n",
    "logger = logging.getLogger(\"cities_analysis_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False\n",
    "logger.handlers.clear()\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", \n",
    "                              datefmt=\"%Y-%m-%d %H:%M:%S\")  \n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c8e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Paths -------------------------\n",
    "DATA_PATH = \"/home/jovyan/datafabric/tutorial/\"\n",
    "ARTIFACTS_PATH = \"../artifacts\"\n",
    "\n",
    "# ------------------------ MLflow Integration ------------------------\n",
    "EXPERIMENT_NAME = \"Two_Cities_Experiment\"\n",
    "RUN_NAME = \"Two_Cities_Run\"\n",
    "MODEL_NAME = \"Two_Cities_Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a198d962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 01:46:01 - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  \n",
    "logger.info('Notebook execution started.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2166ee00",
   "metadata": {},
   "source": [
    "## Verify Assets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25e95e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 01:46:01 - INFO - The Dataset is properly configured.\n"
     ]
    }
   ],
   "source": [
    "# Check whether the Dataset file exists\n",
    "is_dataset_available = Path(DATA_PATH).exists()\n",
    "\n",
    "# Log the configuration status of the dataset\n",
    "if is_dataset_available:\n",
    "    logger.info(\"The Dataset is properly configured.\")\n",
    "else:\n",
    "    logger.info(\n",
    "        \"The Dataset is not properly configured. Please create and download the required assets \"\n",
    "        \"in your project on AI Studio.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ac07a",
   "metadata": {
    "papermill": {
     "duration": 0.012023,
     "end_time": "2022-07-21T20:12:57.156282",
     "exception": false,
     "start_time": "2022-07-21T20:12:57.144259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f5acc7",
   "metadata": {
    "papermill": {
     "duration": 0.011898,
     "end_time": "2022-07-21T20:12:57.180282",
     "exception": false,
     "start_time": "2022-07-21T20:12:57.168384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Acknowledgments:\n",
    "I'd like to thank the original authors of these data sources!\n",
    "\n",
    "| Data | Original Source |\n",
    "| --- | --- |\n",
    "| Mobility Data | [COVID-19 Community Mobility Reports](https://www.google.com/covid19/mobility/) |\n",
    "| NYC Cases | [NYC Department of Health and Mental Hygiene](https://www1.nyc.gov/site/doh/index.page) |\n",
    "| London Cases | [GOV.UK Coronavirus (COVID-19) in the UK](https://coronavirus.data.gov.uk/) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d21de66f",
   "metadata": {
    "papermill": {
     "duration": 0.29149,
     "end_time": "2022-07-21T20:12:57.483924",
     "exception": false,
     "start_time": "2022-07-21T20:12:57.192434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_folder = DATA_PATH\n",
    "ny_mobility = pd.read_csv(f\"{source_folder}/NewYork_mobility.csv\")\n",
    "ldn_mobility = pd.read_csv(f\"{source_folder}London_mobility.csv\")\n",
    "ny_cases = pd.read_csv(f\"{source_folder}daily_data_NewYork.csv\")\n",
    "ldn_cases = pd.read_csv(f\"{source_folder}daily_data_London.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "913b3534",
   "metadata": {
    "papermill": {
     "duration": 0.047635,
     "end_time": "2022-07-21T20:12:57.545403",
     "exception": false,
     "start_time": "2022-07-21T20:12:57.497768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rename_mobility_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Renames the and cleans the dataset columns.\n",
    "\n",
    "    Parameters:\n",
    "        df(pd.DataFrame): A Dataframe containing the data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned dataframe with the renamed columns.\n",
    "    \"\"\"\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={'country_region':'country'})\n",
    "    df = df.rename(columns={'retail_and_recreation_percent_change_from_baseline':'retail'})\n",
    "    df = df.rename(columns={'grocery_and_pharmacy_percent_change_from_baseline':'pharmacy'})\n",
    "    df = df.rename(columns={'parks_percent_change_from_baseline':'parks'})\n",
    "    df = df.rename(columns={'transit_stations_percent_change_from_baseline':'transit_station'})\n",
    "    df = df.rename(columns={'workplaces_percent_change_from_baseline':'workplaces'})\n",
    "    df = df.rename(columns={'residential_percent_change_from_baseline':'residential'})\n",
    "    df.drop(['country_region_code','sub_region_1', 'sub_region_2', 'residential'], axis=1, inplace = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "ny_mobility = ny_mobility.loc[ny_mobility['sub_region_2'] == \"New York County\"].reset_index(drop=True)\n",
    "ldn_mobility = ldn_mobility.loc[ldn_mobility['sub_region_2'] == \"City of London\"].reset_index(drop=True)\n",
    "\n",
    "ny_mobility = rename_mobility_cols(ny_mobility)\n",
    "ldn_mobility = rename_mobility_cols(ldn_mobility)\n",
    "\n",
    "mobility_features = ny_mobility.columns[6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9347c6",
   "metadata": {
    "papermill": {
     "duration": 0.012002,
     "end_time": "2022-07-21T20:12:57.570115",
     "exception": false,
     "start_time": "2022-07-21T20:12:57.558113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "| Mobility Features     | Description                                                                                                                           |\n",
    "|-----------------|---------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| country          | Country Name                                                                         |\n",
    "| metro_area       | Metropolitan area                                                                    |\n",
    "| iso_3166_2_code  | Codes for the names of the principal subdivisions (e.g. provinces or states)         |\n",
    "| census_fips_code | Census fips code                                                                     |\n",
    "| place_id         | Place IDs uniquely identify a place in the Google Places database and on Google Maps |\n",
    "| date             | Date                                                                                 |\n",
    "| retail          | Mobility trends for places like restaurants, cafes, shopping centers, theme parks, museums, libraries, and movie theaters.            |\n",
    "| pharmacy        | Mobility trends for places like grocery markets, food warehouses, farmers markets, specialty food shops, drug stores, and pharmacies. |\n",
    "| parks           | Mobility trends for places like local parks, national parks, public beaches, marinas, dog parks, plazas, and public gardens.          |\n",
    "| transit_station | Mobility trends for places like public transport hubs such as subway, bus, and train stations.                                        |\n",
    "| workplaces      | Mobility trends for places of work.                                                                                                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dd209b4",
   "metadata": {
    "papermill": {
     "duration": 0.037799,
     "end_time": "2022-07-21T20:12:57.620000",
     "exception": false,
     "start_time": "2022-07-21T20:12:57.582201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>metro_area</th>\n",
       "      <th>iso_3166_2_code</th>\n",
       "      <th>census_fips_code</th>\n",
       "      <th>place_id</th>\n",
       "      <th>date</th>\n",
       "      <th>retail</th>\n",
       "      <th>pharmacy</th>\n",
       "      <th>parks</th>\n",
       "      <th>transit_station</th>\n",
       "      <th>workplaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB-LND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB-LND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB-LND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB-LND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ</td>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB-LND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  metro_area iso_3166_2_code  census_fips_code  \\\n",
       "0  United Kingdom         NaN          GB-LND               NaN   \n",
       "1  United Kingdom         NaN          GB-LND               NaN   \n",
       "2  United Kingdom         NaN          GB-LND               NaN   \n",
       "3  United Kingdom         NaN          GB-LND               NaN   \n",
       "4  United Kingdom         NaN          GB-LND               NaN   \n",
       "\n",
       "                      place_id        date  retail  pharmacy  parks  \\\n",
       "0  ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ  2020-02-15    -5.0      -9.0  -12.0   \n",
       "1  ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ  2020-02-16    -1.0     -21.0  -23.0   \n",
       "2  ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ  2020-02-17    -3.0      -2.0    4.0   \n",
       "3  ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ  2020-02-18    -2.0      -2.0   -1.0   \n",
       "4  ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ  2020-02-19    -7.0      -4.0    5.0   \n",
       "\n",
       "   transit_station  workplaces  \n",
       "0            -11.0         NaN  \n",
       "1            -13.0         NaN  \n",
       "2             -1.0        -4.0  \n",
       "3             -2.0        -2.0  \n",
       "4              0.0        -4.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldn_mobility.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4594a05",
   "metadata": {
    "papermill": {
     "duration": 0.012371,
     "end_time": "2022-07-21T20:12:57.645034",
     "exception": false,
     "start_time": "2022-07-21T20:12:57.632663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Try it out yourself üöÄ : [Get the Address for a Place ID üåé](https://developers.google.com/maps/documentation/javascript/examples/geocoding-place-id)\n",
    "\n",
    "![](https://i.imgur.com/B69162k.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94dbb2b0",
   "metadata": {
    "papermill": {
     "duration": 0.025077,
     "end_time": "2022-07-21T20:12:57.682840",
     "exception": false,
     "start_time": "2022-07-21T20:12:57.657763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rename_dailyData_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Renames the daily data DataFrame columns to standardized names.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): A Dataframe containing daily COVID-19 statistics.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The Dataframe with the renamed columns.\n",
    "    \"\"\"\n",
    "    mapping = {df.columns[0]:'date', df.columns[1]: 'case_count', df.columns[2]:'hospitalized_count', df.columns[3]: 'death_count'} \n",
    "    df = df.rename(columns = mapping)\n",
    "    return df\n",
    "\n",
    "ny_cases = ny_cases[['date_of_interest','CASE_COUNT','HOSPITALIZED_COUNT','DEATH_COUNT']]\n",
    "ldn_cases = ldn_cases[['date','newCasesBySpecimenDate', 'newAdmissions', 'newDeaths28DaysByDeathDate']]\n",
    "\n",
    "ny_cases = rename_dailyData_cols(ny_cases)\n",
    "ldn_cases = rename_dailyData_cols(ldn_cases)\n",
    "\n",
    "cases_features = ny_cases.columns[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7308a",
   "metadata": {
    "papermill": {
     "duration": 0.012104,
     "end_time": "2022-07-21T20:12:57.707548",
     "exception": false,
     "start_time": "2022-07-21T20:12:57.695444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "| Cases Features     | Description                    |\n",
    "|--------------------|--------------------------------|\n",
    "| date               | Date                           |\n",
    "| case_count         | Number of daily cases recorded |\n",
    "| hospitalized_count | Number of people hospitalized  |\n",
    "| death_count        | Number of deaths recorded      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a94c84",
   "metadata": {
    "papermill": {
     "duration": 0.025326,
     "end_time": "2022-07-21T20:12:57.745203",
     "exception": false,
     "start_time": "2022-07-21T20:12:57.719877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>case_count</th>\n",
       "      <th>hospitalized_count</th>\n",
       "      <th>death_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/29/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/01/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/02/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/03/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/04/2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  case_count  hospitalized_count  death_count\n",
       "0  02/29/2020           1                   1            0\n",
       "1  03/01/2020           0                   1            0\n",
       "2  03/02/2020           0                   2            0\n",
       "3  03/03/2020           1                   7            0\n",
       "4  03/04/2020           5                   2            0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15d7633a",
   "metadata": {
    "papermill": {
     "duration": 0.027912,
     "end_time": "2022-07-21T20:12:57.785816",
     "exception": false,
     "start_time": "2022-07-21T20:12:57.757904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for df in ny_mobility, ldn_mobility, ny_cases, ldn_cases:\n",
    "    df['date'] = df['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6e74fd5-887f-46e0-86a0-50c740cfba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(mobility: pd.DataFrame, cases: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges mobility and case data on the 'date' column using an inner join.\n",
    "\n",
    "    Parameters:\n",
    "        mobility (pd.DataFrame): DataFrame containing mobility indicators.\n",
    "        cases (pd.DataFrame): DataFrame containing COVID-19 case statistics.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Merged DataFrame containing both mobility and case data, aligned by date.\n",
    "    \"\"\"\n",
    "    merged_df = pd.merge(mobility, cases, how='inner', on = 'date')\n",
    "    return merged_df\n",
    "\n",
    "# setting date as the index column\n",
    "ny_df = merge_data(ny_mobility, ny_cases).set_index('date')\n",
    "ldn_df = merge_data(ldn_mobility, ldn_cases).set_index('date')\n",
    "ldn_df = ldn_df.iloc[:-2,:]\n",
    "\n",
    "features = ny_df.columns[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de8e51d9-e467-478b-aaf4-ce55376c60d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>metro_area</th>\n",
       "      <th>iso_3166_2_code</th>\n",
       "      <th>census_fips_code</th>\n",
       "      <th>place_id</th>\n",
       "      <th>retail</th>\n",
       "      <th>pharmacy</th>\n",
       "      <th>parks</th>\n",
       "      <th>transit_station</th>\n",
       "      <th>workplaces</th>\n",
       "      <th>case_count</th>\n",
       "      <th>hospitalized_count</th>\n",
       "      <th>death_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-19</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB-LND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>332</td>\n",
       "      <td>240</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-20</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB-LND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>424</td>\n",
       "      <td>272</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-21</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB-LND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348</td>\n",
       "      <td>311</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-22</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB-LND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439</td>\n",
       "      <td>335</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-23</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GB-LND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>685</td>\n",
       "      <td>505</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   country  metro_area iso_3166_2_code  census_fips_code  \\\n",
       "date                                                                       \n",
       "2020-03-19  United Kingdom         NaN          GB-LND               NaN   \n",
       "2020-03-20  United Kingdom         NaN          GB-LND               NaN   \n",
       "2020-03-21  United Kingdom         NaN          GB-LND               NaN   \n",
       "2020-03-22  United Kingdom         NaN          GB-LND               NaN   \n",
       "2020-03-23  United Kingdom         NaN          GB-LND               NaN   \n",
       "\n",
       "                               place_id  retail  pharmacy  parks  \\\n",
       "date                                                               \n",
       "2020-03-19  ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ   -78.0     -47.0  -74.0   \n",
       "2020-03-20  ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ   -82.0     -54.0  -77.0   \n",
       "2020-03-21  ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ   -86.0     -53.0  -86.0   \n",
       "2020-03-22  ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ   -85.0     -67.0  -86.0   \n",
       "2020-03-23  ChIJ4Y3fTlUDdkgR0Gbsoi2uDgQ   -87.0     -70.0  -82.0   \n",
       "\n",
       "            transit_station  workplaces  case_count  hospitalized_count  \\\n",
       "date                                                                      \n",
       "2020-03-19            -70.0       -63.0         332                 240   \n",
       "2020-03-20            -73.0       -64.0         424                 272   \n",
       "2020-03-21            -78.0         NaN         348                 311   \n",
       "2020-03-22            -81.0         NaN         439                 335   \n",
       "2020-03-23            -79.0       -76.0         685                 505   \n",
       "\n",
       "            death_count  \n",
       "date                     \n",
       "2020-03-19           25  \n",
       "2020-03-20           46  \n",
       "2020-03-21           46  \n",
       "2020-03-22           53  \n",
       "2020-03-23           56  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a796054-c0c9-4d2e-9471-6d360e1a0815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>metro_area</th>\n",
       "      <th>iso_3166_2_code</th>\n",
       "      <th>census_fips_code</th>\n",
       "      <th>place_id</th>\n",
       "      <th>retail</th>\n",
       "      <th>pharmacy</th>\n",
       "      <th>parks</th>\n",
       "      <th>transit_station</th>\n",
       "      <th>workplaces</th>\n",
       "      <th>case_count</th>\n",
       "      <th>hospitalized_count</th>\n",
       "      <th>death_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-29</th>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36061.0</td>\n",
       "      <td>ChIJOwE7_GTtwokRFq0uOwLSE9g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-01</th>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36061.0</td>\n",
       "      <td>ChIJOwE7_GTtwokRFq0uOwLSE9g</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-02</th>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36061.0</td>\n",
       "      <td>ChIJOwE7_GTtwokRFq0uOwLSE9g</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-03</th>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36061.0</td>\n",
       "      <td>ChIJOwE7_GTtwokRFq0uOwLSE9g</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-04</th>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36061.0</td>\n",
       "      <td>ChIJOwE7_GTtwokRFq0uOwLSE9g</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  country  metro_area iso_3166_2_code  census_fips_code  \\\n",
       "date                                                                      \n",
       "2020-02-29  United States         NaN             NaN           36061.0   \n",
       "2020-03-01  United States         NaN             NaN           36061.0   \n",
       "2020-03-02  United States         NaN             NaN           36061.0   \n",
       "2020-03-03  United States         NaN             NaN           36061.0   \n",
       "2020-03-04  United States         NaN             NaN           36061.0   \n",
       "\n",
       "                               place_id  retail  pharmacy  parks  \\\n",
       "date                                                               \n",
       "2020-02-29  ChIJOwE7_GTtwokRFq0uOwLSE9g     1.0       2.0   -2.0   \n",
       "2020-03-01  ChIJOwE7_GTtwokRFq0uOwLSE9g    -3.0       2.0   -7.0   \n",
       "2020-03-02  ChIJOwE7_GTtwokRFq0uOwLSE9g     3.0       6.0   17.0   \n",
       "2020-03-03  ChIJOwE7_GTtwokRFq0uOwLSE9g     0.0       6.0    5.0   \n",
       "2020-03-04  ChIJOwE7_GTtwokRFq0uOwLSE9g     3.0       9.0   13.0   \n",
       "\n",
       "            transit_station  workplaces  case_count  hospitalized_count  \\\n",
       "date                                                                      \n",
       "2020-02-29             -1.0         6.0           1                   1   \n",
       "2020-03-01             -3.0         1.0           0                   1   \n",
       "2020-03-02             -3.0         4.0           0                   2   \n",
       "2020-03-03             -1.0         3.0           1                   7   \n",
       "2020-03-04             -3.0         2.0           5                   2   \n",
       "\n",
       "            death_count  \n",
       "date                     \n",
       "2020-02-29            0  \n",
       "2020-03-01            0  \n",
       "2020-03-02            0  \n",
       "2020-03-03            0  \n",
       "2020-03-04            0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959456a",
   "metadata": {},
   "source": [
    "## Logging Model to MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf97381-e661-4765-865c-03afcc79ffff",
   "metadata": {},
   "source": [
    "Reading the JSON with training parameters that were saved during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61a41c35-f31a-436e-b4a0-a4c431f27216",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = ARTIFACTS_PATH\n",
    "os.makedirs(artifacts_dir, exist_ok=True)\n",
    "\n",
    "with open(f\"{artifacts_dir}/training_metrics.json\", \"r\") as metrics:\n",
    "            metrics_dict = json.load(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a19973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/mlflow/pyfunc/model.py:172: UserWarning: \u001b[31mType hint used in the model's predict function is not supported for MLflow's schema validation. Type hints must be wrapped in list[...] because MLflow assumes the predict method to take multiple input instances. Specify your type hint as `list[typing.Dict[str, typing.Any]]` for a valid signature. Remove the type hint to disable this warning. To enable validation for the input data, specify input example or model signature when logging the model. \u001b[0m\n",
      "  func_info = _get_func_info_if_type_hint_supported(predict_attr)\n"
     ]
    }
   ],
   "source": [
    "class TwoCitiesModel(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context: mlflow.pyfunc.PythonModelContext) -> None:\n",
    "        \"\"\"Load model artifacts from the MLflow context.\"\"\"\n",
    "        try:    \n",
    "            \n",
    "            # Load the trained models\n",
    "            self.ny_model = pickle.load(open(os.path.join(context.artifacts[\"ny_model\"]), \"rb\"))\n",
    "            self.ldn_model = pickle.load(open(os.path.join(context.artifacts[\"ldn_model\"]), \"rb\"))\n",
    "            \n",
    "            # Load the last values for forecasting and reverse transformation\n",
    "            self.ny_last_values = pickle.load(open(os.path.join(context.artifacts[\"ny_last_values\"]), \"rb\"))\n",
    "            self.ldn_last_values = pickle.load(open(os.path.join(context.artifacts[\"ldn_last_values\"]), \"rb\"))\n",
    "            \n",
    "            # Load the lag order for each model\n",
    "            self.ny_lag_order = self.ny_model.k_ar\n",
    "            self.ldn_lag_order = self.ldn_model.k_ar\n",
    "            \n",
    "            # Load the last raw values needed for transforming differenced forecasts back\n",
    "            self.ny_last_raw_value = pickle.load(open(os.path.join(context.artifacts[\"ny_last_raw_value\"]), \"rb\"))\n",
    "            self.ldn_last_raw_value = pickle.load(open(os.path.join(context.artifacts[\"ldn_last_raw_value\"]), \"rb\"))\n",
    "            \n",
    "            # Load feature names\n",
    "            self.features = pickle.load(open(os.path.join(context.artifacts[\"features\"]), \"rb\"))\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading context: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def check_stationarity(self, series: pd.Series) -> bool:\n",
    "        \"\"\"Check if a time series is stationary using Augmented Dickey-Fuller test.\"\"\"\n",
    "        result = adfuller(series, autolag='AIC')\n",
    "        return result[1] <= 0.05 \n",
    "    \n",
    "    def difference_data(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply differencing to make time series stationary.\"\"\"\n",
    "        return data.diff().dropna()\n",
    "    \n",
    "    def rolling_back_transformation(self, last_raw_value: Any, forecast_output: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Convert differenced forecasts back to original scale.\"\"\"\n",
    "        forecast_final = forecast_output.copy()\n",
    "        \n",
    "        for i, col in enumerate(self.features):\n",
    "            col_forecast = f\"{col}_forecast\"\n",
    "            # Cumulatively add differences starting from the last known value\n",
    "            forecast_final[col_forecast] = last_raw_value[i] + forecast_output[col_forecast].cumsum()\n",
    "        \n",
    "        return forecast_final\n",
    "\n",
    "    \n",
    "    def predict(self, context: Any, model_input: Dict[str, Any], params: Optional[dict] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Computes the predicted forecast.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            city = model_input.get(\"city\", [\"New York\"])[0]\n",
    "            steps = int(model_input.get(\"steps\", [7])[0])\n",
    "            new_data = model_input.get(\"new_data\", None)\n",
    "        \n",
    "            if city == \"New York\":\n",
    "                model = self.ny_model\n",
    "                forecast_input = self.ny_last_values\n",
    "                last_raw_value = self.ny_last_raw_value\n",
    "                lag_order = self.ny_lag_order\n",
    "            else:  # London\n",
    "                model = self.ldn_model\n",
    "                forecast_input = self.ldn_last_values\n",
    "                last_raw_value = self.ldn_last_raw_value\n",
    "                lag_order = self.ldn_lag_order\n",
    "            \n",
    "            # If new data is provided, update the forecast input\n",
    "            if new_data is not None:\n",
    "                new_df = pd.DataFrame(new_data)\n",
    "                \n",
    "                # Check if data needs differencing\n",
    "                stationary = all(self.check_stationarity(new_df[col]) for col in new_df.columns)\n",
    "                \n",
    "                if not stationary:\n",
    "                    new_df = self.difference_data(new_df)\n",
    "                \n",
    "                forecast_input = new_df.values[-lag_order:]\n",
    "                \n",
    "                last_raw_value = new_data.iloc[-1].values\n",
    "            \n",
    "            # Make forecast\n",
    "            fc = model.forecast(y=forecast_input, steps=steps)\n",
    "            \n",
    "            # Create DataFrame with forecasted values\n",
    "            dates = pd.date_range(start=pd.Timestamp.today(), periods=steps)\n",
    "            forecast_output = pd.DataFrame(fc, index=dates, columns=[f\"{col}_forecast\" for col in self.features])\n",
    "            \n",
    "            # Transform differenced forecasts back to original scale\n",
    "            forecast_final = self.rolling_back_transformation(last_raw_value, forecast_output)\n",
    "            \n",
    "            return forecast_final\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error performing prediction: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    @classmethod\n",
    "    def log_model(cls, model_name: str) -> None:\n",
    "        \"\"\"\n",
    "        Logs the model to MLflow with artifacts for demo and config.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Define input and output schema\n",
    "            input_schema = Schema([\n",
    "                ColSpec(\"string\",\"city\"),\n",
    "                ColSpec(\"long\",\"steps\"),\n",
    "                ])\n",
    "            output_schema = Schema([\n",
    "                ColSpec(\"string\", \"class\"),\n",
    "            ])\n",
    "            \n",
    "            # Define model signature\n",
    "            signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "            \n",
    "            # Prepare artifacts dictionary with model files\n",
    "            artifacts = {\n",
    "                \"ny_model\": f\"{artifacts_dir}/ny_model.pkl\",\n",
    "                \"ldn_model\": f\"{artifacts_dir}/ldn_model.pkl\",\n",
    "                \"ny_last_values\": f\"{artifacts_dir}/ny_last_values.pkl\",\n",
    "                \"ldn_last_values\": f\"{artifacts_dir}/ldn_last_values.pkl\",\n",
    "                \"ny_last_raw_value\": f\"{artifacts_dir}/ny_last_raw_value.pkl\",\n",
    "                \"ldn_last_raw_value\": f\"{artifacts_dir}/ldn_last_raw_value.pkl\",\n",
    "                \"features\": f\"{artifacts_dir}/features.pkl\"\n",
    "            }\n",
    "            \n",
    "            # Add demo folder as artifact\n",
    "            demo_folder = \"../demo\"\n",
    "            if os.path.exists(demo_folder):\n",
    "                artifacts[\"demo\"] = demo_folder\n",
    "                logger.info(f\"‚úÖ Demo folder added to artifacts: {demo_folder}\")\n",
    "            else:\n",
    "                logger.warning(f\"‚ö†Ô∏è  Demo folder not found: {demo_folder}\")\n",
    "                \n",
    "            # Add config file as artifact\n",
    "            config_path = \"../configs/config.yaml\"\n",
    "            if os.path.exists(config_path):\n",
    "                artifacts[\"config\"] = config_path\n",
    "                logger.info(f\"‚úÖ Config file added to artifacts: {config_path}\")\n",
    "            else:\n",
    "                logger.warning(f\"‚ö†Ô∏è  Config file not found: {config_path}\")\n",
    "            \n",
    "            # Log the model in MLflow\n",
    "            mlflow.pyfunc.log_model(\n",
    "                artifact_path=model_name,\n",
    "                python_model=cls(),\n",
    "                artifacts=artifacts,\n",
    "                signature=signature\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error logging model: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a3656fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 01:46:02 - INFO - Starting the experiment: Two_Cities_Experiment\n",
      "2025/09/11 01:46:02 INFO mlflow.tracking.fluent: Experiment with name 'Two_Cities_Experiment' does not exist. Creating a new experiment.\n",
      "2025-09-11 01:46:03 - INFO - ‚úÖ Demo folder added to artifacts: ../demo\n",
      "2025-09-11 01:46:03 - INFO - ‚úÖ Config file added to artifacts: ../configs/config.yaml\n",
      "2025/09/11 01:46:03 INFO mlflow.models.signature: Inferring model signature from type hints\n",
      "/opt/conda/lib/python3.12/site-packages/mlflow/pyfunc/__init__.py:3139: UserWarning: Failed to infer signature from type hint: Type hints must be wrapped in list[...] because MLflow assumes the predict method to take multiple input instances. Specify your type hint as `list[typing.Dict[str, typing.Any]]` for a valid signature.\n",
      "  signature_from_type_hints = _infer_signature_from_type_hints(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0def7a83f3c84481913ebfc067dca7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6714a6ded06c452e98fbfcd2f4a0f90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b167950bce1459f9ff0d5bc07347e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b23bbd97a943a6b9ce612ccf4abd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ab1d73920d449bba934263697d3110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18a4616e9aa401c8d2007b42f681c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07052d410d1f45febdc0c1e31ef1a9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac6d95db47b49bc9d8612347496f5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15962f3a890d4efdb575ac0cab3394eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Two_Cities_Model'.\n",
      "Created version '1' of model 'Two_Cities_Model'.\n",
      "2025-09-11 01:46:10 - INFO - Registered the model: Two_Cities_Model\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Starting the experiment: {EXPERIMENT_NAME}')\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"/phoenix/mlflow\")\n",
    "# Set the MLflow experiment name\n",
    "mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:    \n",
    "    \n",
    "    # Registering the training metrics to mlflow\n",
    "    mlflow.log_metrics(metrics_dict)\n",
    "    \n",
    "    # Print the artifact URI for reference\n",
    "    logging.info(f\"Run's Artifact URI: {run.info.artifact_uri}\")\n",
    "    \n",
    "    # Log the model to MLflow\n",
    "    TwoCitiesModel.log_model(model_name=MODEL_NAME)\n",
    "\n",
    "    # Register the logged model in MLflow Model Registry\n",
    "    mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run.info.run_id}/{MODEL_NAME}\", \n",
    "        name=MODEL_NAME\n",
    "    )\n",
    "\n",
    "logger.info(f'Registered the model: {MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878eacd7",
   "metadata": {},
   "source": [
    "## Fetching the Latest Model Version from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05c82b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Model Version: 1\n",
      "Model Signature: inputs: \n",
      "  ['city': string (required), 'steps': long (required)]\n",
      "outputs: \n",
      "  ['class': string (required)]\n",
      "params: \n",
      "  None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Retrieve the latest version of the model\n",
    "model_metadata = client.get_latest_versions(MODEL_NAME, stages=[\"None\"])\n",
    "latest_model_version = model_metadata[0].version  # Extract the latest model version\n",
    "\n",
    "# Fetch model information, including its signature\n",
    "model_info = mlflow.models.get_model_info(f\"models:/{MODEL_NAME}/{latest_model_version}\")\n",
    "\n",
    "# Print the latest model version and its signature\n",
    "print(f\"Latest Model Version: {latest_model_version}\")\n",
    "print(f\"Model Signature: {model_info.signature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef755e",
   "metadata": {},
   "source": [
    "## Loading the Model and Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e11a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York:                             retail_forecast  pharmacy_forecast  \\\n",
      "2025-09-11 01:46:10.861316       -33.728463         -30.846299   \n",
      "2025-09-12 01:46:10.861316       -38.215550         -30.564491   \n",
      "2025-09-13 01:46:10.861316       -35.413120         -22.604498   \n",
      "\n",
      "                            parks_forecast  transit_station_forecast  \\\n",
      "2025-09-11 01:46:10.861316       10.141208                -22.428500   \n",
      "2025-09-12 01:46:10.861316       -4.275643                -39.144546   \n",
      "2025-09-13 01:46:10.861316       11.427796                -30.944809   \n",
      "\n",
      "                            workplaces_forecast  case_count_forecast  \\\n",
      "2025-09-11 01:46:10.861316           -22.994693          2408.753695   \n",
      "2025-09-12 01:46:10.861316           -56.921910          4896.935950   \n",
      "2025-09-13 01:46:10.861316           -40.361528          4383.142165   \n",
      "\n",
      "                            hospitalized_count_forecast  death_count_forecast  \n",
      "2025-09-11 01:46:10.861316                    98.599755             11.877681  \n",
      "2025-09-12 01:46:10.861316                   116.084260             10.017072  \n",
      "2025-09-13 01:46:10.861316                    99.183920              8.373051  \n",
      "\n",
      "\n",
      "London:                             retail_forecast  pharmacy_forecast  \\\n",
      "2025-09-11 01:46:10.864717       -58.335887         -65.339207   \n",
      "2025-09-12 01:46:10.864717       -58.566546         -61.706790   \n",
      "2025-09-13 01:46:10.864717       -63.021569         -70.304335   \n",
      "\n",
      "                            parks_forecast  transit_station_forecast  \\\n",
      "2025-09-11 01:46:10.864717      -49.128761                -45.393284   \n",
      "2025-09-12 01:46:10.864717      -47.566437                -43.432193   \n",
      "2025-09-13 01:46:10.864717      -49.084741                -50.660061   \n",
      "\n",
      "                            workplaces_forecast  case_count_forecast  \\\n",
      "2025-09-11 01:46:10.864717           -35.708088          3417.097620   \n",
      "2025-09-12 01:46:10.864717           -37.237890          2859.464938   \n",
      "2025-09-13 01:46:10.864717           -45.280012          3518.417212   \n",
      "\n",
      "                            hospitalized_count_forecast  death_count_forecast  \n",
      "2025-09-11 01:46:10.864717                   210.033193             15.678151  \n",
      "2025-09-12 01:46:10.864717                   214.484667             12.328597  \n",
      "2025-09-13 01:46:10.864717                   240.783570             21.206821  \n"
     ]
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{MODEL_NAME}/{latest_model_version}\")\n",
    "# Make predictions for New York\n",
    "ny_prediction = model.predict({\n",
    "    \"city\": [\"New York\"],\n",
    "    \"steps\": [3]  # Forecast for the next 3 days\n",
    "})\n",
    "\n",
    "# Make predictions for London\n",
    "ldn_prediction = model.predict({\n",
    "    \"city\": [\"London\"],\n",
    "    \"steps\": [3]  # Forecast for the next 3 days\n",
    "})\n",
    "\n",
    "print(f\"New York: {ny_prediction}\" )\n",
    "print(\"\\n\")\n",
    "print(f\"London: {ldn_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d805a67b-86b7-4b9d-979d-dafd43d7f880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 01:46:10 - INFO - ‚è±Ô∏è Total execution time: 0m 9.10s\n",
      "2025-09-11 01:46:10 - INFO - ‚úÖ Notebook execution completed successfully.\n"
     ]
    }
   ],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"‚è±Ô∏è Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"‚úÖ Notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f6f158",
   "metadata": {},
   "source": [
    "Built with ‚ù§Ô∏è using [**HP AI Studio**](https://hp.com/ai-studio)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 54.676437,
   "end_time": "2022-07-21T20:13:40.519212",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-21T20:12:45.842775",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
