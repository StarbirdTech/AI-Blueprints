{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f57b339a",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-size: 50px;\"> Spam Detection with NLP (Natural Language Processing) MLflow Integration </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ce3c0",
   "metadata": {},
   "source": [
    "Notebook Overview\n",
    "- Start Execution\n",
    "- User Constants\n",
    "- Install and Import Libraries\n",
    "- Configure Settings\n",
    "- Verify Assets\n",
    "- Logging Model to MLflow\n",
    "- Fetching the Latest Model Version from MLflow\n",
    "- Loading the Model and Running Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603b4752",
   "metadata": {},
   "source": [
    "## Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c18c0be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "# Configure logger\n",
    "logger: logging.Logger = logging.getLogger(\"register_model_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent duplicate logs from parent loggers\n",
    "\n",
    "# Set formatter\n",
    "formatter: logging.Formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Configure and attach stream handler\n",
    "stream_handler: logging.StreamHandler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd8a0ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 12:11:49 - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  \n",
    "\n",
    "logger.info(\"Notebook execution started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb13ca",
   "metadata": {},
   "source": [
    "## User Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d56348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"You have won a free ticket!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f18f9b",
   "metadata": {},
   "source": [
    "##  Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a572e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4842c6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------ System Utilities ------------------------\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ------------------------ Data Manipulation ------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------ Text Preprocessing ------------------------\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from types import SimpleNamespace\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ------------------------ Machine Learning tools ------------------------\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ------------------------ MLflow for Experiment Tracking and Model Management ------------------------\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a5569",
   "metadata": {},
   "source": [
    "## Configure Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01347a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Python warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d75e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Paths -------------------------\n",
    "DATA_PATH = '/home/jovyan/datafabric/tutorial/spam_utf8.csv'\n",
    "NLTK_DIR_LOCAL  = '/home/jovyan/local/nltk_data'  \n",
    "# ------------------------ MLflow Integration ------------------------\n",
    "EXPERIMENT_NAME = \"Spam_Detection_Experiment\"\n",
    "RUN_NAME = \"Spam_Detection_Run\"\n",
    "MODEL_NAME = \"Spam_Detection_Model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f6aff",
   "metadata": {},
   "source": [
    "## Verify Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a13cec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 12:11:54 - INFO - Spam data is properly configured. \n",
      "2025-07-16 12:11:54 - INFO - NLTK Path is properly configured. \n"
     ]
    }
   ],
   "source": [
    "def log_asset_status(asset_path: str, asset_name: str, success_message: str, failure_message: str) -> None:\n",
    "    \"\"\"\n",
    "    Logs the status of a given asset based on its existence.\n",
    "\n",
    "    Parameters:\n",
    "        asset_path (str): File or directory path to check.\n",
    "        asset_name (str): Name of the asset for logging context.\n",
    "        success_message (str): Message to log if asset exists.\n",
    "        failure_message (str): Message to log if asset does not exist.\n",
    "    \"\"\"\n",
    "    if Path(asset_path).exists():\n",
    "        logger.info(f\"{asset_name} is properly configured. {success_message}\")\n",
    "    else:\n",
    "        logger.info(f\"{asset_name} is not properly configured. {failure_message}\")\n",
    "\n",
    "log_asset_status(\n",
    "    asset_path=DATA_PATH,\n",
    "    asset_name=\"Spam data\",\n",
    "    success_message=\"\",\n",
    "    failure_message=\"Please create and download the required assets in your project on AI Studio.\"\n",
    ")\n",
    "\n",
    "log_asset_status(\n",
    "    asset_path=NLTK_DIR_LOCAL,\n",
    "    asset_name=\"NLTK Path\",\n",
    "    success_message=\"\",\n",
    "    failure_message=\"Please check if NLTK was downloaded.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c93000",
   "metadata": {},
   "source": [
    "## Logging Model to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5054ddb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a732d575aa6540a1becdfe4ef26a50cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f104a58f704beea223d8b09911dac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Spam_Detection_Model' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'Spam_Detection_Model'.\n",
      "2025-07-16 12:11:57 - INFO - Registered the model: Spam_Detection_Model\n",
      "2025-07-16 12:11:57 - INFO - ✅Stopwords packed in the artifact\": /phoenix/mlflow/825651502965763105/288e6b4419f5478a993917b36ee86d19/artifacts/nltk_data\n"
     ]
    }
   ],
   "source": [
    "def ensure_local_stopwords(base_dir: str):\n",
    "    sw_file = Path(base_dir) / 'corpora' / 'stopwords' / 'english'\n",
    "    if not sw_file.exists():\n",
    "        sw_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        logger.info(\"⬇️ Downloanding stopwords on %s …\", base_dir)\n",
    "        nltk.download('stopwords', download_dir=base_dir, quiet=True, raise_on_error=True)\n",
    "    nltk.data.path = [base_dir]            \n",
    "\n",
    "class SpamDetectionModel(mlflow.pyfunc.PythonModel):\n",
    "    def preprocess(self, text: str):\n",
    "        \"\"\"\n",
    "        Preprocesses the message, performing:\n",
    "        1. Removal of all punctuation\n",
    "        2. Removal of all stopwords\n",
    "        3. Return of a list of the cleaned text\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            nopunc = ''.join(c for c in text if c not in string.punctuation)\n",
    "            return [w for w in nopunc.split() if w.lower() not in self.stop_words]\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error preprocessing: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def load_context(self, context):\n",
    "        \"\"\"Load model artifacts and pipeline.\"\"\"\n",
    "        try:\n",
    "        \n",
    "            nltk_dir = os.path.abspath(context.artifacts['nltk_data'])\n",
    "            nltk.data.path = [nltk_dir]\n",
    "            os.environ['NLTK_DATA'] = nltk_dir\n",
    "    \n",
    "            self.stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "            df = pd.read_csv(context.artifacts['data_path'], sep=',',\n",
    "                             names=['label', 'message', '_1', '_2', '_3'])\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "                df['message'], df['label'], test_size=0.2, random_state=42\n",
    "            )\n",
    "    \n",
    "            self.pipeline = Pipeline([\n",
    "                ('bow',   CountVectorizer(analyzer=self.preprocess)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf',   MultinomialNB()),\n",
    "            ])\n",
    "            self.pipeline.fit(X_tr, y_tr)\n",
    "            self._X_test, self._y_test = X_te, y_te\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading context: {str(e)}\")\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"\n",
    "        Computes the prediction of whether it is ham or spam.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            return self.pipeline.predict(model_input)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error performing prediction: {str(e)}\")\n",
    "            \n",
    "mlflow.set_tracking_uri(\"/phoenix/mlflow\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "ensure_local_stopwords(NLTK_DIR_LOCAL)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    mlflow.log_artifacts(NLTK_DIR_LOCAL, artifact_path='nltk_data')\n",
    "    nltk_artifact_uri = mlflow.get_artifact_uri('nltk_data')\n",
    "\n",
    "    ctx = SimpleNamespace(artifacts={\n",
    "        'data_path': DATA_PATH,\n",
    "        'nltk_data': nltk_artifact_uri\n",
    "    })\n",
    "\n",
    "    model = SpamDetectionModel()\n",
    "    model.load_context(ctx)\n",
    "\n",
    "    preds   = model.pipeline.predict(model._X_test)\n",
    "    report  = classification_report(model._y_test, preds, output_dict=True)\n",
    "    mlflow.log_metric('accuracy', report['accuracy'])\n",
    "\n",
    "    signature = ModelSignature(\n",
    "        inputs  = Schema([ColSpec('string', 'text')]),\n",
    "        outputs = Schema([ColSpec('string')])\n",
    "    )\n",
    "\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=MODEL_NAME,\n",
    "        python_model=model,\n",
    "        artifacts={\n",
    "            'data_path': DATA_PATH,\n",
    "            'nltk_data': nltk_artifact_uri\n",
    "        },\n",
    "        signature=signature,\n",
    "        pip_requirements='../requirements.txt'\n",
    "    )\n",
    "    \n",
    "    model_uri = f\"runs:/{run.info.run_id}/{MODEL_NAME}\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=MODEL_NAME)\n",
    "\n",
    "logger.info(f'Registered the model: {MODEL_NAME}')\n",
    "logger.info(f'✅Stopwords packed in the artifact\": {nltk_artifact_uri}')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229ff16",
   "metadata": {},
   "source": [
    "## Fetching the Latest Model Version from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85b56eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 12:11:57 - INFO - Latest Model Version: 2\n",
      "2025-07-16 12:11:57 - INFO - Model Signature: inputs: \n",
      "  ['text': string (required)]\n",
      "outputs: \n",
      "  [string (required)]\n",
      "params: \n",
      "  None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Retrieve the latest version of the \"spam_detect_model\" model \n",
    "model_metadata = client.get_latest_versions(MODEL_NAME, stages=[\"None\"])\n",
    "latest_model_version = model_metadata[0].version  # Extract the latest model version\n",
    "\n",
    "# Fetch model information, including its signature\n",
    "model_info = mlflow.models.get_model_info(f\"models:/{MODEL_NAME}/{latest_model_version}\")\n",
    "\n",
    "# Print the latest model version and its signature\n",
    "logger.info(f\"Latest Model Version: {latest_model_version}\")\n",
    "logger.info(f\"Model Signature: {model_info.signature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c894e1",
   "metadata": {},
   "source": [
    "## Loading the Model and Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d89833d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 12:11:57 - INFO - ['ham']\n"
     ]
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{MODEL_NAME}/{latest_model_version}\")\n",
    "\n",
    "# Define a sample text for testing\n",
    "text = pd.DataFrame({'text': [TEXT]})\n",
    "\n",
    "# Use the model to predict \n",
    "result = model.predict(text)\n",
    "logger.info(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "374ad096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 12:11:57 - INFO - ⏱️ Total execution time: 0m 8.23s\n",
      "2025-07-16 12:11:57 - INFO - ✅ Notebook execution completed successfully.\n"
     ]
    }
   ],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"⏱️ Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"✅ Notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134e6104",
   "metadata": {},
   "source": [
    "Built with ❤️ using [**Z by HP AI Studio**](https://zdocs.datascience.hp.com/docs/aistudio/overview)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
