{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f57b339a",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-size: 50px;\"> Spam Detection with NLP (Natural Language Processing) MLflow Integration </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ce3c0",
   "metadata": {},
   "source": [
    "Notebook Overview\n",
    "- Start Execution\n",
    "- User Constants\n",
    "- Install and Import Libraries\n",
    "- Configure Settings\n",
    "- Verify Assets\n",
    "- Logging Model to MLflow\n",
    "- Fetching the Latest Model Version from MLflow\n",
    "- Loading the Model and Running Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603b4752",
   "metadata": {},
   "source": [
    "## Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c18c0be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "# Configure logger\n",
    "logger: logging.Logger = logging.getLogger(\"register_model_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent duplicate logs from parent loggers\n",
    "\n",
    "# Set formatter\n",
    "formatter: logging.Formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Configure and attach stream handler\n",
    "stream_handler: logging.StreamHandler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd8a0ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 17:15:01 - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  \n",
    "\n",
    "logger.info(\"Notebook execution started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb13ca",
   "metadata": {},
   "source": [
    "## User Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d56348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"You have won a free ticket!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f18f9b",
   "metadata": {},
   "source": [
    "##  Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a572e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4842c6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------ System Utilities ------------------------\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# ------------------------ Data Manipulation ------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------ Text Preprocessing ------------------------\n",
    "import string\n",
    "import nltk\n",
    "import sys\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from types import SimpleNamespace\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ------------------------ Machine Learning tools ------------------------\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ------------------------ MLflow for Experiment Tracking and Model Management ------------------------\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "# ------------------------ Utils Import ------------------------\n",
    "sys.path.append(\"../src\")\n",
    "from utils import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a5569",
   "metadata": {},
   "source": [
    "## Configure Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01347a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Python warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d75e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Paths -------------------------\n",
    "DATA_PATH = '/home/jovyan/datafabric/tutorial/spam_utf8.csv'\n",
    "NLTK_DIR_LOCAL  = '/home/jovyan/local/nltk_data'  \n",
    "CONFIG_PATH = \"../configs/config.yaml\"\n",
    "config = load_config(CONFIG_PATH)\n",
    "DEMO_FOLDER = \"../demo\"\n",
    "\n",
    "# ------------------------ MLflow Integration ------------------------\n",
    "EXPERIMENT_NAME = \"Spam_Detection_Experiment\"\n",
    "RUN_NAME = \"Spam_Detection_Run\"\n",
    "MODEL_NAME = \"Spam_Detection_Model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f6aff",
   "metadata": {},
   "source": [
    "## Verify Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a13cec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 17:15:04 - INFO - Spam data is properly configured. \n",
      "2025-08-01 17:15:04 - INFO - NLTK Path is properly configured. \n",
      "2025-08-01 17:15:04 - INFO - Demo Folder is properly configured. \n"
     ]
    }
   ],
   "source": [
    "def log_asset_status(asset_path: str, asset_name: str, success_message: str, failure_message: str) -> None:\n",
    "    \"\"\"\n",
    "    Logs the status of a given asset based on its existence.\n",
    "\n",
    "    Parameters:\n",
    "        asset_path (str): File or directory path to check.\n",
    "        asset_name (str): Name of the asset for logging context.\n",
    "        success_message (str): Message to log if asset exists.\n",
    "        failure_message (str): Message to log if asset does not exist.\n",
    "    \"\"\"\n",
    "    if Path(asset_path).exists():\n",
    "        logger.info(f\"{asset_name} is properly configured. {success_message}\")\n",
    "    else:\n",
    "        logger.info(f\"{asset_name} is not properly configured. {failure_message}\")\n",
    "\n",
    "log_asset_status(\n",
    "    asset_path=DATA_PATH,\n",
    "    asset_name=\"Spam data\",\n",
    "    success_message=\"\",\n",
    "    failure_message=\"Please create and download the required assets in your project on AI Studio.\"\n",
    ")\n",
    "\n",
    "log_asset_status(\n",
    "    asset_path=NLTK_DIR_LOCAL,\n",
    "    asset_name=\"NLTK Path\",\n",
    "    success_message=\"\",\n",
    "    failure_message=\"Please check if NLTK was downloaded.\"\n",
    ")\n",
    "\n",
    "log_asset_status(\n",
    "    asset_path=DEMO_FOLDER,\n",
    "    asset_name=\"Demo Folder\",\n",
    "    success_message=\"\",\n",
    "    failure_message=\"Please check if Demo folder was downloaded.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c93000",
   "metadata": {},
   "source": [
    "## Logging Model to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5054ddb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:168: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "def ensure_local_stopwords(base_dir: str):\n",
    "    sw_file = Path(base_dir) / 'corpora' / 'stopwords' / 'english'\n",
    "    if not sw_file.exists():\n",
    "        sw_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        logger.info(\"‚¨áÔ∏è Downloading stopwords to %s ‚Ä¶\", base_dir)\n",
    "        nltk.download('stopwords', download_dir=base_dir, quiet=True, raise_on_error=True)\n",
    "    nltk.data.path = [base_dir]\n",
    "\n",
    "\n",
    "class SpamDetectionModel(mlflow.pyfunc.PythonModel):\n",
    "    def preprocess(self, text: str):\n",
    "        \"\"\"\n",
    "        Preprocesses the message, performing:\n",
    "        1. Removal of all punctuation\n",
    "        2. Removal of all stopwords\n",
    "        3. Return of a list of the cleaned text\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            nopunc = ''.join(c for c in text if c not in string.punctuation)\n",
    "            return [w for w in nopunc.split() if w.lower() not in self.stop_words]\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error preprocessing: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def load_context(self, context):\n",
    "        try:\n",
    "            nltk_dir = os.path.abspath(context.artifacts['nltk_data'])\n",
    "            nltk.data.path = [nltk_dir]\n",
    "            os.environ['NLTK_DATA'] = nltk_dir\n",
    "            self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "            df = pd.read_csv(context.artifacts['data_path'], sep=',',\n",
    "                             names=[\"label\", \"message\", \"v3\", \"v4\", \"v5\"])\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "                df['message'], df['label'], test_size=0.2, random_state=42\n",
    "            )\n",
    "\n",
    "            self.pipeline = Pipeline([\n",
    "                ('bow', CountVectorizer(analyzer=self.preprocess)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', MultinomialNB()),\n",
    "            ])\n",
    "            self.pipeline.fit(X_tr, y_tr)\n",
    "            self._X_test, self._y_test = X_te, y_te\n",
    "\n",
    "            config_path = context.artifacts[\"config\"]\n",
    "            with open(config_path, 'r') as f:\n",
    "                self.config = yaml.safe_load(f)\n",
    "\n",
    "            logger.info(\"‚úÖ Model and configuration loaded successfully\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading context: {str(e)}\")\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        try:\n",
    "            return self.pipeline.predict(model_input)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error performing prediction: {str(e)}\")\n",
    "\n",
    "    @classmethod\n",
    "    def log_model(cls, artifact_path, config_path, demo_path):\n",
    "        \"\"\"\n",
    "        Logs the model to MLflow with appropriate artifacts and schema (vanilla-rag pattern).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            mlflow.log_artifacts(NLTK_DIR_LOCAL, artifact_path='nltk_data')\n",
    "            mlflow.log_artifact(CONFIG_PATH, artifact_path='config')\n",
    "            nltk_artifact_uri = mlflow.get_artifact_uri('nltk_data')\n",
    "\n",
    "            ctx = SimpleNamespace(artifacts={\n",
    "                'data_path': DATA_PATH,\n",
    "                'nltk_data': nltk_artifact_uri,\n",
    "                'config': config_path,\n",
    "                'demo' : DEMO_FOLDER\n",
    "                \n",
    "            })\n",
    "\n",
    "            model = SpamDetectionModel()\n",
    "            model.load_context(ctx)\n",
    "\n",
    "            signature = ModelSignature(\n",
    "                inputs=Schema([ColSpec('string', 'text')]),\n",
    "                outputs=Schema([ColSpec('string')])\n",
    "            )\n",
    "\n",
    "            mlflow.pyfunc.log_model(\n",
    "                artifact_path=artifact_path,\n",
    "                python_model=model,\n",
    "                artifacts={\n",
    "                    'data_path': DATA_PATH,\n",
    "                    'nltk_data': nltk_artifact_uri,\n",
    "                    'config': config_path,\n",
    "                    'demo': DEMO_FOLDER\n",
    "                },\n",
    "                signature=signature\n",
    "            )\n",
    "\n",
    "            logger.info(\"‚úÖ Model and artifacts successfully registered in MLflow\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error logging model: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4332b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 17:15:04 - INFO - üöÄ Starting the experiment: Spam_Detection_Experiment\n",
      "2025-08-01 17:15:04 - INFO - üìÅ Run's Artifact URI: /phoenix/mlflow/711006087746390577/fd906992e7e5436e9fd7fd65895e8517/artifacts\n",
      "2025-08-01 17:15:05 - INFO - ‚úÖ Model and configuration loaded successfully\n",
      "2025-08-01 17:15:05 - INFO - ‚úÖ Model and configuration loaded successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2509931908814b88b3e23a733feeaba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b80e0c91e194abb95608e36d58008b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6223290df8c24e949d63a139ba86c6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b8374e20694d71ab543e0c01c16ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 17:15:10 - INFO - ‚úÖ Model and artifacts successfully registered in MLflow\n",
      "Registered model 'Spam_Detection_Model' already exists. Creating a new version of this model...\n",
      "Created version '21' of model 'Spam_Detection_Model'.\n",
      "2025-08-01 17:15:11 - INFO - ‚úÖ Model registered successfully with run ID: fd906992e7e5436e9fd7fd65895e8517\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'üöÄ Starting the experiment: {EXPERIMENT_NAME}')\n",
    "\n",
    "mlflow.set_tracking_uri('/phoenix/mlflow')\n",
    "mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    logger.info(f\"üìÅ Run's Artifact URI: {run.info.artifact_uri}\")\n",
    "\n",
    "    mlflow.log_artifacts(NLTK_DIR_LOCAL, artifact_path='nltk_data')\n",
    "    mlflow.log_artifact(CONFIG_PATH, artifact_path='config')\n",
    "    nltk_artifact_uri = mlflow.get_artifact_uri('nltk_data')\n",
    "\n",
    "    ctx = SimpleNamespace(artifacts={\n",
    "        'data_path': DATA_PATH,\n",
    "        'nltk_data': nltk_artifact_uri,\n",
    "        'config': CONFIG_PATH,\n",
    "        'demo' : DEMO_FOLDER\n",
    "    })\n",
    "\n",
    "    model = SpamDetectionModel()\n",
    "    model.load_context(ctx)\n",
    "\n",
    "    preds = model.pipeline.predict(model._X_test)\n",
    "    report = classification_report(model._y_test, preds, output_dict=True)\n",
    "    mlflow.log_metric('accuracy', report['accuracy'])\n",
    "\n",
    "    SpamDetectionModel.log_model(\n",
    "        artifact_path=MODEL_NAME,\n",
    "        config_path=CONFIG_PATH,\n",
    "        demo_path = DEMO_FOLDER\n",
    "    )\n",
    "\n",
    "    model_uri = f\"runs:/{run.info.run_id}/{MODEL_NAME}\"\n",
    "    mlflow.register_model(\n",
    "        model_uri=model_uri,\n",
    "        name=MODEL_NAME\n",
    "    )\n",
    "\n",
    "    logger.info(f\"‚úÖ Model registered successfully with run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229ff16",
   "metadata": {},
   "source": [
    "## Fetching the Latest Model Version from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b56eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 17:15:12 - INFO - Latest Model Version: 21\n",
      "2025-08-01 17:15:12 - INFO - Model Signature: inputs: \n",
      "  ['text': string (required)]\n",
      "outputs: \n",
      "  [string (required)]\n",
      "params: \n",
      "  None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Retrieve the latest version of the \"spam_detect_model\" model \n",
    "model_metadata = client.get_latest_versions(MODEL_NAME, stages=[\"None\"])\n",
    "latest_model_version = model_metadata[0].version  # Extract the latest model version\n",
    "\n",
    "# Fetch model information, including its signature\n",
    "model_info = mlflow.models.get_model_info(f\"models:/{MODEL_NAME}/{latest_model_version}\")\n",
    "\n",
    "# Print the latest model version and its signature\n",
    "logger.info(f\"Latest Model Version: {latest_model_version}\")\n",
    "logger.info(f\"Model Signature: {model_info.signature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c894e1",
   "metadata": {},
   "source": [
    "## Loading the Model and Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d89833d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 17:15:12 - INFO - ‚úÖ Model and configuration loaded successfully\n",
      "2025-08-01 17:15:12 - INFO - You have won a free ticket!\n",
      "2025-08-01 17:15:12 - INFO - ['ham']\n"
     ]
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{MODEL_NAME}/{latest_model_version}\")\n",
    "\n",
    "# Define a sample text for testing\n",
    "logger.info(TEXT)\n",
    "text = pd.DataFrame({'text': [TEXT]})\n",
    "\n",
    "# Use the model to predict \n",
    "result = model.predict(text)\n",
    "logger.info(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "374ad096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 17:15:12 - INFO - ‚è±Ô∏è Total execution time: 0m 10.99s\n",
      "2025-08-01 17:15:12 - INFO - ‚úÖ Notebook execution completed successfully.\n"
     ]
    }
   ],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"‚è±Ô∏è Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"‚úÖ Notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134e6104",
   "metadata": {},
   "source": [
    "Built with ‚ù§Ô∏è using [**Z by HP AI Studio**](https://zdocs.datascience.hp.com/docs/aistudio/overview)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
