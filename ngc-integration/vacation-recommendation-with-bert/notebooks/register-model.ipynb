{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f68791c",
   "metadata": {},
   "source": [
    "# Register Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783a1167",
   "metadata": {},
   "source": [
    "## Notebook Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a0e62",
   "metadata": {},
   "source": [
    "- Start Execution\n",
    "- Install and Import Libraries\n",
    "- Configure Settings\n",
    "- Log the Model to MLFlow\n",
    "- Fetch the Latest Model Version from MLflow\n",
    "- Load the Model and Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951ab53",
   "metadata": {},
   "source": [
    "# Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3a0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "# Configure logger\n",
    "logger: logging.Logger = logging.getLogger(\"register_model_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent duplicate logs from parent loggers\n",
    "\n",
    "# Set formatter\n",
    "formatter: logging.Formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Configure and attach stream handler\n",
    "stream_handler: logging.StreamHandler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18911b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 15:23:18 - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "logger.info(\"Notebook execution started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97edf68c",
   "metadata": {},
   "source": [
    "# Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c787b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CPU times: user 315 ms, sys: 158 ms, total: 473 ms\n",
      "Wall time: 9.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%pip install -r ../requirements.txt --quiet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1899ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/aistudio/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:168: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "# MLflow for Experiment Tracking and Model Management\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec, TensorSpec, ParamSchema, ParamSpec\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# # Define the relative path to the 'src' directory (two levels up from current working directory)\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add 'src' directory to system path for module imports (e.g., utils)\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from src.bert_recommendation_service import BERTTourismModel\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a47190",
   "metadata": {},
   "source": [
    "# Configure Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d99ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Suppress Verbose Logs ------------------------\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba78255",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_PATH = \"../data/raw/corpus.csv\"\n",
    "TOKENIZER_DIR = \"../artifacts/tokenizer\"\n",
    "BERT_MODEL_NAME = \"bert-large-uncased\"\n",
    "BERT_MODEL_DATAFABRIC_PATH = \"/home/jovyan/datafabric/Bertlargeuncased/bertlargeuncased.nemo\"\n",
    "EMBEDDINGS_OUTPUT_PATH = \"../data/processed/\"\n",
    "BERT_MODEL_ONLINE_PATH = \"/root/.cache/torch/NeMo/NeMo_1.22.0/bertlargeuncased/ca4ebba9f05a8ffb79845249ca046983/bertlargeuncased.nemo\"\n",
    "DEMO_PATH = \"../demo\"\n",
    "EMBEDDINGS_PATH = \"../data/processed/embeddings.csv\"\n",
    "\n",
    "# Define required constants for MLflow registration\n",
    "EXPERIMENT_NAME = \"BERT_Tourism_Experiment\"\n",
    "RUN_NAME = \"BERT_Tourism_Run\"\n",
    "MODEL_NAME = \"BERT_Tourism_Model\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec62136d",
   "metadata": {},
   "source": [
    "# Register and Log the Model to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3476776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 15:23:35 - INFO - Starting the experiment: BERT_Tourism_Experiment\n",
      "2025-08-11 15:23:35 - INFO - Using MLflow tracking URI: /phoenix/mlflow\n",
      "2025-08-11 15:23:58 - INFO - Loading BERT model from: /home/jovyan/datafabric/Bertlargeuncased/bertlargeuncased.nemo\n",
      "[NeMo W 2025-08-11 15:26:06 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    data_file: /home/yzhang/data/nlp/bert/47316/hdf5/lower_case_1_seq_len_512_max_pred_80_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/books_wiki_en_corpus/training/\n",
      "    max_predictions_per_seq: 80\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    num_workers: 2\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n",
      "[NeMo W 2025-08-11 15:26:16 modelPT:617] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-08-11 15:26:16 modelPT:728] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 4.375e-05\n",
      "        maximize: False\n",
      "        weight_decay: 0.01\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-08-11 15:26:16 lr_scheduler:890] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-08-11 15:26:18 save_restore_connector:249] Model BERTLMModel was successfully restored from /home/jovyan/datafabric/Bertlargeuncased/bertlargeuncased.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 15:26:18 - INFO - 🔧 Generating ONNX model(s) for specified models...\n",
      "2025-08-11 15:26:18 - INFO - 🔄 Converting pytorch model: bert_tourism_onnx\n",
      "2025-08-11 15:26:18 - INFO - 🔍 Model identified as: pytorch\n",
      "2025-08-11 15:26:18 - INFO - 🔄 Exporting loaded PyTorch model with opset 12...\n",
      "2025-08-11 15:27:05 - INFO - Model saved to ONNX: bert_tourism_onnx.onnx\n",
      "2025-08-11 15:27:05 - INFO - ✅ PyTorch model exported to: bert_tourism_onnx.onnx\n",
      "2025-08-11 15:27:05 - INFO - ✅ Converted bert_tourism_onnx: bert_tourism_onnx.onnx\n",
      "2025-08-11 15:27:05 - INFO - 📦 Added ONNX artifact: onnx_model -> bert_tourism_onnx.onnx\n",
      "2025-08-11 15:27:05 - INFO -   Creating individual model directories for artifacts...\n",
      "2025-08-11 15:27:05 - INFO -   Copying ONNX models for 1 models: ['bert_tourism_onnx']\n",
      "2025-08-11 15:27:05 - INFO - 📄 Model file already has correct name: bert_tourism_onnx.onnx\n",
      "2025-08-11 15:27:05 - INFO - 📦 Added model file artifact: model_bert_tourism_onnx -> bert_tourism_onnx.onnx\n",
      "2025-08-11 15:27:05 - INFO - ✅ Copied 1 model files!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cd7d3f249c4a1fb9eae0682691b681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc5e1f517c94c5b9e94227e8d79afac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ff32160fd74ec5bcba5f85f1327519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27be000fe7441aab993304f0f2cb8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70674bb7e064c52b43784f24ca6bf9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0965e867b046d198a4be341fac56f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fcb3d046dd49c4815cfbc34f594b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e327aa8514904bb9b08952559ca78247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 15:30:38 - INFO - Model logged with artifacts: ['corpus_path', 'embeddings_path', 'tokenizer_dir', 'bert_model_path', 'demo', 'config', 'onnx_model', 'model_bert_tourism_onnx']\n",
      "2025-08-11 15:30:38 - INFO - ✅ Model logged with 1 model directories created!\n",
      "Registered model 'BERT_Tourism_Model' already exists. Creating a new version of this model...\n",
      "Created version '19' of model 'BERT_Tourism_Model'.\n",
      "2025-08-11 15:30:43 - INFO - ✅ Model 'BERT_Tourism_Model' successfully logged and registered under experiment 'BERT_Tourism_Experiment'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 1min 1s, total: 2min 20s\n",
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\", \"/phoenix/mlflow\"))\n",
    "\n",
    "# Set the MLflow experiment name\n",
    "mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "\n",
    "logger.info(f'Starting the experiment: {EXPERIMENT_NAME}')\n",
    "logger.info(f\"Using MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    # Print the artifact URI for reference\n",
    "    logging.info(f\"Run's Artifact URI: {run.info.artifact_uri}\")\n",
    "    \n",
    "    # Log the BERT similarity model to MLflow\n",
    "    BERTTourismModel.log_model(\n",
    "        model_name=MODEL_NAME,\n",
    "        corpus_path=CORPUS_PATH,\n",
    "        embeddings_path=EMBEDDINGS_PATH,\n",
    "        tokenizer_dir=TOKENIZER_DIR,\n",
    "        bert_model_online_path=BERT_MODEL_ONLINE_PATH,\n",
    "        bert_model_datafabric_path=BERT_MODEL_DATAFABRIC_PATH,\n",
    "        demo_path=DEMO_PATH,\n",
    "        config_path=\"../configs/config.yaml\"\n",
    "    )\n",
    "    # Register the logged model in MLflow Model Registry\n",
    "    model_uri = f\"runs:/{run.info.run_id}/{MODEL_NAME}\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=MODEL_NAME)\n",
    "\n",
    "logger.info(f\"✅ Model '{MODEL_NAME}' successfully logged and registered under experiment '{EXPERIMENT_NAME}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf7f63",
   "metadata": {},
   "source": [
    "# Fetch the Latest Model Version from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a6f33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest registered version of 'BERT_Tourism_Model': 19\n",
      "Signature: inputs: \n",
      "  ['query': string (required)]\n",
      "outputs: \n",
      "  ['List of Pledges and Similarities': Tensor('object', (-1,))]\n",
      "params: \n",
      "  ['show_score': boolean (default: False)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Retrieve the latest version of the \"BERT_Tourism_Model\" model (not yet in a specific stage)\n",
    "versions = client.get_latest_versions(MODEL_NAME, stages=[\"None\"])\n",
    "if not versions:\n",
    "    raise RuntimeError(f\"No registered versions found for model '{MODEL_NAME}'.\")\n",
    "latest_version = versions[0].version\n",
    "\n",
    "# Fetch model information, including its signature\n",
    "model_info = mlflow.models.get_model_info(f\"models:/{MODEL_NAME}/{latest_version}\")\n",
    "\n",
    "# Print the latest model version and its signature\n",
    "print(f\"Latest registered version of '{MODEL_NAME}': {latest_version}\")\n",
    "print(f\"Signature: {model_info.signature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f9b20",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Load the Model and Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a68f80f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-08-11 15:36:10 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    data_file: /home/yzhang/data/nlp/bert/47316/hdf5/lower_case_1_seq_len_512_max_pred_80_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/books_wiki_en_corpus/training/\n",
      "    max_predictions_per_seq: 80\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    num_workers: 2\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n",
      "[NeMo W 2025-08-11 15:36:24 modelPT:617] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-08-11 15:36:24 modelPT:728] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 4.375e-05\n",
      "        maximize: False\n",
      "        weight_decay: 0.01\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-08-11 15:36:24 lr_scheduler:890] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-08-11 15:36:26 save_restore_connector:249] Model BERTLMModel was successfully restored from /phoenix/mlflow/569123593767764897/f065cb1e55fe4b569e9ec933f7d29b0f/artifacts/BERT_Tourism_Model/artifacts/bertlargeuncased.nemo.\n",
      "Successfully loaded model 'BERT_Tourism_Model' version 19 for inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 15:36:27 - INFO - PyFunc Corpus total lines: 10374\n",
      "2025-08-11 15:36:27 - INFO - PyFunc Embeddings total lines: 10374\n",
      "2025-08-11 15:36:27 - INFO - === DEBUG CORPUS PYFUNC ===\n",
      "2025-08-11 15:36:27 - INFO - Corpus shape: (10374, 3)\n",
      "2025-08-11 15:36:27 - INFO - Embeddings shape: (10374, 1024)\n",
      "2025-08-11 15:36:27 - INFO - First 3 texts:\n",
      "2025-08-11 15:36:27 - INFO -   0: Actually we as an association are still pretty much at the beginning due to the pandemic which took the better part of our ressources. What we want to provide is a proper guideline for STR how to achieve, maintain and develop a sustainable business.\n",
      "Additionally our business is very fragmented and diverse. We have privat hosts with one or only a few apartments, professional hosts, local property managers of all sizes, platforms for STR (local, national and international level) and service providers for the industry of all kind.\n",
      "Our target for 2025 is to achieve that guideline. \n",
      "\n",
      "Nonetheless Some of our members have implemented a variation of measures like strategies for a sustainable transmission, climate compensation, specific advertising for sustainable accomodations, using local supplies, charging stations for e-cars, using renewable energy and CO2-neutral construction, tools to minimise negative impact of tourism on neighbourhoods etc.\n",
      "2025-08-11 15:36:27 - INFO -   1: EFFAT welcomes the Commission Proposal for a Regulation on data collection and sharing relating to short-term accommodation rental services COM(2022) 571 published on 7 November 2022. Such regulation is a first important step to ensure fair competition and a level playing field between all providers of accommodation services.\n",
      "\n",
      "The collection of full and comprehensive data on short-term rental hosts and guests, and the obligation of short-term rental platforms to provide these data to national competent authorities, as well as the sharing of the data at European level, will enable Member States to better regulate the sector in a harmonised approach.\n",
      "\n",
      "EFFAT, together with its social partner HOTREC, has been advocating for many years for a level playing field and fair competition in hospitality and tourism, asking that the same rules have to be applied to all providers of accommodation services, with regard to  e.g.\n",
      "- Legislation\n",
      "- Fiscal obligations\n",
      "- Food hygiene rules\n",
      "- Registration and permits for operation\n",
      "- Licensing to serve alcohol\n",
      "- Statistical measurement of the economic activity\n",
      "- Safety and security\n",
      "- Employees’ rights and protection\n",
      "- Consumers’ rights\n",
      "- Right to proper living conditions of residential neighbourhoods\n",
      "- Zoning in urban planning, e.g. the distinction between residential and commercial properties\n",
      "(see Joint EFFAT-HOTREC Statements on the Sharing / Platform Economy of December 2015 and November 2019)\n",
      "\n",
      "EFFAT will \n",
      "- in 2023-2024, follow the legislative procedure for the Regulation through European Parliament and Council of Ministers\n",
      "- during this legislative procedure, regularly keep its national member organisations updated about the legislation in the making, by reporting at least 2 times per year on the progress made and agree on measures to be taken by EFFAT and national affiliates\n",
      "- once the Regulation is finally adopted, ask national member organisations to monitor the transposition of the Regulation in their countries and to push for its proper implementation, and to report at least 2 times per year about the actions taken and the progress made \n",
      "- follow the work of the Single Digital Entry Points Coordination Group composed of Member States' national coordinators\n",
      "- continue to address the issue of short-term accommodation rental services in the Sectoral Social Dialogue Committee Horeca, by putting it on the agenda of the 2 Working Group and 1 Plenary meetings per year, and to undertake joint actions with its social partner HOTREC whenever necessary\n",
      "- continue to advocate for further measures to guarantee a level playing field and fair competition in hospitality and tourism, by compelling short-term accommodation rental services to comply with the same rules and obligations as other accommodation providers\n",
      "\n",
      "The actions described above shall contribute to achieving the aim that all short-term accommodation rental platforms have applied the obligations of the Regulation by 2025, or at least 2 years after its coming into force.\n",
      "2025-08-11 15:36:27 - INFO -   2: HOTREC calls for a level playing field and fair competition in the EU for the hospitality sector. We advocate for a specific instrument that addresses the complex and diverse regulatory questions presented by the STR industry. The main objectives include the introduction of a robust and efficient EU-wide registration system; or outlining clear and comprehensive data-sharing requirements. HOTREC made its first call for a level playing field for hoteliers vis-à-vis STR in 2014 and has since then produced several brochures and policy papers addressing how to introduce rules which are adapted to STR services and necessary regulatory requirements. \n",
      "\n",
      "We commit to issue and disseminate during the course of 2022 our position and research study among the EU institutions as well as with members of HOTREC and other stakeholders via our website. We will continue to share our position on the matter including via meetings with interested parties and stakeholders in order to reach a fair framework on the topic. Through our internal working group on STR held twice a year as well as during our biannual General Assemblies, we’ll continue to gather information about STR developments in EU countries and share the latter with the EU stakeholders during the designing phase of the STR regulation. We intend to continue monitoring STR developments during the implementation phase of the STR initiative and act as an information sharing platform between our members\n",
      "2025-08-11 15:36:27 - INFO - ========================================\n",
      "2025-08-11 15:36:27 - INFO - PyFunc Query: '['Give me a resort budget vacation suggestion']'\n",
      "2025-08-11 15:36:27 - INFO - PyFunc input_ids shape: torch.Size([1, 9])\n",
      "2025-08-11 15:36:27 - INFO - PyFunc input_ids[:10]: tensor([  101,  2507,  2033,  1037,  7001,  5166, 10885, 10293,   102])\n",
      "2025-08-11 15:36:27 - INFO - PyFunc attention_mask[:10]: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "2025-08-11 15:36:27 - INFO - PyFunc token_type_ids[:10]: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "2025-08-11 15:36:27 - INFO - PyFunc embedding shape: (1, 1024)\n",
      "2025-08-11 15:36:27 - INFO - PyFunc embedding[:5]: [ 0.06976533  0.07480656 -0.891693    0.00676205 -0.21886505]\n",
      "2025-08-11 15:36:27 - INFO - PyFunc embedding range: [-6.812421, 1.474453]\n",
      "2025-08-11 15:36:27 - INFO - --------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 44.2 s, total: 2min 16s\n",
      "Wall time: 5min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load the trained BERT similarity model from MLflow\n",
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{MODEL_NAME}/{latest_version}\")\n",
    "print(f\"Successfully loaded model '{MODEL_NAME}' version {latest_version} for inference.\")\n",
    "\n",
    "# Define a sample query for testing\n",
    "query = \"Give me a resort budget vacation suggestion\"\n",
    "\n",
    "# Use the model to predict similar results based on the query\n",
    "result = model.predict({\"query\": [query]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "120bd381-f0bb-428a-ac49-ad2ed81fe00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════╤═════════════════════════════════════════════════════════════════════════════════════════════════════╤═══════════════════╕\n",
      "│    │ Recommended Option                                                                                  │   Relevance Score │\n",
      "╞════╪═════════════════════════════════════════════════════════════════════════════════════════════════════╪═══════════════════╡\n",
      "│  0 │ For a budget-friendly vacation, consider a resort with vacation options and cruise activities.      │          0.869162 │\n",
      "├────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────┤\n",
      "│  1 │ For a budget-friendly vacation, consider a getaway with beach options and vacation activities.      │          0.863917 │\n",
      "├────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────┤\n",
      "│  2 │ For a budget-friendly vacation, consider a getaway with hotel options and vacation activities.      │          0.862302 │\n",
      "├────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────┤\n",
      "│  3 │ For a budget-friendly vacation, consider a reservation with beach options and mountains activities. │          0.861637 │\n",
      "├────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────┤\n",
      "│  4 │ For a budget-friendly wildlife, consider a vacation with vacation options and holiday activities.   │          0.861579 │\n",
      "╘════╧═════════════════════════════════════════════════════════════════════════════════════════════════════╧═══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Convert the result into a pandas DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "# Drop unnecessary columns if needed\n",
    "df = df.drop(columns=[\"Unnamed: 0\", \"Topic\"], errors=\"ignore\")\n",
    "\n",
    "# Rename columns for better readability\n",
    "df.rename(columns={\"Pledge\": \"Recommended Option\", \"Similarity\": \"Relevance Score\"}, inplace=True)\n",
    "\n",
    "# Display the DataFrame in a tabular format\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36c4f0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 15:36:27 - INFO - ⏱️ Total execution time: 13m 9.61s\n",
      "2025-08-11 15:36:27 - INFO - ✅ Notebook execution completed successfully.\n"
     ]
    }
   ],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"⏱️ Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"✅ Notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d9c656",
   "metadata": {},
   "source": [
    "Built with ❤️ using Z by HP AI Studio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aistudio",
   "language": "python",
   "name": "aistudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
