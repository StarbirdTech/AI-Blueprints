{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f68791c",
   "metadata": {},
   "source": [
    "# Register Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783a1167",
   "metadata": {},
   "source": [
    "## Notebook Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a0e62",
   "metadata": {},
   "source": [
    "- Start Execution\n",
    "- Install and Import Libraries\n",
    "- Configure Settings\n",
    "- Log the Model to MLFlow\n",
    "- Fetch the Latest Model Version from MLflow\n",
    "- Load the Model and Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951ab53",
   "metadata": {},
   "source": [
    "# Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3a0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "# Configure logger\n",
    "logger: logging.Logger = logging.getLogger(\"register_model_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent duplicate logs from parent loggers\n",
    "\n",
    "# Set formatter\n",
    "formatter: logging.Formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Configure and attach stream handler\n",
    "stream_handler: logging.StreamHandler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18911b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 16:26:09 - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "logger.info(\"Notebook execution started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97edf68c",
   "metadata": {},
   "source": [
    "# Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c787b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CPU times: user 122 ms, sys: 38.1 ms, total: 160 ms\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%pip install -r ../requirements.txt --quiet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1899ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/aistudio/lib/python3.10/site-packages/mlflow/pyfunc/utils/data_validation.py:168: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "# MLflow for Experiment Tracking and Model Management\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec, TensorSpec, ParamSchema, ParamSpec\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# # Define the relative path to the 'src' directory (two levels up from current working directory)\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add 'src' directory to system path for module imports (e.g., utils)\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from src.bert_recommendation_service import BERTTourismModel\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a47190",
   "metadata": {},
   "source": [
    "# Configure Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d99ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Suppress Verbose Logs ------------------------\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba78255",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_PATH = \"../data/raw/corpus.csv\"\n",
    "TOKENIZER_DIR = \"../artifacts/tokenizer\"\n",
    "BERT_MODEL_NAME = \"bert-large-uncased\"\n",
    "BERT_MODEL_DATAFABRIC_PATH = \"/home/jovyan/datafabric/Bertlargeuncased/bertlargeuncased.nemo\"\n",
    "EMBEDDINGS_OUTPUT_PATH = \"../data/processed/\"\n",
    "BERT_MODEL_ONLINE_PATH = \"/root/.cache/torch/NeMo/NeMo_1.22.0/bertlargeuncased/ca4ebba9f05a8ffb79845249ca046983/bertlargeuncased.nemo\"\n",
    "DEMO_PATH = \"../demo\"\n",
    "EMBEDDINGS_PATH = \"../data/processed/embeddings.csv\"\n",
    "\n",
    "# Define required constants for MLflow registration\n",
    "EXPERIMENT_NAME = \"BERT_Tourism_Experiment\"\n",
    "RUN_NAME = \"BERT_Tourism_Run\"\n",
    "MODEL_NAME = \"BERT_Tourism_Model\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec62136d",
   "metadata": {},
   "source": [
    "# Register and Log the Model to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3476776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 16:26:25 - INFO - Starting the experiment: BERT_Tourism_Experiment\n",
      "2025-08-21 16:26:25 - INFO - Using MLflow tracking URI: /phoenix/mlflow\n",
      "2025-08-21 16:26:32 - INFO - Loading BERT model from: /home/jovyan/datafabric/Bertlargeuncased/bertlargeuncased.nemo\n",
      "[NeMo W 2025-08-21 16:27:07 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    data_file: /home/yzhang/data/nlp/bert/47316/hdf5/lower_case_1_seq_len_512_max_pred_80_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/books_wiki_en_corpus/training/\n",
      "    max_predictions_per_seq: 80\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    num_workers: 2\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a83c848dcc64a87ae7ef62f318105a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ef2eb5e4914fbdb7533fbd8adf8323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cas-bridge.xethub.hf.co/xet-bridge-us/621ffdc036468d709f17433e/c58b5aaad0ae78a35c3c7e8175077f521c0a4c7f280fef43f0f3b92ca7a2956c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250821%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250821T162716Z&X-Amz-Expires=3600&X-Amz-Signature=2eefbfb291612c002f5154c70d344d68abb1dae2eac41111fd5d1129eec24957&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&x-id=GetObject&Expires=1755797236&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NTc5NzIzNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82MjFmZmRjMDM2NDY4ZDcwOWYxNzQzM2UvYzU4YjVhYWFkMGFlNzhhMzVjM2M3ZTgxNzUwNzdmNTIxYzBhNGM3ZjI4MGZlZjQzZjBmM2I5MmNhN2EyOTU2YyoifV19&Signature=pFPEqPX7R4YVJdwzbSlRteWh1rjrmLBRooPISyPFmngFjaLOOsFHfNqJuSAroLhRElipoACeVkzVNTO%7EQZEtM9WPsXkxyueXbL4-KZU6rY2CLMzD850V-CXm7Fig8uqYy0-xhfa913Zb2NBhLUyt4X1r3-djb%7EbY4ccfQrDru0ZXjhEBsZUANN3RNIgcrtwOv-HRjc7ffQjLLeOmTGIhLRiMEGBMy0ixe5IqxEISKPQrB-CQTgvk2ITLJ95xzuZxUZ29s4xePhZZdkiAq%7EFbQI2spcixyx%7EnBwAnpXu-b0%7EHS%7E4LKwhPFqaFAPN71XR2UTuHvh5x7OZU-cIXKmfzrw__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0821 16:29:19.746510 139713831174592 file_download.py:538] Error while downloading from https://cas-bridge.xethub.hf.co/xet-bridge-us/621ffdc036468d709f17433e/c58b5aaad0ae78a35c3c7e8175077f521c0a4c7f280fef43f0f3b92ca7a2956c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250821%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250821T162716Z&X-Amz-Expires=3600&X-Amz-Signature=2eefbfb291612c002f5154c70d344d68abb1dae2eac41111fd5d1129eec24957&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&x-id=GetObject&Expires=1755797236&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NTc5NzIzNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82MjFmZmRjMDM2NDY4ZDcwOWYxNzQzM2UvYzU4YjVhYWFkMGFlNzhhMzVjM2M3ZTgxNzUwNzdmNTIxYzBhNGM3ZjI4MGZlZjQzZjBmM2I5MmNhN2EyOTU2YyoifV19&Signature=pFPEqPX7R4YVJdwzbSlRteWh1rjrmLBRooPISyPFmngFjaLOOsFHfNqJuSAroLhRElipoACeVkzVNTO%7EQZEtM9WPsXkxyueXbL4-KZU6rY2CLMzD850V-CXm7Fig8uqYy0-xhfa913Zb2NBhLUyt4X1r3-djb%7EbY4ccfQrDru0ZXjhEBsZUANN3RNIgcrtwOv-HRjc7ffQjLLeOmTGIhLRiMEGBMy0ixe5IqxEISKPQrB-CQTgvk2ITLJ95xzuZxUZ29s4xePhZZdkiAq%7EFbQI2spcixyx%7EnBwAnpXu-b0%7EHS%7E4LKwhPFqaFAPN71XR2UTuHvh5x7OZU-cIXKmfzrw__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8c5d3713ae4ebf93ec00a0a2ec2433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  95%|#########5| 1.28G/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-08-21 16:29:30 modelPT:617] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-08-21 16:29:30 modelPT:728] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 4.375e-05\n",
      "        maximize: False\n",
      "        weight_decay: 0.01\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-08-21 16:29:30 lr_scheduler:890] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-08-21 16:29:31 save_restore_connector:249] Model BERTLMModel was successfully restored from /home/jovyan/datafabric/Bertlargeuncased/bertlargeuncased.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 16:29:31 - INFO - 🔧 Generating ONNX model(s) for specified models...\n",
      "2025-08-21 16:29:31 - INFO - 🔄 Converting pytorch model: bert_tourism_onnx\n",
      "2025-08-21 16:29:31 - INFO - 🔍 Model identified as: pytorch\n",
      "2025-08-21 16:29:31 - INFO - 🔄 Exporting loaded PyTorch model with opset 12...\n",
      "2025-08-21 16:29:43 - INFO - Model saved to ONNX: bert_tourism_onnx.onnx\n",
      "2025-08-21 16:29:43 - INFO - ✅ PyTorch model exported to: bert_tourism_onnx.onnx\n",
      "2025-08-21 16:29:43 - INFO - ✅ Converted bert_tourism_onnx: bert_tourism_onnx.onnx\n",
      "2025-08-21 16:29:43 - INFO - 📦 Added ONNX artifact: onnx_model -> bert_tourism_onnx.onnx\n",
      "2025-08-21 16:29:43 - INFO -   Creating individual model directories for artifacts...\n",
      "2025-08-21 16:29:43 - INFO -   Copying ONNX models for 1 models: ['bert_tourism_onnx']\n",
      "2025-08-21 16:29:43 - INFO - 📄 Model file already has correct name: bert_tourism_onnx.onnx\n",
      "2025-08-21 16:29:43 - INFO - 📦 Added model file artifact: model_bert_tourism_onnx -> bert_tourism_onnx.onnx\n",
      "2025-08-21 16:29:43 - INFO - ✅ Copied 1 model files!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90437c8d2284dd08591edcdc86a7a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1ca79831dd43afae1a6d6d9b82f19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3097a74f57d04186b45b04835e5c3210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a46d9fec8f40a1920fe2cb08861999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e8e81a63604999939b4433dc6a9c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07152d70254143148825c96b42a23e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7b33f77118443d8a697005f82dba49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f07dd4448e4147b9c0d85a593362e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 16:30:10 - INFO - Model logged with artifacts: ['corpus_path', 'embeddings_path', 'tokenizer_dir', 'bert_model_path', 'demo', 'config', 'onnx_model', 'model_bert_tourism_onnx']\n",
      "2025-08-21 16:30:10 - INFO - ✅ Model logged with 1 model directories created!\n",
      "Registered model 'BERT_Tourism_Model' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'BERT_Tourism_Model'.\n",
      "2025-08-21 16:30:10 - INFO - ✅ Model 'BERT_Tourism_Model' successfully logged and registered under experiment 'BERT_Tourism_Experiment'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.1 s, sys: 13.9 s, total: 35.9 s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\", \"/phoenix/mlflow\"))\n",
    "\n",
    "# Set the MLflow experiment name\n",
    "mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "\n",
    "logger.info(f'Starting the experiment: {EXPERIMENT_NAME}')\n",
    "logger.info(f\"Using MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    # Print the artifact URI for reference\n",
    "    logging.info(f\"Run's Artifact URI: {run.info.artifact_uri}\")\n",
    "    \n",
    "    # Log the BERT similarity model to MLflow\n",
    "    BERTTourismModel.log_model(\n",
    "        model_name=MODEL_NAME,\n",
    "        corpus_path=CORPUS_PATH,\n",
    "        embeddings_path=EMBEDDINGS_PATH,\n",
    "        tokenizer_dir=TOKENIZER_DIR,\n",
    "        bert_model_online_path=BERT_MODEL_ONLINE_PATH,\n",
    "        bert_model_datafabric_path=BERT_MODEL_DATAFABRIC_PATH,\n",
    "        demo_path=DEMO_PATH,\n",
    "        config_path=\"../configs/config.yaml\"\n",
    "    )\n",
    "    # Register the logged model in MLflow Model Registry\n",
    "    model_uri = f\"runs:/{run.info.run_id}/{MODEL_NAME}\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=MODEL_NAME)\n",
    "\n",
    "logger.info(f\"✅ Model '{MODEL_NAME}' successfully logged and registered under experiment '{EXPERIMENT_NAME}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf7f63",
   "metadata": {},
   "source": [
    "# Fetch the Latest Model Version from MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a6f33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest registered version of 'BERT_Tourism_Model': 2\n",
      "Signature: inputs: \n",
      "  ['query': string (required)]\n",
      "outputs: \n",
      "  ['List of Pledges and Similarities': Tensor('object', (-1,))]\n",
      "params: \n",
      "  ['show_score': boolean (default: False)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Retrieve the latest version of the \"BERT_Tourism_Model\" model (not yet in a specific stage)\n",
    "versions = client.get_latest_versions(MODEL_NAME, stages=[\"None\"])\n",
    "if not versions:\n",
    "    raise RuntimeError(f\"No registered versions found for model '{MODEL_NAME}'.\")\n",
    "latest_version = versions[0].version\n",
    "\n",
    "# Fetch model information, including its signature\n",
    "model_info = mlflow.models.get_model_info(f\"models:/{MODEL_NAME}/{latest_version}\")\n",
    "\n",
    "# Print the latest model version and its signature\n",
    "print(f\"Latest registered version of '{MODEL_NAME}': {latest_version}\")\n",
    "print(f\"Signature: {model_info.signature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f9b20",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Load the Model and Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a68f80f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-08-21 16:30:42 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    data_file: /home/yzhang/data/nlp/bert/47316/hdf5/lower_case_1_seq_len_512_max_pred_80_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/books_wiki_en_corpus/training/\n",
      "    max_predictions_per_seq: 80\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    num_workers: 2\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n",
      "[NeMo W 2025-08-21 16:30:43 modelPT:617] Trainer wasn't specified in model constructor. Make sure that you really wanted it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-08-21 16:30:43 modelPT:728] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 4.375e-05\n",
      "        maximize: False\n",
      "        weight_decay: 0.01\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-08-21 16:30:43 lr_scheduler:890] Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, cannot compute effective `max_steps` !\n",
      "    Scheduler will not be instantiated !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-08-21 16:30:44 save_restore_connector:249] Model BERTLMModel was successfully restored from /phoenix/mlflow/715571117481761930/ad280f014ebd4e87babba585d7fd076e/artifacts/BERT_Tourism_Model/artifacts/bertlargeuncased.nemo.\n",
      "Successfully loaded model 'BERT_Tourism_Model' version 2 for inference.\n",
      "CPU times: user 13.6 s, sys: 2.77 s, total: 16.4 s\n",
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load the trained BERT similarity model from MLflow\n",
    "model = mlflow.pyfunc.load_model(model_uri=f\"models:/{MODEL_NAME}/{latest_version}\")\n",
    "print(f\"Successfully loaded model '{MODEL_NAME}' version {latest_version} for inference.\")\n",
    "\n",
    "# Define a sample query for testing\n",
    "query = \"Give me a resort budget vacation suggestion\"\n",
    "\n",
    "# Use the model to predict similar results based on the query\n",
    "result = model.predict({\"query\": [query]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "120bd381-f0bb-428a-ac49-ad2ed81fe00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════╤═════════════════════════════════════════════════════════════════════════════════════════════════════╤═══════════════════╕\n",
      "│    │ Recommended Option                                                                                  │   Relevance Score │\n",
      "╞════╪═════════════════════════════════════════════════════════════════════════════════════════════════════╪═══════════════════╡\n",
      "│  0 │ For a budget-friendly vacation, consider a resort with vacation options and cruise activities.      │          0.869151 │\n",
      "├────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────┤\n",
      "│  1 │ For a budget-friendly vacation, consider a getaway with beach options and vacation activities.      │          0.863877 │\n",
      "├────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────┤\n",
      "│  2 │ For a budget-friendly vacation, consider a getaway with hotel options and vacation activities.      │          0.862286 │\n",
      "├────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────┤\n",
      "│  3 │ For a budget-friendly vacation, consider a reservation with beach options and mountains activities. │          0.861614 │\n",
      "├────┼─────────────────────────────────────────────────────────────────────────────────────────────────────┼───────────────────┤\n",
      "│  4 │ For a budget-friendly wildlife, consider a vacation with vacation options and holiday activities.   │          0.861545 │\n",
      "╘════╧═════════════════════════════════════════════════════════════════════════════════════════════════════╧═══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "# Convert the result into a pandas DataFrame\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "# Drop unnecessary columns if needed\n",
    "df = df.drop(columns=[\"Unnamed: 0\", \"Topic\"], errors=\"ignore\")\n",
    "\n",
    "# Rename columns for better readability\n",
    "df.rename(columns={\"Pledge\": \"Recommended Option\", \"Similarity\": \"Relevance Score\"}, inplace=True)\n",
    "\n",
    "# Display the DataFrame in a tabular format\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36c4f0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 16:30:44 - INFO - ⏱️ Total execution time: 4m 35.02s\n",
      "2025-08-21 16:30:44 - INFO - ✅ Notebook execution completed successfully.\n"
     ]
    }
   ],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"⏱️ Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"✅ Notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d9c656",
   "metadata": {},
   "source": [
    "Built with ❤️ using Z by HP AI Studio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aistudio",
   "language": "python",
   "name": "aistudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
