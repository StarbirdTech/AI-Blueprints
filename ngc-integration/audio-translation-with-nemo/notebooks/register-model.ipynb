{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\\\"text-align: center; font-size: 50px;\\\"> Register Model </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "- Start Execution\n",
    "- Install and Import Libraries\n",
    "- Configure Settings\n",
    "- Register the Model Log Results to MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "# Configure logger\n",
    "logger: logging.Logger = logging.getLogger(\"register_model_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent duplicate logs from parent loggers\n",
    "\n",
    "# Set formatter\n",
    "formatter: logging.Formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Configure and attach stream handler\n",
    "stream_handler: logging.StreamHandler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 20:54:23 - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  \n",
    "logger.info(\"Notebook execution started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CPU times: user 113 ms, sys: 25.1 ms, total: 138 ms\n",
      "Wall time: 3.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- NeMo Core Imports -------------------------\n",
    "import nemo                             # NVIDIA NeMo core package\n",
    "import nemo.collections.asr as nemo_asr # Speech Recognition (ASR) collection\n",
    "import nemo.collections.tts as nemo_tts # Text-to-Speech (TTS) collection\n",
    "\n",
    "# ------------------------- Transformers -------------------------\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# ------------------------- Audio Processing Utilities -------------------------\n",
    "import IPython                          # For playing audio inside Jupyter Notebooks\n",
    "import soundfile                        # For reading and writing audio files\n",
    "from pathlib import Path                # Filesystem path management\n",
    "\n",
    "# ------------------------- System Utilities -------------------------\n",
    "\n",
    "import os                               # Operating system interfaces\n",
    "import shutil                           # High-level file operations\n",
    "import uuid                             # Unique ID generation\n",
    "import io                               # Input/Output core tools\n",
    "import base64                           # Encoding and decoding base64 strings\n",
    "import json                             # JSON serialization and deserialization\n",
    "import warnings                         # Suppressing and managing warnings\n",
    "import numpy as np                      # Numerical array operations\n",
    "np.float_ = np.float64\n",
    "import torch\n",
    "\n",
    "# ------------------------- MLflow Integration -------------------------\n",
    "\n",
    "import mlflow                           # MLflow experiment tracking and model management\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "from mlflow.types import ParamSchema, ParamSpec\n",
    "from mlflow.models import ModelSignature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Suppress Verbose Logs ------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Suppress NeMo internal logging\n",
    "logging.getLogger('nemo_logger').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Model File Paths -------------------------\n",
    "MT_MODEL = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "ASR_MODEL_PATH = \"/home/jovyan/datafabric/STT_En_Citrinet_1024_Gamma_0.25/stt_en_citrinet_1024_gamma_0_25.nemo\"                  # Speech-to-Text (ASR) model\n",
    "SPECTROGRAM_GENERATOR_PATH = \"/home/jovyan/datafabric/TTS_Es_Multispeaker_FastPitch_HiFiGAN/tts_es_fastpitch_multispeaker.nemo\"  # Spectrogram generator model (FastPitch)\n",
    "VOCODER_PATH = \"/home/jovyan/datafabric/TTS_Es_Multispeaker_FastPitch_HiFiGAN/tts_es_hifigan_ft_fastpitch_multispeaker.nemo\"     # Vocoder model (HiFiGAN)\n",
    "\n",
    "# ------------------------- Sample Audio Path -------------------------\n",
    "\n",
    "AUDIO_SAMPLE_PATH = \"../data/ForrestGump.mp3\"      # Path to the input English audio sample\n",
    "\n",
    "# ------------------------- MLflow Experiment Configuration -------------------------\n",
    "\n",
    "EXPERIMENT_NAME = \"NeMo_Translation_Experiment\"    # MLflow experiment name\n",
    "RUN_NAME = \"NeMo_en_es_Translation_Run\"            # Specific run name inside the experiment\n",
    "MODEL_NAME = \"nemo_en_es\"                          # Registered model name in MLflow\n",
    "DEMO_PATH = \"../demo\"                              # Path to save demo outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register the Model and Log Results to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NemoTranslationModel(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"\n",
    "    A custom MLflow pyfunc model for performing end-to-end audio translation using NVIDIA NeMo models.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_context(self, context):\n",
    "        \"\"\"Load NeMo models and prepare the temporary working directory.\"\"\"\n",
    "        model_dir = context.artifacts[\"model\"]\n",
    "\n",
    "        self.asr_model = nemo_asr.models.EncDecCTCModel.restore_from(f\"{model_dir}/enc_dec_CTC.nemo\")\n",
    "        self.mt_tokenizer = MarianTokenizer.from_pretrained(MT_MODEL)\n",
    "        self.mt_model = MarianMTModel.from_pretrained(MT_MODEL)\n",
    "        self.spectrogram_generator = nemo_tts.models.FastPitchModel.restore_from(f\"{model_dir}/fast_pitch.nemo\")\n",
    "        self.vocoder = nemo_tts.models.HifiGanModel.restore_from(f\"{model_dir}/hifi_gan.nemo\")\n",
    "\n",
    "        self.framerate = 41000\n",
    "\n",
    "        os.makedirs(\"/phoenix/mlflow/tmp\", exist_ok=True)\n",
    "\n",
    "    def transcribe_audio(self, model_input):\n",
    "        \"\"\"Deserialize base64-encoded audio, save it temporarily, and perform speech-to-text.\"\"\"\n",
    "        serialized_audio = model_input['source_serialized_audio'][0]\n",
    "        audio_buffer = io.BytesIO(base64.b64decode(serialized_audio))\n",
    "        audio_array, self.framerate = soundfile.read(audio_buffer)\n",
    "\n",
    "        # Ensure mono-channel audio\n",
    "        if audio_array.ndim > 1:\n",
    "            audio_array = audio_array[:, 0]\n",
    "\n",
    "        temp_wave_path = f\"/phoenix/mlflow/tmp/{self.file_id}.wav\"\n",
    "        soundfile.write(temp_wave_path, audio_array, self.framerate)\n",
    "\n",
    "        # Perform ASR\n",
    "        transcribed_text = self.asr_model.cuda().transcribe([temp_wave_path])\n",
    "        return transcribed_text\n",
    "\n",
    "    def text_to_audio(self, text: str):\n",
    "        \"\"\"Generate audio waveform from text using TTS models.\"\"\"\n",
    "        parsed_tokens = self.spectrogram_generator.cuda().parse(text)\n",
    "        spectrogram = self.spectrogram_generator.cuda().generate_spectrogram(tokens=parsed_tokens, speaker=2)\n",
    "        audio_tensor = self.vocoder.cuda().convert_spectrogram_to_audio(spec=spectrogram)\n",
    "\n",
    "        return audio_tensor.to('cpu').detach().numpy()\n",
    "\n",
    "    def serialize_audio(self, audio_array: np.ndarray):\n",
    "        \"\"\"Serialize a NumPy audio array into a base64-encoded WAV file.\"\"\"\n",
    "\n",
    "        \n",
    "        wave_path = f\"/phoenix/mlflow/tmp/out_{self.file_id}.wav\"\n",
    "        soundfile.write(wave_path, audio_array, samplerate=self.framerate, format='WAV')\n",
    "\n",
    "        with io.BytesIO() as buffer:\n",
    "            soundfile.write(buffer, audio_array, samplerate=self.framerate, format='WAV')\n",
    "            buffer.seek(0)\n",
    "            audio_base64 = base64.b64encode(buffer.read()).decode('utf-8')\n",
    "\n",
    "        return audio_base64\n",
    "\n",
    "    def predict(self, context, model_input, params):\n",
    "        \"\"\"\n",
    "        Perform inference:\n",
    "        1. Transcribe audio (if input is audio)\n",
    "        2. Translate text using Hugging Face MarianMT\n",
    "        3. Synthesize translated text into speech\n",
    "        4. Serialize the audio if needed\n",
    "        \"\"\"\n",
    "\n",
    "        self.file_id = uuid.uuid1()\n",
    "        use_audio = params.get(\"use_audio\", False)\n",
    "\n",
    "        if use_audio:\n",
    "            source_text = self.transcribe_audio(model_input)[0]\n",
    "        else:\n",
    "            source_text = model_input['source_text'][0]\n",
    "\n",
    "        # Move model to GPU if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.mt_model = self.mt_model.to(device)\n",
    "\n",
    "        # Tokenize and move inputs to device\n",
    "        inputs = self.mt_tokenizer(source_text, return_tensors=\"pt\", padding=True)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        # Generate translation\n",
    "        translated = self.mt_model.generate(**inputs)\n",
    "        translated_text = self.mt_tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "        translated_audio_base64 = \"\"\n",
    "        if use_audio:\n",
    "            audio_array = self.text_to_audio(translated_text)\n",
    "            translated_audio_base64 = self.serialize_audio(audio_array[0])\n",
    "\n",
    "        return {\n",
    "            \"original_text\": source_text,\n",
    "            \"translated_text\": translated_text,\n",
    "            \"translated_serialized_audio\": translated_audio_base64\n",
    "        }\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def log_model(cls, model_name: str, nemo_models: dict, demo_folder: str, pip_requirements: str | list[str] | None = None,):\n",
    "        \"\"\"\n",
    "        Log the translation model to MLflow with model artifacts and signatures.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Name under which to register the model.\n",
    "            nemo_models: Dictionary mapping component names to their local .nemo file paths.\n",
    "            demo_folder: Path to the demo files folder.\n",
    "        \"\"\"\n",
    "        \n",
    "        input_schema = Schema([\n",
    "            ColSpec(\"string\", \"source_text\"),\n",
    "            ColSpec(\"string\", \"source_serialized_audio\"),\n",
    "        ])\n",
    "\n",
    "        output_schema = Schema([\n",
    "            ColSpec(\"string\", \"original_text\"),\n",
    "            ColSpec(\"string\", \"translated_text\"),\n",
    "            ColSpec(\"string\", \"translated_serialized_audio\"),\n",
    "        ])\n",
    "\n",
    "        params_schema = ParamSchema([\n",
    "            ParamSpec(\"use_audio\", \"boolean\", False)\n",
    "        ])\n",
    "\n",
    "        signature = ModelSignature(\n",
    "            inputs=input_schema,\n",
    "            outputs=output_schema,\n",
    "            params=params_schema\n",
    "        )\n",
    "\n",
    "        os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "        # Copy NeMo model artifacts\n",
    "        if \"enc_dec_CTC\" in nemo_models:\n",
    "            shutil.copyfile(nemo_models[\"enc_dec_CTC\"], f\"{model_name}/enc_dec_CTC.nemo\")\n",
    "        if \"fast_pitch\" in nemo_models:\n",
    "            shutil.copyfile(nemo_models[\"fast_pitch\"], f\"{model_name}/fast_pitch.nemo\")\n",
    "        if \"hifi_gan\" in nemo_models:\n",
    "            shutil.copyfile(nemo_models[\"hifi_gan\"], f\"{model_name}/hifi_gan.nemo\")\n",
    "\n",
    "        # Log model to MLflow\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=model_name,\n",
    "            python_model=cls(),\n",
    "            artifacts={\"model\": model_name, \"demo\": demo_folder},\n",
    "            signature=signature,\n",
    "            pip_requirements=pip_requirements\n",
    "        )\n",
    "\n",
    "        # Clean up temporary files\n",
    "        shutil.rmtree(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf9f8b31d894e5a9c57ffae7bcb465f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5a68fa73584bdb8e16b38da0d67641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'nemo_en_es' already exists. Creating a new version of this model...\n",
      "Created version '9' of model 'nemo_en_es'.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- MLflow Model Logging and Registration -------------------------\n",
    "\n",
    "mlflow.set_tracking_uri('/phoenix/mlflow')\n",
    "# Set the MLflow experiment\n",
    "mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "\n",
    "# Start a new MLflow run\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    # Define the set of NeMo model components to be logged\n",
    "    nemo_model_artifacts = {\n",
    "        \"enc_dec_CTC\": ASR_MODEL_PATH,\n",
    "        \"fast_pitch\": SPECTROGRAM_GENERATOR_PATH,\n",
    "        \"hifi_gan\": VOCODER_PATH,\n",
    "    }\n",
    "\n",
    "    # Log the custom translation model with specified artifacts and demo folder\n",
    "    NemoTranslationModel.log_model(\n",
    "        model_name=MODEL_NAME,\n",
    "        nemo_models=nemo_model_artifacts,\n",
    "        demo_folder=DEMO_PATH,\n",
    "        pip_requirements=\"../requirements.txt\"\n",
    "    )\n",
    "\n",
    "    # Register the logged model in MLflow Model Registry\n",
    "    mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run.info.run_id}/{MODEL_NAME}\",\n",
    "        name=MODEL_NAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model 'nemo_en_es' successfully logged and registered under experiment 'NeMo_Translation_Experiment'.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- Success Confirmation -------------------------\n",
    "\n",
    "print(f\"✅ Model '{MODEL_NAME}' successfully logged and registered under experiment '{EXPERIMENT_NAME}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 20:56:12 - INFO - ⏱️ Total execution time: 1m 48.98s\n",
      "2025-07-18 20:56:12 - INFO - ✅ Notebook execution completed successfully.\n"
     ]
    }
   ],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"⏱️ Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"✅ Notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built with ❤️ using [**HP AI Studio**](https://hp.com/ai-studio)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aistudio",
   "language": "python",
   "name": "aistudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
