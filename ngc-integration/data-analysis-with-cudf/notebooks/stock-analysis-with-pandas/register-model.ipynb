{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\\\"text-align: center; font-size: 50px;\\\"> Register Model </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "- Start Execution\n",
    "- Install and Import Libraries\n",
    "- Define User Constants\n",
    "- Import Workflow Methods\n",
    "- Log Results to MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Configure logger\n",
    "logger: logging.Logger = logging.getLogger(\"register_model_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent duplicate logs from parent loggers\n",
    "\n",
    "# Set formatter\n",
    "formatter: logging.Formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Configure and attach stream handler\n",
    "stream_handler: logging.StreamHandler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 06:33:22 - INFO - Notebook execution started.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  \n",
    "logger.info(\"Notebook execution started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CPU times: user 54.2 ms, sys: 7.61 ms, total: 61.8 ms\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%pip install -r ../../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Standard Library Imports\n",
    "# =============================\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import nbformat\n",
    "import importlib.util\n",
    "import warnings           # To manage and filter Python warnings\n",
    "from pathlib import Path  # For object-oriented filesystem paths\n",
    "\n",
    "# =============================\n",
    "# Third-Party Library Imports\n",
    "# =============================\n",
    "import pandas as pd       # Data manipulation and analysis\n",
    "import mlflow             # Experiment tracking and model logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define User Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Suppress Verbose Logs ------------------------\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the USA stock parquet datasets\n",
    "DATASET_DIR = Path(\"/home/jovyan/datafabric/USA_Stocks/\")\n",
    "\n",
    "# Sample sizes (in millions of rows) to evaluate during the analysis\n",
    "SAMPLE_SIZES_TO_TEST = [5, 10]\n",
    "\n",
    "# Rolling window size (in days) used for time-series statistical operations\n",
    "ROLLING_WINDOW_SIZE = 7\n",
    "\n",
    "# Name of the MLflow experiment for tracking performance and metrics\n",
    "MLFLOW_EXPERIMENT_NAME = \"USA Stock Analysis with Pandas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Workflow Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "nb_path = Path.cwd() / \"run-workflow.ipynb\"      # same folder as this notebook\n",
    "\n",
    "module_name = \"run_workflow_nb\"\n",
    "\n",
    "if module_name not in sys.modules:\n",
    "    mod = types.ModuleType(module_name)\n",
    "    sys.modules[module_name] = mod\n",
    "\n",
    "    nb = nbformat.read(nb_path, as_version=4)\n",
    "    code_cells = [c.source for c in nb.cells if c.cell_type == \"code\"]\n",
    "    exec(\"\\n\\n\".join(code_cells), mod.__dict__)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "from run_workflow_nb import describe_dataframe, aggregate_by_ticker, aggregate_by_ticker_week, compute_rolling_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Results to MLFlow\n",
    "\n",
    "In this section, we will log the dataset analysis results into MLFlow, particularly the necessary time it took for each dataset to run successfully and the different operations performed on them. We will be calling the functions defined in the workflow notebook which will be applied to the given set of samples in sample_sizes (e.g. [5, 10])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Analysis for 5M Rows ---\n",
      "\n",
      "--- Running Analysis for 10M Rows ---\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('/phoenix/mlflow')\n",
    "# Set the MLflow experiment to track runs\n",
    "mlflow.set_experiment(experiment_name=MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "# Loop through each dataset sample size and run analysis\n",
    "for sample_size in SAMPLE_SIZES_TO_TEST:\n",
    "    run_name = f\"Standard Analysis - {sample_size}M\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Log configuration parameters\n",
    "        mlflow.log_param(\"Computing\", \"cpu\")\n",
    "        mlflow.log_param(\"Dataset size in millions of rows\", sample_size)\n",
    "        \n",
    "        # Load dataset corresponding to the current sample size\n",
    "        dataset_path = f\"/home/jovyan/datafabric/USA_Stocks/usa_stocks_{sample_size}m.parquet\"\n",
    "        df = pd.read_parquet(dataset_path)\n",
    "\n",
    "        print(f\"\\n--- Running Analysis for {sample_size}M Rows ---\")\n",
    "        \n",
    "        # Description\n",
    "        description_time, _ = describe_dataframe(df)\n",
    "        mlflow.log_metric(\"Description_time_seconds\", description_time)\n",
    "        \n",
    "        # Simple Aggregation\n",
    "        simple_agg_time, _ = aggregate_by_ticker(df)\n",
    "        mlflow.log_metric(\"Simple_aggregation_time_seconds\", simple_agg_time)\n",
    "        \n",
    "        # Composite Aggregation\n",
    "        composite_agg_time, _ = aggregate_by_ticker_week(df)\n",
    "        mlflow.log_metric(\"Composite_aggregation_time_seconds\", composite_agg_time)\n",
    "        \n",
    "        # Rolling Window\n",
    "        rolling_time, _ = compute_rolling_mean(df, ROLLING_WINDOW_SIZE)\n",
    "        mlflow.log_metric(f\"Rolling_window_{ROLLING_WINDOW_SIZE}D_time_seconds\", rolling_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 06:34:13 - INFO - ⏱️ Total execution time: 0m 51.44s\n",
      "2025-07-15 06:34:13 - INFO - ✅ Notebook execution completed successfully.\n"
     ]
    }
   ],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"⏱️ Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"✅ Notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built with ❤️ using [**HP AI Studio**](https://hp.com/ai-studio)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aistudio",
   "language": "python",
   "name": "aistudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
