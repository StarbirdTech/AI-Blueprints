{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\\\"text-align: center; font-size: 50px;\\\"> Register Model </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "- Start Execution\n",
    "- Install and Import Libraries\n",
    "- Define User Constants\n",
    "- Import Workflow Methods\n",
    "- Log Results to MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Configure logger\n",
    "logger: logging.Logger = logging.getLogger(\"register_model_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent duplicate logs from parent loggers\n",
    "\n",
    "# Set formatter\n",
    "formatter: logging.Formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# Configure and attach stream handler\n",
    "stream_handler: logging.StreamHandler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()  \n",
    "logger.info(\"Notebook execution started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# Load cuDF Pandas extension (required for GPU acceleration)\n",
    "# ========================================================\n",
    "%load_ext cudf.pandas\n",
    "\n",
    "# =============================\n",
    "# Standard Library Imports\n",
    "# =============================\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import nbformat\n",
    "import importlib.util\n",
    "import warnings           # To manage and filter Python warnings\n",
    "from pathlib import Path  # For object-oriented filesystem paths\n",
    "\n",
    "# =============================\n",
    "# Third-Party Library Imports\n",
    "# =============================\n",
    "import pandas as pd       # Data manipulation and analysis\n",
    "import mlflow             # Experiment tracking and model logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define User Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Suppress Verbose Logs ------------------------\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the USA stock parquet datasets\n",
    "DATASET_DIR = Path(\"/home/jovyan/datafabric/USA_Stocks/\")\n",
    "\n",
    "# Sample sizes (in millions of rows) to evaluate during the analysis\n",
    "SAMPLE_SIZES_TO_TEST = [5, 10]\n",
    "\n",
    "# Rolling window size (in days) used for time-series statistical operations\n",
    "ROLLING_WINDOW_SIZE = 7\n",
    "\n",
    "# Name of the MLflow experiment for tracking performance and metrics\n",
    "MLFLOW_EXPERIMENT_NAME = \"USA Stock Analysis with Pandas with cuDF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Workflow Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "nb_path = Path(__file__).with_name(\"run-workflow.ipynb\")\n",
    "module_name = \"run_workflow_nb\"\n",
    "\n",
    "if module_name not in sys.modules:\n",
    "    mod = types.ModuleType(module_name)\n",
    "    sys.modules[module_name] = mod\n",
    "\n",
    "    nb = nbformat.read(nb_path, as_version=4)\n",
    "    code_cells = [c.source for c in nb.cells if c.cell_type == \"code\"]\n",
    "    exec(\"\\n\\n\".join(code_cells), mod.__dict__)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "from run_workflow_nb import describe_dataframe, aggregate_by_ticker, aggregate_by_ticker_week, compute_rolling_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Results to MLFlow\n",
    "\n",
    "In this section, we will log the dataset analysis results into MLFlow, particularly the necessary time it took for each dataset to run successfully and the different operations performed on them. We will be calling the functions defined in the workflow notebook which will be applied to the given set of samples in sample_sizes (e.g. [5, 10])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('/phoenix/mlflow')\n",
    "# Set the MLflow experiment to track runs\n",
    "mlflow.set_experiment(experiment_name=MLFLOW_EXPERIMENT_NAME)\n",
    "\n",
    "# Loop through each dataset sample size and run analysis\n",
    "for sample_size in SAMPLE_SIZES_TO_TEST:\n",
    "    run_name = f\"Standard Analysis - {sample_size}M\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Log configuration parameters\n",
    "        mlflow.log_param(\"Computing\", \"cpu\")\n",
    "        mlflow.log_param(\"Dataset size in millions of rows\", sample_size)\n",
    "        \n",
    "        # Load dataset corresponding to the current sample size\n",
    "        dataset_path = f\"/home/jovyan/datafabric/USA_Stocks/usa_stocks_{sample_size}m.parquet\"\n",
    "        df = pd.read_parquet(dataset_path)\n",
    "\n",
    "        print(f\"\\n--- Running Analysis for {sample_size}M Rows ---\")\n",
    "        \n",
    "        # Description\n",
    "        mlflow.log_metric(\"Description_time_seconds\", describe_dataframe(df))\n",
    "        \n",
    "        # Simple Aggregation\n",
    "        mlflow.log_metric(\"Simple_aggregation_time_seconds\", aggregate_by_ticker(df))\n",
    "        \n",
    "        # Composite Aggregation\n",
    "        mlflow.log_metric(\"Composite_aggregation_time_seconds\", aggregate_by_ticker_week(df))\n",
    "        \n",
    "        # Rolling Window\n",
    "        mlflow.log_metric(f\"Rolling_window_{ROLLING_WINDOW_SIZE}D_time_seconds\", compute_rolling_mean(df, ROLLING_WINDOW_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time: float = time.time()\n",
    "elapsed_time: float = end_time - start_time\n",
    "elapsed_minutes: int = int(elapsed_time // 60)\n",
    "elapsed_seconds: float = elapsed_time % 60\n",
    "\n",
    "logger.info(f\"⏱️ Total execution time: {elapsed_minutes}m {elapsed_seconds:.2f}s\")\n",
    "logger.info(\"✅ Notebook execution completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built with ❤️ using [**HP AI Studio**](https://hp.com/ai-studio)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
